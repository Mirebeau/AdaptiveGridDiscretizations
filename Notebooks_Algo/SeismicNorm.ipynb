{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive PDE discretizations on Cartesian grids\n",
    "## Volume : Algorithmic tools\n",
    "## Part : Generalized acuteness\n",
    "## Chapter : Norms defined by a Hooke tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The propagation speed of seismic waves is governed by the elastic properties of the medium, encoded in a Hooke tensor $c$. The dependency is anisotropic, non-linear and rather complex from the algebraic point of view, involving for instance a polynomial constraint of degree six in three variables. In this notebook, we provide some detail on the definition and numerical computation of these quantities, implemented in the `Hooke` class of norms (`agd.Metrics.Seismic.Hooke`). We also extract some quantities of interest for the fast marching method used to solve the related eikonal equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Algorithmic tools, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. Geometric distorsion](#1.-Geometric-distorsion)\n",
    "    * [1.1 Considered norms](#1.1-Considered-norms)\n",
    "    * [1.2 Half sphere sampling](#1.2-Half-sphere-sampling)\n",
    "    * [1.3 Length distorsion](#1.3-Length-distorsion)\n",
    "    * [1.4 Angular distortion](#1.4-Angular-distortion)\n",
    "  * [2. Convexity of the constraint](#2.-Convexity-of-the-constraint)\n",
    "    * [2.1 Quasi-concavity](#2.1-Quasi-concavity)\n",
    "    * [2.2 Convexity of $\\exp(-\\alpha f_c)$.](#2.2-Convexity-of-$\\exp(-\\alpha-f_c)$.)\n",
    "  * [3. Computation of a frame of reference](#3.-Computation-of-a-frame-of-reference)\n",
    "    * [3.1 Alternative projections](#3.1-Alternative-projections)\n",
    "    * [3.2 Optimization routines](#3.2-Optimization-routines)\n",
    "    * [3.3 Two dimensions](#3.3-Two-dimensions)\n",
    "    * [3.4 Three dimensions](#3.4-Three-dimensions)\n",
    "  * [4 GPU acceleration of the TTI projection](#4-GPU-acceleration-of-the-TTI-projection)\n",
    "    * [4.1 Taking advantage of VTI rotational invariance](#4.1-Taking-advantage-of-VTI-rotational-invariance)\n",
    "    * [4.2 Validation tests](#4.2-Validation-tests)\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgement.** Some of the experiments presented in these notebooks are part of \n",
    "ongoing research with Ludovic Métivier and Da Chen.\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, Centre Borelli, ENS Paris-Saclay, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\") # Allow import of agd from parent directory (useless if conda package installed)\n",
    "#from Miscellaneous import TocTools; print(TocTools.displayTOC('SeismicNorm','Algo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "from agd.Metrics.Seismic import Hooke,Thomsen,TTI\n",
    "from agd.Metrics import Riemann\n",
    "from agd import Sphere\n",
    "from agd import LinearParallel as lp\n",
    "from agd import AutomaticDifferentiation as ad\n",
    "from agd.Plotting import SetTitle3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Geometric distorsion\n",
    "\n",
    "Norms arising in seismology have a fairly complex expression, but eventually their anisotropy is rather mild in comparison with other applications.\n",
    "We illustrate this point by computing the length distortion associated with several geologic materials, as well as their angular distortion. \n",
    "\n",
    "This allows to choose a discretization stencil for the eikonal equation, ensuring the causality property and the  applicability of the fast marching method.\n",
    "Note that for other applications involving stronger anisotropies, more complex (data adaptive, anisotropic) strategies are used in the design of the discretization stencil, see [Stern-Brocot tree](SternBrocot.ipynb) and [Voronoi vectors](VoronoiVectors.ipynb).\n",
    "\n",
    "The algebraic expression of a `Hooke` norm is not used in this section, or any of its properties, except for symmetry (which allows to consider only half of the unit sphere)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Considered norms\n",
    "\n",
    "The various geologic materials yield different types of anisotropies. We select a few for illustration.\n",
    "The level sets of the norm illustrate the distance that the seismic waves can reach in a given time, which depends on their direction of propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two specific examples\n",
    "norm2 = Hooke.mica[0].extract_xz().rotate_by(0.3) \n",
    "norm3 = Hooke.mica[0].rotate_by(0.8,axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more examples\n",
    "norms2 = [\n",
    "    (\"riemann2\",Riemann.from_diagonal([1,3**2]).rotate_by(0.7)),\n",
    "    (\"mica2\",Hooke.mica[0].extract_xz().rotate_by(1.2)),\n",
    "    (\"stishovite2\",Hooke.stishovite[0].extract_xz().rotate_by(-0.5)),\n",
    "    (\"mudshale2\",Hooke.from_ThomsenElastic(\n",
    "        Thomsen.ThomsenData[\"Mesaverde (4903) mudshale\"])[0].extract_xz().rotate_by(-0.5)),\n",
    "]\n",
    "norms3 = [\n",
    "    (\"mica3\",Hooke.mica[0].rotate_by(0.3,axis=(1,2,3))),\n",
    "    (\"stishovite3\",Hooke.stishovite[0].rotate_by(0.8,axis=(1,1,1))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aX = np.linspace(-1,1)\n",
    "X = np.meshgrid(aX,aX,indexing='ij')\n",
    "plt.title(\"Level sets of a two dimensional norm\"); plt.axis('equal');\n",
    "plt.contourf(*X,norm2.norm(X)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,3])\n",
    "for i,(name,norm) in enumerate(norms2):\n",
    "    plt.subplot(1,len(norms2),1+i)\n",
    "    plt.title(name); plt.axis('equal')\n",
    "    plt.contourf(*X,norm.norm(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Half sphere sampling\n",
    "\n",
    "We sample our norms on the Euclidean unit sphere, so as to quantify their length distortion and other distortion.\n",
    "Since the norms considered in this notebook are symmetric w.r.t the origin, it is enough to sample the half sphere.\n",
    "\n",
    "We use $40$ points for the two dimensional half-sphere, and $40^2$ points for the three dimensional one. This sampling is dense enough to extract the desired numerical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HalfSphereSampling(vdim,dens=40):\n",
    "    \"\"\"\n",
    "    Produces a rather uniform sampling of the upper half of the unit sphere.\n",
    "    - vdim (in [2,3]) : dimension of the sphere\n",
    "    - dens : sampling density. dens**(vdim-1) points are returned.\n",
    "    \"\"\"\n",
    "    if vdim==2: \n",
    "        θs = np.linspace(0,np.pi,dens,endpoint=False)\n",
    "        return np.array([np.cos(θs),np.sin(θs)])\n",
    "    elif vdim==3:\n",
    "        θs = np.linspace(0,np.pi/2,dens//2)\n",
    "        ϕs = np.linspace(0,2*np.pi,2*dens,endpoint=False)\n",
    "        return np.array([(np.cos(θ)*np.cos(ϕ), np.cos(θ)*np.sin(ϕ), np.sin(θ)) for θ in θs for ϕ in ϕs]).T\n",
    "    else: \n",
    "        raise ValueError(\"Unsupported dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sampling of the two dimensional half sphere\")\n",
    "plt.scatter(*HalfSphereSampling(2));plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "SetTitle3D(ax,\"Sampling of the three dimensional half sphere\")\n",
    "ax.scatter(*HalfSphereSampling(3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Length distorsion\n",
    "\n",
    "A natural measure of the anisotropy associated with a norm is its maximal length distortion\n",
    "$$\n",
    "    \\mu(N) := \\max_{|u|=|v|=1} \\frac {N(u)}{N(v)}.\n",
    "$$\n",
    "This quantity is to the ratio of the largest propagation speed, divided by the smallest propagation speed, over all space orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LengthDistortion(norm,**kwargs):\n",
    "    p = HalfSphereSampling(norm.vdim,**kwargs)\n",
    "    Np = norm.norm(p)\n",
    "    return np.max(Np)/np.min(Np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mica medium has a length distortion of approximately $1.8$, which is large for a geological material (that is because mica is a crystal). Note that, with other types of norms, the HFM library routinely handles norms with length distortion exceeding $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.826531520777687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LengthDistortion(norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By construction, length distortion is invariant under rotation of the norm. The (very small) difference arises because we use a finite sampling of the sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8270304991351363"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LengthDistortion(norm2.rotate_by(np.pi/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because mica is transversally isotropic, the length distortion of the three dimensional mica norm is equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8283196290043455"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LengthDistortion(norm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Riemannian norms, the length distortion can be computed in closed form, and is provided as the `anisotropy` member function. (In contrast, there is no simple closed form expression for the anisotropy of `Hooke` norms to our knowledge, and the `anisotropy` method is thus not implemented.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm : riemann2. Length distortion : approximate 2.9993730212254377, exact 2.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "name,norm = norms2[0]\n",
    "print(f\"Norm : {name}. Length distortion : approximate {LengthDistortion(norm)}, exact {norm.anisotropy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm riemann2. Length distortion 2.9993730212254377\n",
      "Norm mica2. Length distortion 1.8240126561699308\n",
      "Norm stishovite2. Length distortion 1.308367631573457\n",
      "Norm mudshale2. Length distortion 1.06979299782106\n",
      "Norm mica3. Length distortion 1.8282899187030757\n",
      "Norm stishovite3. Length distortion 1.3084655222014125\n"
     ]
    }
   ],
   "source": [
    "for name,norm in norms2+norms3:\n",
    "    print(f\"Norm {name}. Length distortion {LengthDistortion(norm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Angular distortion\n",
    "\n",
    "The Fast-Marching method relies on a *causality property*, ensuring that the front arrival time at a given point can be computed in terms of neighbors earlier reached, and thus that the non-linear system of equations discretizing the PDE can be solved in a single pass.\n",
    "\n",
    "For `Hooke` norms, we rely on a semi-lagrangian discretization of the eikonal equation, based on fixed stencils (illustrated below). In this context, the *causality property* follows from a geometrical *acuteness property*, as already observed by Sethian et al. The acuteness property requires that \n",
    "$$\n",
    "    \\Theta(N) + \\Theta(V) < \\pi/2,\n",
    "$$\n",
    "where $N$ is the norm, and $V$ is the stencil used for the PDE discretization.\n",
    "We denoted:\n",
    "* $\\Theta(N)$ the angular distortion of the norm, defined as the largest (unoriented) angle between $p$ and $\\nabla N(p)$, for each non-zero vector $p$. (By homogeneity, it suffices to consider the unit sphere, and by symmetry the half unit sphere.)\n",
    "* $\\Theta(V)$ the angular width of the stencil, defined as the largest (unoriented) angle between two vertices of a facet of the stencil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some standard stencils are illustrate below, whose angular width $\\Theta(V)$ is easily computed:\n",
    "\n",
    "Stencil | Dimension | Angular width $\\Theta(V)$\n",
    "--- | --- | ---\n",
    "Square | 2 | $\\pi/4$\n",
    "Cut-cube | 3 | $\\pi/3$\n",
    "Cube | 3 | $0.955..$\n",
    "Spiky-cube | 3 | $\\pi/4$\n",
    "\n",
    "(The exact angular width of the cube stencil is $\\arccos(1/\\sqrt 3)$.)\n",
    "\n",
    "**In practice, for `Hooke` norms.** Most geologic materials are only midly anisotropic, so that the square stencil can be used in two dimensions, and the cut-cube in three dimensions. This is not true however of crystals, such as mica which exhibits stronger anisotropy and require more the refined spiky-cube stencil in three dimensions. \n",
    "\n",
    "**In practice, for strongly anisotropic norms arising in other applications.** The use of fixed stencils is inadequate when the anisotropy is strong, and one must instead produce adaptive and anisotropic stencils, using mathematical tools such as the [Stern-Brocot tree](SternBrocot.ipynb) and [Voronoi vectors](VoronoiVectors.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Illustrations/SeismicNorm/FixedStencils.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The angular distortion of a norm is numerically evaluated by the next function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AngularDistortion(norm,**kwargs):\n",
    "    p = HalfSphereSampling(norm.vdim,**kwargs)\n",
    "    dNp = norm.gradient(p)\n",
    "    ratio = lp.dot_VV(p,dNp)/np.linalg.norm(dNp,ord=2,axis=0)\n",
    "    return np.arccos(np.min(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The angular distortion of the mica medium is less than $\\pi/4$, which allows using the square stencil (in two dimensions), and the spiky cube stencil (in three dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angular distortion of mica : 0.7509887694791147, pi/4 : 0.7853981633974483\n"
     ]
    }
   ],
   "source": [
    "μ = AngularDistortion(norm2)\n",
    "print(f\"Angular distortion of mica : {μ}, pi/4 : {np.pi/4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that angular distortion is invariant under rotation (up to numerical accuracy due to the finite sampling of the sphere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7497254150260351"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AngularDistortion(norm2.rotate_by(1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mica medium is transversally isotropic, the angular distortion of the three dimensional medium is identical (again up to numerical accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528581192017458"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AngularDistortion(norm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angular distortion is bounded in terms of the Length distortion : one has \n",
    "$$\n",
    "\\mu(N) \\cos \\Theta(N) \\geq 1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3352210770062627"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LengthDistortion(norm2) * np.cos(AngularDistortion(norm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of Riemannian metrics, the angular distortion has a closed form expression, as does the length distortion, and they are related by $(\\mu(N)+\\mu(N)^{-1})\\cos \\Theta(N) = 2$. Let us check this expression numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm riemann2. Angular distortion : approximate 0.9272937826526069, exact 0.9272952180016121 \n"
     ]
    }
   ],
   "source": [
    "name,norm = norms2[0]\n",
    "μ = norm.anisotropy()\n",
    "Θ = AngularDistortion(norm)\n",
    "print(f\"Norm {name}. Angular distortion : approximate {Θ}, exact {np.arccos(2/(μ+1/μ))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm riemann2. Angular distortion 0.9272937826526069\n",
      "Norm mica2. Angular distortion 0.7521110091600802\n",
      "Norm stishovite2. Angular distortion 0.3126982198178143\n",
      "Norm mudshale2. Angular distortion 0.12435235682165878\n",
      "Norm mica3. Angular distortion 0.7528596773866241\n",
      "Norm stishovite3. Angular distortion 0.34104154422640154\n"
     ]
    }
   ],
   "source": [
    "for name,norm in norms2+norms3:\n",
    "    print(f\"Norm {name}. Angular distortion {AngularDistortion(norm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper bound on the angular width $\\Theta(N)$ for the applicability of the fast-marching method with the cut-cube stencil, in three dimensions, is \n",
    "$\\pi/2 - \\Theta(\\text{cut-cube}) = \\pi/6$. As mentioned above, it is satisfied for all common geological materials, except crystals (such as mica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5235987755982988"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convexity of the constraint\n",
    "\n",
    "In this section, we discuss in more detail the computational aspects of `Hooke` norms. \n",
    "For that purpose, let us fix a Hooke tensor $c$ of components $c_{ijkl}$ where $i,j,k,l \\in \\{1,\\cdots,d\\}$.\n",
    "\n",
    "\n",
    "**Definition of the `Hooke` norm.**\n",
    "For each vector $v \\in R^d$ define a $d \\times d$ symmetric matrix $m(v)$ of components \n",
    "$$\n",
    "    m_c(v)_{ik} = \\sum_{j,l} c_{ijkl} v_j v_l.\n",
    "$$\n",
    "In view of energetic considerations, one assumes that the Hooke tensor $c$ is positive (in an appropriate sense), which implies that $m(v)$ is a positive semi-definite matrix for each $v \\in R^d$.\n",
    "\n",
    "The *dual norm* to a `Hooke` norm is defined as the square root of the largest eigenvalue of the matrix $m_c(v)$\n",
    "$$\n",
    "    N_c^*(v) := \\sqrt{\\lambda_{\\max}(m_c(v))},\n",
    "$$\n",
    "whereas the primal norm is defined dually, for all $w \\in R^d$\n",
    "$$\n",
    "    N_c(w) := \\max \\{<w,v>;\\ N_c^*(w) \\leq 1\\}.\n",
    "$$\n",
    "One can prove that $N_c^*$ is a norm, and in particular it is convex, so that $N_c$ is defined as the maximization of a linear objective function subject to a convex constraint.\n",
    "\n",
    "**Efficient numerical computation.**\n",
    "Despite being well posed, the above definition of $N_c$ is not very tractable numerically, due to the complex and costly evaluation of $N_c^*$.\n",
    "Instead, let us define \n",
    "$$\n",
    "    f_c(v) := \\det(I - m_c(v)),\n",
    "$$\n",
    "so that the (closed) dual unit ball $B_c^*$ admits the equivalent characterizations\n",
    "$$\n",
    "B_c^* \n",
    ":= \n",
    "\\{v; N_c^*(v) \\leq 1\\}\n",
    "=\n",
    "\\text{CC}_0(\\{f_c(v) \\geq 0\\}),\n",
    "$$\n",
    "where $\\text{CC}_x(X)$ denotes the connected component of the point $x$ in the set $X$. We can thus rephrase the definition of $N_c$, with a slight abuse of notation, as \n",
    "$$\n",
    "    N_c(w) := \\{<w,v>;\\ f_c(v) \\geq 0,\\ v \\in \\text{CC}_0\\}.\n",
    "$$\n",
    "We have replaced the highly non-linear constraint $N^*_c(v)\\leq 1$ with the polynomial constraint $f_c(v) \\geq 0$, which is much more tractable numerically (in particular it is easy to differentiate). Note that $f_c$ is an in-homogeneous polynomial of degree $2d$ in $d$ variables, where $f\\in \\{2,3\\}$ is the dimension.\n",
    "\n",
    "**Convexity.** \n",
    "The dual norm $N_c^*$ is convex, as mentioned above, but properties of $f_c$ are slightly more subtle. \n",
    "One can show that:\n",
    "* $f_c$ is quasi-concave on a neighborhood of $B_c^*$. (In other words the set $\\{v \\in B_c^*; f_c\\geq \\lambda\\}$ is convex for all $\\lambda$.)\n",
    "* $f_c^{\\frac 1 d}$ is strongly concave on $B_c^*$. Note that this function in not defined outside $B_c^*$.\n",
    "* $\\exp(-\\alpha f_c)$ is strongly convex on a neighborhood of $B_c^*$, for sufficiently large $\\alpha$.\n",
    "\n",
    "The constraint function $f_c$ is a hidden method of the dual norm, evidenced below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(norm,v): return -norm._dual_level(v) # Constraint function f_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Quasi-concavity\n",
    "\n",
    "The dual unit ball $B_c^*$ is the connected component of the origin delimited by the level set $f_c=0$, shown red.\n",
    "As announced, the level sets of $\\{f_c\\geq \\lambda\\}$ within this region are convex, reflecting the quasi-concavity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aX = np.linspace(-0.3,0.3)\n",
    "X = np.array(np.meshgrid(aX,aX,indexing='ij'))\n",
    "X_ad = ad.Dense2.identity(constant=X,shape_free=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6)); plt.axis('equal');\n",
    "plt.title(\"The constraint is quasi convex, within the dual unit ball\")\n",
    "f = F(norm2,X)\n",
    "plt.contourf(*X,f,np.linspace(-0.2,1,10))\n",
    "plt.contour(*X,f,[0],colors='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $f_c$ however is *not* concave in $B_c^*$. Indeed, as illustrated below, the determinant of the hessian of $f_c$ changes sign in this region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6)); plt.axis('equal');\n",
    "plt.title(\"The constraint is not convex\")\n",
    "f_ad = F(norm2,X_ad)\n",
    "f = f_ad.value\n",
    "det_h = lp.det(f_ad.hessian())\n",
    "plt.contourf(*X,det_h)\n",
    "plt.contour(*X,det_h,[0])\n",
    "plt.contour(*X,f,[0],colors='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $f_c^{\\frac 1 d}$ is strongly concave in $B_c^*$, and indeed its hessian is negative definite in the interior of this region. However $f_c^{\\frac 1 d}$ is not very nice to use numerically due to the singularity on the boundary of $B_c^*$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmmir\\Documents\\GitHub\\AdaptiveGridDiscretizations\\Notebooks_Algo\\..\\agd\\AutomaticDifferentiation\\Base.py:42: RuntimeWarning: divide by zero encountered in power\n",
      "  def pow(x,n):\treturn (x**n,n*x**(n-1),(n*(n-1))*x**(n-2))\n",
      "C:\\Users\\jmmir\\Documents\\GitHub\\AdaptiveGridDiscretizations\\Notebooks_Algo\\..\\agd\\AutomaticDifferentiation\\Dense2.py:99: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self.new(a,_add_dim(b)*self.coef1,_add_dim2(b)*self.coef2+_add_dim2(c)*mixed)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6)); plt.axis('equal');\n",
    "plt.title(\"The constraint power 1/d is convex\")\n",
    "f_pow_ad = np.maximum(0,F(norm2,X_ad))**(1/norm.vdim)\n",
    "det_h_pow = lp.det(f_pow_ad.hessian())\n",
    "plt.contourf(*X,det_h_pow>0)\n",
    "plt.contour(*X,f_ad.value,[0],colors='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convexity of $\\exp(-\\alpha f_c)$.\n",
    "\n",
    "The function $\\exp(-\\alpha f_c)$ is known to be strongly convex on a neighborhood $B_c^*$, for sufficiently large $\\alpha$, but the theoretical analysis is not quantitative. \n",
    "The next function estimates numerically the lower bound on the values of $\\alpha$ which achieve this property.\n",
    "\n",
    "Note that the strong convexity of a smooth function $\\exp(-\\alpha f)$ is equivalent to the pointwise positive definiteness property\n",
    "$$\n",
    "    \\alpha \\nabla f \\nabla f^T - \\nabla^2 f \\succ 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LowerAlpha(norm,**kwargs):\n",
    "    # Evaluate the dual norm on the Euclidean sphere\n",
    "    p = HalfSphereSampling(norm.vdim,**kwargs)\n",
    "    norm_pp = norm.contract(p)\n",
    "    dual_norm = np.sqrt(np.linalg.norm(norm_pp,ord=2,axis=(0,1)))\n",
    "    \n",
    "    # Produce a sampling of the dual unit sphere, evaluate the constraint and derivatives\n",
    "    q = p/dual_norm \n",
    "    q_ad = ad.Dense2.identity(constant=q,shape_free=(norm.vdim,))\n",
    "    dual_level_ad = norm._dual_level(q_ad)\n",
    "    assert np.allclose(dual_level_ad.value,0) \n",
    "    \n",
    "    # Compute the minimal relaxation parameter\n",
    "    h = dual_level_ad.hessian()\n",
    "    g = dual_level_ad.gradient()\n",
    "    λ = ad.Dense.identity(constant=1.)\n",
    "    det_ad = lp.det(h + λ * lp.outer_self(g)) # Polynomial of degree one w.r.t λ\n",
    "    α = -det_ad.value/det_ad.coef\n",
    "    \n",
    "    return np.max(α)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the exponential $\\exp(-\\alpha f_c)$ takes rather extreme values, which makes this quantity unfriendly from the numerical point of view due to the risk of overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.129535935595019"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α = LowerAlpha(norm2)\n",
    "α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6));plt.axis('equal');\n",
    "exp_ad = np.exp(-α*F(norm2,X_ad))\n",
    "value = exp_ad.value\n",
    "det_h = lp.det(exp_ad.hessian())\n",
    "plt.contourf(*X,det_h)\n",
    "plt.contour(*X,det_h,[0])\n",
    "plt.contour(*X,value<=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, the hessian of $\\exp(-\\alpha f_c)$ is proportional to \n",
    "$$\n",
    "    \\alpha \\nabla f_c \\nabla f_c^T -\\nabla^2 f_c.\n",
    "$$\n",
    "We check in the following illustration that it is positive definite in the interior of $B_c^*$ with the value $\\alpha$ produced by the `LowerAlpha` function. In addition, this hessian degenerates on the boundary of $B_c^*$, showing that $\\alpha$ is indeed the lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal')\n",
    "f_ad = F(norm2,X_ad)\n",
    "v = f_ad.value\n",
    "g = f_ad.gradient()\n",
    "h = f_ad.hessian()\n",
    "det_h = lp.det(α*lp.outer_self(g)-h)\n",
    "plt.contourf(*X,det_h)\n",
    "plt.contour(*X,det_h,[0])\n",
    "plt.contour(*X,v,[0],colors='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm mica2. Lower bound on α 10.131242536881354\n",
      "Norm stishovite2. Lower bound on α 3.4964388394011783\n",
      "Norm mudshale2. Lower bound on α -0.055859493172704014\n",
      "Norm mica3. Lower bound on α 39.54924965107961\n",
      "Norm stishovite3. Lower bound on α 61.21863144072915\n"
     ]
    }
   ],
   "source": [
    "for name,norm in norms2[1:]+norms3:\n",
    "    print(f\"Norm {name}. Lower bound on α {LowerAlpha(norm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a parameter $\\alpha$ has been determined (as above) such that $\\alpha \\nabla f_c \\nabla f_c^T -\\nabla^2 f_c \\succ 0$, then it can be taken into account in the  Sequential Quadratically Constrained Programming (SQCP) routine used to compute the norm. This ensures that all inverted matrices are positive definite, and is in principle safer. Note that SQCP is an iterative method for solving problems of the form\n",
    "$$\n",
    "    \\max \\{<w,v>; f(v) \\leq 0\\},\n",
    "$$\n",
    "which is based on successively approximating $f$ with its second order Taylor expansion (indeed the exact solution of this problem is known in closed form when the constraint is quadratic).\n",
    "\n",
    "In numerical experiments, somewhat surprisingly, the SQCP method is rather insensitive to the parameter $\\alpha$, even when values are used that do not enforce the positive definiteness of $-\\nabla^2 f_c$ on $B_c^*$. In practice leaving this parameter to the default value $\\alpha=0$ appears to be fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qconv(norm,α,**kwargs):\n",
    "    norm_ = copy.copy(norm)\n",
    "    norm_.qconv_sqp = α # Parameter such that α grad(f_c) grad (f_c)^T - hess(f_c) > 0\n",
    "    norm_.niter_sqp = 12 # A few more iterations than default\n",
    "    p = HalfSphereSampling(norm.vdim,**kwargs)\n",
    "    return np.max(np.abs(norm.norm(p)-norm_.norm(p))) # Largest absolute error on unit ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound of α ensuring strong convexity :  10.129535935595019\n"
     ]
    }
   ],
   "source": [
    "print(\"Lower bound of α ensuring strong convexity : \", LowerAlpha(norm2))\n",
    "# Norm is correctly computed in both cases, with identical value\n",
    "assert check_qconv(norm2,60.)<1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound of α ensuring strong convexity :  39.549595453299936\n"
     ]
    }
   ],
   "source": [
    "print(\"Lower bound of α ensuring strong convexity : \", LowerAlpha(norm3))\n",
    "assert check_qconv(norm3,60.) <1e-12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm mica2, effect of $α$ 2.7755575615628914e-17\n",
      "Norm stishovite2, effect of $α$ 2.0816681711721685e-17\n",
      "Norm mudshale2, effect of $α$ 1.3552527156068805e-19\n",
      "Norm mica3, effect of $α$ 2.7755575615628914e-17\n",
      "Norm stishovite3, effect of $α$ 1.5265566588595902e-15\n"
     ]
    }
   ],
   "source": [
    "for name,norm in norms2[1:]+norms3:\n",
    "    print(f\"Norm {name}, effect of $α$ {check_qconv(norm,60.)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computation of a frame of reference\n",
    "\n",
    "Most materials arising in geology which are *anisotropic* inherit this property from a *layered structure*, which can have various and independent origins:\n",
    "* (Atom scale) In a crystal, due to the periodic arrangement of atoms.\n",
    "* (Centimeter scale) Successive deposits on the sea floor, whose constitutents may vary periodically.\n",
    "* (Kilometer scale) Fault interfaces produce anisotropic elastic response along them.\n",
    "\n",
    "If a frame of reference aligned with the layers is used, then the Hooke tensor typically takes a block-diagonal structure. Depending on the some shared coefficient values, the material symmetry is known as *hexagonal*, *tetragonal*, or *orthorombic*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mica in a frame of reference :\n",
      " [[178.   42.4  14.5   0.    0.    0. ]\n",
      " [ 42.4 178.   14.5   0.    0.    0. ]\n",
      " [ 14.5  14.5  54.9   0.    0.    0. ]\n",
      " [  0.    0.    0.   12.2   0.    0. ]\n",
      " [  0.    0.    0.    0.   12.2   0. ]\n",
      " [  0.    0.    0.    0.    0.   67.8]]\n",
      "\n",
      "Mudshale in a frame of reference :\n",
      " [[21906646.  5949886. 11051999.        0.        0.        0.]\n",
      " [ 5949886. 21906646. 11051999.        0.        0.        0.]\n",
      " [11051999. 11051999. 20511841.        0.        0.        0.]\n",
      " [       0.        0.        0.  7306209.        0.        0.]\n",
      " [       0.        0.        0.        0.  7306209.        0.]\n",
      " [       0.        0.        0.        0.        0.  7978380.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mica in a frame of reference :\\n\", Hooke.mica[0].hooke)\n",
    "print(\"\\nMudshale in a frame of reference :\\n\",Hooke.from_ThomsenElastic(\n",
    "    Thomsen.ThomsenData[\"Mesaverde (4903) mudshale\"])[0].hooke.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dimension $d=2$, the reference structure of interest is built of a $2\\times 2$ block, and an additional diagonal coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178. ,  14.5,   0. ],\n",
       "       [ 14.5,  54.9,   0. ],\n",
       "       [  0. ,   0. ,  12.2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hooke.mica[0].extract_xz().hooke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a rotation is applied to the medium, this block structure lost, is obviously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128.3,  36.8,  39.4,  -0.2, -43.1,   3. ],\n",
       "       [ 36.8, 176.9,  20.6,   7.6, -10.9,   3.8],\n",
       "       [ 39.4,  20.6,  54.9,   0.9,  -6.3,  -2.6],\n",
       "       [ -0.2,   7.6,   0.9,  23.9,  -1.9, -22. ],\n",
       "       [-43.1, -10.9,  -6.3,  -1.9,  37.2,   1.3],\n",
       "       [  3. ,   3.8,  -2.6, -22. ,   1.3,  56.5]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm3.hooke.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Hooke` class can handle general elliptic Hooke tensors, hence the frame of reference has no particular interest to it. However there are other numerical methods, such as the `TTI` (Tilted Transversally Isotropic) class of geological materials in the `agd` library, which require it. The frame of reference is often not available in the input data, if for instance it arises from the homogeneization of a complex material, and therefore it must be approximated or computed. \n",
    "\n",
    "Inspired by works of Paul Cupillard, we propose to approximate a frame of reference using numerical optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def proj_orthorombic(c):\n",
    "    \"\"\"Project onto the vector space of Hooke tensors corresponding to orthorombic materials in their frame of reference\"\"\"\n",
    "    to_orthorombic = (c[0,0],c[0,1],c[0,2],c[1,1],c[1,2],c[2,2],c[3,3],c[4,4],c[5,5]) # Seismologists start at 1 ...\n",
    "    return Hooke.from_orthorombic(*to_orthorombic).hooke\n",
    "\n",
    "def frame_score(c,proj,r):\n",
    "    \"\"\"Score for wether c coincides with its projection in the frame defined by r\"\"\"\n",
    "    c = c.rotate(lp.transpose(r)) # Put in specified frame\n",
    "    c.hooke -= proj(c.hooke) # Substract projection \n",
    "    return (c.to_Mandel()**2).sum(axis=(0,1)) # Return frobenius norm squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By construction, the score vanishes if the correct frame is produced, and is positive otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanishing score in the correct frame :  9.260333492096982e-27\n",
      "Positive score otherwise :  14066.444179546052\n"
     ]
    }
   ],
   "source": [
    "r = lp.rotation(np.pi/3,axis=(1,2,3))\n",
    "norm = Hooke.mica[0].rotate(r)\n",
    "print(\"Vanishing score in the correct frame : \",frame_score(norm,proj_orthorombic,r))\n",
    "print(\"Positive score otherwise : \",frame_score(norm,proj_orthorombic,np.eye(3)))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reference frame reconstruction problem for a Hooke tensor thus be rephrased as \n",
    "$$\n",
    "    min_{r \\in SO_d} f(r),\n",
    "$$\n",
    "where $f(r) = $`frame_score(norm,proj_orthorombic,r)`. Alternatively, projections onto the hexagonal and tetragonal symmetries may be used as well.\n",
    "\n",
    "One may parametrize direct rotations from a sphere\n",
    "* by their first column, which belongs to $S^1$, in dimension two. (This is a bijection.)\n",
    "* by the corresponding unit quaternion, which belongs to $S^3$, in dimension three. (This is a double cover.)\n",
    "\n",
    "Using this quadratic parametrization $R : S^n \\to SO_d$, we obtain a sphere constrained optimization problem, in four variables in dimension three (resp. two variables in dimension two). The objective function is a polynomial of degree $2 \\times 4 \\times 2 = 16$. There exists global methods for such problems, based on positive definite relaxations, but we shall not use them here now.\n",
    "Instead, we content ourselves with a combination of exhaustive search and Newton optimization. The sphere itself is parametrized by the equatorial projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Alternative projections\n",
    "\n",
    "In addition to the three dimensional orthorombic materials, the hexagonal and tetragonal symmetries are also of interest, as well as the (2,1) block diagonal structure in two dimensions. Projections on these spaces of matrices are needed to optimize the corresponding frame.\n",
    "We use orthogonal projections in the Frobenius scalar product associated with the Mandel form of the Hooke tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def proj_hooke2(c):\n",
    "    \"\"\"Project onto the vector space of Hooke tensors with (2,1) block diagonal structure\"\"\"\n",
    "    z = np.zeros_like(c[0,0])\n",
    "    return ad.array([\n",
    "        [c[0,0],c[0,1],     z],\n",
    "        [c[1,0],c[1,1],     z],\n",
    "        [     z,     z,c[2,2]] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def proj_tetragonal(c):\n",
    "    \"\"\"Tetragonal Hooke tensors share the coefficients c11=c22, c13=c23, c44=c55\"\"\"\n",
    "    c11,c12,c13,c22,c23,c33,c44,c55,c66 = ( # Seismologists start at 1 ...\n",
    "        c[0,0],c[0,1],c[0,2],c[1,1],c[1,2],c[2,2],c[3,3],c[4,4],c[5,5])\n",
    "    α=(c11+c22)/2\n",
    "    γ=(c13+c23)/2\n",
    "    δ=(c44+c55)/2\n",
    "    return Hooke.from_orthorombic(α,c12,γ,α,γ,c33,δ,δ,c66).hooke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def proj_hexagonal(c):\n",
    "    \"\"\"Hexagonal Hooke tensors are tetragonal, with the additional property that c66=(c11-c12)/2\"\"\"\n",
    "    c11,c12,c13,c22,c23,c33,c44,c55,c66 = ( # Seismologists start at 1 ...\n",
    "        c[0,0],c[0,1],c[0,2],c[1,1],c[1,2],c[2,2],c[3,3],c[4,4],c[5,5])\n",
    "    α=(3*(c11+c22)+2*c12+4*c66)/8\n",
    "    β=(c11+c22+6*c12-4*c66)/8\n",
    "    γ=(c13+c23)/2\n",
    "    δ=(c44+c55)/2\n",
    "    return Hooke.from_orthorombic(α,β,γ,α,γ,c33,δ,δ,(α-β)/2).hooke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Optimization routines\n",
    "\n",
    "We parametrize rotations from the unit ball, via quaternions in dimension three, and the simple angular parametrization in dimension two.\n",
    "A roughly uniform sampling of the unit ball is produced by an adequate function.\n",
    "\n",
    "The frame score is extremized via a Newton method, in a purely naive manner : no adaptive stepping is used, and no check of the positive definiteness of the Hessian. We look for a *minimum* of the frame score, but the method is blind to this, and it actually converges a local *maximum* in a large proportion of cases. Nevertheless, if one uses enough seeds, one of them is in practice usually caught in the attraction basin of the optimal frame, which is found by the Newton method, and is eventually selected and returned.\n",
    "\n",
    "<!---\n",
    "# Attempt to eliminate matrices with excessive condition number. Not very convincing.\n",
    "def newton_extremize(f,x,niter,max_cond=1e20):\n",
    "    \"\"\"\n",
    "    Runs niter steps of Newton's method for extremizing f. \n",
    "    (A.k.a, solve grad(f) = 0)\n",
    "    \"\"\"\n",
    "    x_ad = ad.Dense2.identity(constant=x,shape_free=(len(x),))\n",
    "    for i in range(niter):\n",
    "        f_ad = f(x_ad)\n",
    "        H = f_ad.hessian(); \n",
    "        bad=np.linalg.cond(np.moveaxis(H,(0,1),(-2,-1)))>max_cond\n",
    "        H[:,:,bad]=np.nan             \n",
    "        x_ad.value -= lp.solve_AV(H,f_ad.gradient())\n",
    "    return x_ad.value,f_ad.value\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def rotation_from_ball(x):\n",
    "    \"\"\"\n",
    "    Produces a rotation matrix from an element of the unit ball\n",
    "    B_3 -> S_3 (lower half) -> SO_3, via quaternions\n",
    "    B_1 -> SO_2, via rotation of angle pi*x\n",
    "    \"\"\"\n",
    "    if   len(x)==3: return Sphere.rotation3_from_ball3(x)[0] \n",
    "    elif len(x)==1: return lp.rotation(np.pi*x[0])\n",
    "    else: raise ValueError(\"Unsupported dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation \n",
      "[[-0.58778525 -0.80901699]\n",
      " [ 0.80901699 -0.58778525]]\n",
      " with parameter [0.7]\n",
      "\n",
      "Rotation \n",
      "[[-0.76802317 -0.60051821  0.22252705]\n",
      " [-0.25301021  0.60371895  0.75598232]\n",
      " [-0.58832495  0.52431032 -0.61560738]]\n",
      " with parameter [-0.2, 0.7, 0.3]\n"
     ]
    }
   ],
   "source": [
    "x=[0.7]; print(f\"Rotation \\n{rotation_from_ball(x)}\\n with parameter {x}\\n\")\n",
    "x=[-0.2,0.7,0.3]; print(f\"Rotation \\n{rotation_from_ball(x)}\\n with parameter {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def ball_samples(vdim,dens):\n",
    "    \"\"\"\n",
    "    Produce samples of the unit ball of dimension vdim.\n",
    "    Approx c(vdim) * dens^vdim elements.\n",
    "    \"\"\"\n",
    "    aB,h = np.linspace(-1,1,dens,retstep=True,endpoint=False)\n",
    "    B = np.array(np.meshgrid(*(aB,)*vdim,indexing='ij'))\n",
    "    B += h*np.random.rand(*B.shape) # Add random perturbations\n",
    "    B = B[:,np.linalg.norm(B,axis=0)<=1]\n",
    "    return B.reshape(vdim,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Uniform sampling of the unit ball'); plt.axis('equal')\n",
    "plt.scatter(*ball_samples(2,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def newton_extremize(f,x,niter,max_cond=1e10):\n",
    "    \"\"\"\n",
    "    Runs niter steps of Newton's method for extremizing f. \n",
    "    (A.k.a, solve grad(f) = 0)\n",
    "    \"\"\"\n",
    "    x_ad = ad.Dense2.identity(constant=x,shape_free=(len(x),))\n",
    "    for i in range(niter):\n",
    "        f_ad = f(x_ad)\n",
    "#        print(np.linalg.eigvalsh(f_ad.coef2[0]))\n",
    "        x_ad.value -= lp.solve_AV(f_ad.hessian(),f_ad.gradient())\n",
    "    return x_ad.value,f_ad.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def hooke_frame(c,proj,dens=8,niter=8):\n",
    "    \"\"\"\n",
    "    Optimize the frame score, via a Newton method, with a large number of initial seeds.\n",
    "    Return the best rotation and associated score.\n",
    "    \"\"\"\n",
    "    def f(x): return frame_score(c,proj,rotation_from_ball(x))\n",
    "    x = ball_samples({2:1,3:3}[c.vdim],dens) \n",
    "    x,f_x = newton_extremize(f,x,niter)\n",
    "    argmin = np.nanargmin(f_x)\n",
    "    return lp.transpose(rotation_from_ball(x[:,argmin])),f_x[argmin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooke tensor : \n",
      "[[154.88711806  26.86228904  35.4467799 ]\n",
      " [ 26.86228904  53.28830387  -0.69303566]\n",
      " [ 35.4467799   -0.69303566  24.56228904]]\n",
      "found to be block diagonal in frame : \n",
      "[[-0.95533649 -0.29552021]\n",
      " [ 0.29552021 -0.95533649]],\n",
      "with score : 2.839899258795643e-28.\n",
      "In this frame of reference : \n",
      "[[ 1.78000000e+02  1.45000000e+01 -8.88178420e-15]\n",
      " [ 1.45000000e+01  5.49000000e+01  3.55271368e-15]\n",
      " [-7.10542736e-15  0.00000000e+00  1.22000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "r,score = hooke_frame(norm2,proj_hooke2,dens=8)\n",
    "print(f\"Hooke tensor : \\n{norm2.hooke}\\nfound to be block diagonal in frame : \\n{r},\\nwith score : {score}.\")\n",
    "print(f\"In this frame of reference : \\n{norm2.rotate(r).hooke}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, a frame of reference with a negligible score residual is found for all our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooke tensor mica2 found frame [[-0.93203909  0.36235775]\n",
      " [-0.36235775 -0.93203909]] with score 1.404172411293401e-28.\n",
      "Hooke tensor stishovite2 found frame [[ 0.87758256 -0.47942554]\n",
      " [ 0.47942554  0.87758256]] with score 4.038967834731581e-27.\n",
      "Hooke tensor mudshale2 found frame [[ 0.87758256 -0.47942554]\n",
      " [ 0.47942554  0.87758256]] with score 1.7347234759768074e-17.\n"
     ]
    }
   ],
   "source": [
    "for name,norm in norms2[1:]:\n",
    "    r,score = hooke_frame(norm,proj_hooke2,dens=8)\n",
    "    print(f\"Hooke tensor {name} found frame {r} with score {score}.\")\n",
    "    assert score<1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Three dimensions\n",
    "\n",
    "**Note on performance.**\n",
    "The numerical code presented below is too slow to be usable in practice, but could easily be (greatly) optimized. A lot of overhead is related with instance creation within the custom automatic differentiation library. A gpu accelerated code, orders of magnitude faster, is presented at the end of this document.\n",
    "\n",
    "**Note on robustness.**\n",
    "The `np.linalg.solve` fails in to the presence of singular matrices. We often encounter these, since we run a Newton method on a rather arbitrary (polynomial) function, without any guarantees, and from many seed points. An easy fix would be to abort the Newton method for all those seed points which raise such a singular matrix exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44) # Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.44843438, -0.06173864,  0.89168097],\n",
       "        [ 0.6000095 , -0.71863157, -0.35150714],\n",
       "        [ 0.66249166,  0.69264494, -0.28521533]]),\n",
       " 1.0797573699555442e-26)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooke_frame(norm3,proj_orthorombic,dens=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooke tensor mica3 found frame [[ 0.96705012  0.20405886 -0.15223022]\n",
      " [ 0.19169447 -0.97712804 -0.09205447]\n",
      " [-0.16753295  0.05983959 -0.98404875]] with score 4.5228570847621514e-27.\n",
      "Hooke tensor stishovite3 found frame [[-0.78550544  0.19978664  0.5857188 ]\n",
      " [-0.34276047 -0.92847926 -0.14297383]\n",
      " [ 0.5152635  -0.31306797  0.79780447]] with score 2.4105064908657414e-25.\n"
     ]
    }
   ],
   "source": [
    "for name,norm in norms3:\n",
    "    r,score = hooke_frame(norm,proj_orthorombic,dens=5)\n",
    "    print(f\"Hooke tensor {name} found frame {r} with score {score}.\")\n",
    "    assert score<1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 GPU acceleration of the TTI projection\n",
    "\n",
    "In order to apply the above projection to meaningful test cases for seimic applications, which involve millions of Hooke tensors, computation time must be sped up dramatically. \n",
    "\n",
    "The proposed GPU implementation is based on : \n",
    "- the treatment of each different hooke Tensor in a different thread, in an embarassingly parallel manner\n",
    "- a specific optimization in dimension 3, taking advantage of the invariance of VTI metrics subject to rotations along the z-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ad.Base.cp is None: raise ad.DeliberateNotebookError(\"Cupy library not found\")\n",
    "from agd.Eikonal.HFM_CUDA.ProjectionTTI import ProjectionTTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_packages():\n",
    "    from Miscellaneous.rreload import rreload\n",
    "    global ad,ProjectionTTI\n",
    "    Hooke,ad,ProjectionTTI, = rreload([Hooke,ad,ProjectionTTI],rootdir=\"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Taking advantage of VTI rotational invariance\n",
    "\n",
    "**Three dimensions.**\n",
    "Let us consider a material which does *not* have a TTI structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Hooke.olivine[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And introduce the following rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = lp.rotation(0.8,(1,2,3)) # Some arbitrary rotation\n",
    "def rx(θ): return lp.rotation(θ,(1,0,0)) # A rotation along the x-axis\n",
    "def ry(θ): return lp.rotation(θ,(0,1,0)) # A rotation along the y-axis\n",
    "def rz(θ): return lp.rotation(θ,(0,0,1)) # A rotation along the z-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the objective is to find a frame which minimizes the VTI projection error.\n",
    "However, since the set of VTI tensors is invariant under the action of rotations along the z-axis, the projection error also is.\n",
    "\n",
    "We also have some invariance by symmetry around the $x$ and $y$-axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [frame_score(norm,proj_hexagonal,r0 @ rx(θx) @ ry(θy) @ rz(θz))\n",
    "          for θx in (0,np.pi) for θy in (0,np.pi) for θz in np.linspace(0,np.pi,10)]\n",
    "assert np.allclose(scores,scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any rotation matrix can be written as the composition\n",
    "$$\n",
    "    r(\\theta_x,\\theta_y,\\theta_z) := r_x(\\theta_x) r_y(\\theta_y) r_z(\\theta_z)\n",
    "$$\n",
    "of three rotations around the $x$, $y$ and $z$ axes.\n",
    "\n",
    "Based on the above invariance property, if one wants to optimize the TTI projection error, then it is sufficient to optimize the parameter $\\theta_x\\in [0,\\pi]$ and $\\theta_y \\in [0,\\pi]$, and one can set $\\theta_z=0$. \n",
    "\n",
    "Note that rotations along the $x$ and $y$ axes do not commute, but we have the identity\n",
    "$$\n",
    "    r_x(\\pi) r_y(\\theta_y) = r_y(-\\theta_y) r_x(\\pi).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two dimensions.** There is a weaker invariance property, which that the set of VTI tensors is invariant under a rotation of $\\pi/2$, exchanging the roles of the $x$ and $y$ axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Validation tests\n",
    "\n",
    "Since the implementation is embarassingly parallel, the computation time does not increase much until the number of Hooke tensors exceeds the number of threads of the GPU (about 2560 on a GTX 1080)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "norm = Hooke.olivine[0]\n",
    "nrand = 2500\n",
    "angle = np.random.uniform(0,np.pi,nrand)\n",
    "axis = np.random.uniform(size=(3,nrand))\n",
    "norms = norm.rotate_by(angle,axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398.52292 398.52243 398.52237 398.5226  398.52246 398.52267 398.52206\n",
      " 398.52283 398.52234 398.52252]\n",
      "CPU times: total: 2.84 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score,hexa,rotation = ProjectionTTI(norms.hooke)\n",
    "print(score[:10]) # Do not remove, otherwise false timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this special case, we applied random rotations to a fixed norm. But then we inverse that process by finding the optimal frame of reference. As a result, the obtained TTI projection errors are all identical.\n",
    "(Note that there is some amount of roundoff error, since the Hooke tensor coefficients are rather large, and the GPU uses single precision.)\n",
    "\n",
    "Note that the original rotations, with the angles and axes defined above, *cannot* recovered, because of the $z$ rotational invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.00195312, dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(score-score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(score,score[0],atol=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recover the projection error scores defined in this notebook, up to a factor two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = 0.5*frame_score(norms,proj_hexagonal,rotation.get())\n",
    "assert np.allclose(score2,score[0],atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tti_approx = Hooke.from_hexagonal(*hexa).rotate(rotation)\n",
    "tti_approx = Hooke(tti_approx.hooke.get())\n",
    "score3 = 0.5*np.sum( (tti_approx.to_Mandel()-norms.to_Mandel())**2,axis=(0,1) )\n",
    "assert np.allclose(score3,score[0],atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a TTI metric from the output of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTI.from_hexagonal(*hexa).rotate(rotation);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the ProjectionTTI implementation uses optimization over two angles. The quaternion approach was also implemented, for reproducibility, but it is slower and there should be no good reason to use it at this time. (The quaternion approach may be used in the future to compute projections onto a sets of Hooke tensors which are not $z$ rotationally invariant, such as orthorombic tensors.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398.52292 398.52243 398.52237 398.5226  398.52246 398.52267 398.52206\n",
      " 398.52283 398.52234 398.52252]\n",
      "CPU times: total: 3.05 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_quat,hexa,rotation = ProjectionTTI(norms.hooke,quaternion=True)\n",
    "print(score[:10]) # Do not remove, otherwise false timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By construction, the projection error is the same. However the rotations are expected to differ from the previous ones, again due to $z$ rotational invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(score_quat,score[0],atol=0.05)\n",
    "tti_approx = Hooke.from_hexagonal(*hexa).rotate(rotation)\n",
    "tti_approx = Hooke(tti_approx.hooke.get())\n",
    "score3 = 0.5*np.sum( (tti_approx.to_Mandel()-norms.to_Mandel())**2,axis=(0,1) )\n",
    "assert np.allclose(score3,score[0],atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test the two dimensional implementation.\n",
    "Since all classical two dimensional materials are TTI, we build a random positive definite Hooke tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "A = np.random.rand(3,3)-0.5\n",
    "norm = Hooke(A.T @ A + 0.3*np.eye(3))\n",
    "angles = 2*np.pi*np.random.rand(nrand)\n",
    "norms = norm.rotate_by(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00021021 0.00021021 0.00021021 0.00021021 0.00021021 0.00021021\n",
      " 0.00021021 0.00021021 0.00021021 0.00021021]\n",
      "CPU times: total: 391 ms\n",
      "Wall time: 391 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score,hexa,rotation = ProjectionTTI(norms.hooke)\n",
    "print(score[:10]) # Do not remove, otherwise false timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, since the same norm is subject to random rotations, the obtained projection errors are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(score,score[0],atol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = 0.5*frame_score(norms,proj_hooke2,rotation.get())\n",
    "assert np.allclose(score2,score[0],atol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tti_approx = Hooke.from_hexagonal(*hexa,vdim=2).rotate(rotation)\n",
    "tti_approx = Hooke(tti_approx.hooke.get())\n",
    "score3 = 0.5*np.sum( (tti_approx.to_Mandel()-norms.to_Mandel())**2,axis=(0,1) )\n",
    "assert np.allclose(score3,score[0],atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, one can build a TTI norm from the output of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTI.from_hexagonal(*hexa,vdim=2).rotate(rotation);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check visually the quality of the TTI approximation.\n",
    "In this case it is almost perfect. Note that exact reconstruction is not possible in general, since a two dimensional Hooke tensor is defined by $6$ parameters, whereas the TTI approximation is defined by $5$ parameters (4 coefficients and an angle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = 10\n",
    "c11,_,c13,c33,c44 = hexa\n",
    "c11,c13,c33,c44 = [x[i0].get() for x in (c11,c13,c33,c44)]\n",
    "tti0 = TTI.from_hexagonal(c11,None,c13,c33,c44,vdim=2).rotate(rotation[:,:,i0].get())\n",
    "norm0 = norm.rotate_by(angles[i0])\n",
    "\n",
    "#import cupy as cp\n",
    "aX = np.linspace(-1.2,1.2)\n",
    "X = np.meshgrid(aX,aX,indexing='ij')\n",
    "plt.axis('equal')\n",
    "plt.contour(*X,tti0.norm(X),levels=[1.01],colors='red') # Red : tti approximation\n",
    "plt.contour(*X,norm0.norm(X),levels=[1],colors='blue'); # Blue : original hooke tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, in contrast with the three dimensional case, one can recover the rotation angles, up to a multiple of $\\pi/2$ in view of the invariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,hexa,θ = ProjectionTTI(norms.hooke,ret_rot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = θ.get()+angles # Note the different sign conventions\n",
    "diff = (diff - diff[0])/(np.pi/2) # convert to quarter turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.max(np.abs(np.round(diff) - diff)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}