{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive PDE discretizations on Cartesian grids\n",
    "## Volume : Algorithmic tools\n",
    "## Part : Tensor decomposition techniques\n",
    "## Chapter : Selling's algorithm, in dimension 2 and 3\n",
    "\n",
    "This notebook presents some tensor decomposition techniques that are at the foundation of our anisotropic PDE discretizations on Cartesian grids. The general objective is to write a given symmetric positive definite matrix $D$ under the form\n",
    "$$\n",
    "    D = \\sum_{0 \\leq i < I} \\lambda_i e_i e_i^T. \n",
    "$$\n",
    "From this point, various numerical schemes can be designed, for both first order and second order, and both linear and non-linear PDEs.\n",
    "\n",
    "The techniques used for constructing the above decomposition are non-trivial, and are related to classical yet subtle tools of discrete geometry. This notebook is meant to illustrate some of their properties.\n",
    "\n",
    "This notebook is limited to dimensions $d\\in \\{2,3\\}$. Tensor decomposition in dimension $d \\in \\{4,5\\}$ requires another set of techniques (and in practice the call to a c++ library), which are discussed in [II Tensor decomposition, dimensions 4 and 5](TensorVoronoi.ipynb)\n",
    "\n",
    "**References**\n",
    "\n",
    "The tensor decomposition presented in this notebook is a central ingredient of the following paper:\n",
    "\n",
    "Fehrenbach, J., & Mirebeau, J.-M. (2014). Sparse non-negative stencils for anisotropic diffusion. Journal of Mathematical Imaging and Vision, 49(1), 123–147. http://doi.org/http://dx.doi.org/10.1007/s10851-013-0446-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Algorithmic tools, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. Decomposing a tensor, or a tensor field](#1.-Decomposing-a-tensor,-or-a-tensor-field)\n",
    "    * [1.1 Case of a $2\\times 2$ matrix](#1.1-Case-of-a-$2\\times-2$-matrix)\n",
    "    * [1.2 Case of a $3 \\times 3$ matrix.](#1.2-Case-of-a-$3-\\times-3$-matrix.)\n",
    "    * [1.3 Case of (extremely) strong anisotropy](#1.3-Case-of-(extremely)-strong-anisotropy)\n",
    "    * [1.4 Decomposition a field of symmetric tensors](#1.4-Decomposition-a-field-of-symmetric-tensors)\n",
    "  * [2. Under the hood : obtuse superbases](#2.-Under-the-hood-:-obtuse-superbases)\n",
    "    * [2.1 Two dimensions](#2.1-Two-dimensions)\n",
    "    * [2.2 Three dimensions](#2.2-Three-dimensions)\n",
    "  * [3. Properties of the decomposition](#3.-Properties-of-the-decomposition)\n",
    "    * [3.1 Offsets smallness](#3.1-Offsets-smallness)\n",
    "    * [3.2 Stability](#3.2-Stability)\n",
    "    * [3.3 Spanning property (no chessboard artifacts)](#3.3-Spanning-property-(no-chessboard-artifacts))\n",
    "    * [3.4 Piecewise linearity](#3.4-Piecewise-linearity)\n",
    "  * [4. Smooth decomposition](#4.-Smooth-decomposition)\n",
    "    * [4.1 Construction](#4.1-Construction)\n",
    "    * [4.2 Display of coefficients](#4.2-Display-of-coefficients)\n",
    "    * [4.3 Linear decomposition](#4.3-Linear-decomposition)\n",
    "    * [4.4 Automatic differentiation](#4.4-Automatic-differentiation)\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgement.** Some of the experiments presented in these notebooks are part of \n",
    "ongoing research with Ludovic Métivier and Da Chen.\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, Centre Borelli, ENS Paris-Saclay, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\") # Allow import of agd from parent directory (useless if conda package installed)\n",
    "#from Miscellaneous import TocTools; print(TocTools.displayTOC('TensorSelling','Algo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "from agd import LinearParallel as lp\n",
    "from agd import FiniteDifferences as fd\n",
    "from agd import Selling\n",
    "from agd.Plotting import savefig; #savefig.dirName = 'Figures/TensorSelling'\n",
    "from agd import AutomaticDifferentiation as ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library imported as **lp** is a set of routines meant to facilitate the manipulation of *numerous small vectors and matrices* simultaneously. It is based on numpy and implements  only a small number of linear algebra tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np; xp = np; allclose = np.allclose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Additional configuration\n",
    "\n",
    "Uncomment the following line to run the notebook on the GPU. (This only for compatibility testing, since no intensive computation is involved in this specific notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "GPU_config"
    ]
   },
   "outputs": [],
   "source": [
    "#xp,plt,allclose=map(ad.cupy_friendly,(xp,plt,allclose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decomposing a tensor, or a tensor field\n",
    "\n",
    "In order to illustrate our tensor decomposition facilities, we will rely on randomly generated *symmetric positive definite* tensors. They are built as \n",
    "$$\n",
    "    M = A^T A + \\varepsilon \\mathrm{Id}\n",
    "$$\n",
    "where $A$ has normalized random Gaussian entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def MakeRandomTensor(dim,shape = tuple(),relax=0.01):\n",
    "    identity = fd.as_field(np.eye(dim),shape,depth=2)\n",
    "    A = np.random.standard_normal( (dim,dim) + shape ) \n",
    "    M = lp.dot_AA(lp.transpose(A),A) + relax*identity\n",
    "    return xp.asarray(M) # Convert to GPU array if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, we fix the random seed\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Case of a $2\\times 2$ matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 2x2 random psd tensor\n",
    "D2 = MakeRandomTensor(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Selling.Decomposition** routine, applies to a symmetric positive definite matrix $D$ of size $d \\times d$, with $d\\leq 3$. It returns coefficients $\\lambda_i \\geq 0$ and offsets $e_i \\in Z^d$.\n",
    "\n",
    "A discussion on the inner workings of this decomposition is presented in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix can be reconstructed by the formula\n",
    "$$\n",
    "    D = \\sum_{0 \\leq i < I} \\lambda_i e_i e_i^T. \n",
    "$$\n",
    "\n",
    "<!---ExoFR\n",
    "Définissez une fonction qui reconstruit le tenseur D à partir de coefficients $(\\lambda_i)_{0\\leq i <I}$ et offsets $(e_i)_{0 \\leq i < I}$.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def Reconstruct(coefs,offsets):\n",
    "    \"\"\"\n",
    "    Input.\n",
    "     - coefs :   array of shape   (I,n1,...,nk)\n",
    "     - offsets : array of shape (d,I,n1,...,nk)\n",
    "    Output. \n",
    "     - D :       array of shape (d,d,n1,...,nk)\n",
    "    \"\"\"\n",
    "    return # TODO.\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "ExportCode"
    ]
   },
   "outputs": [],
   "source": [
    "def Reconstruct(coefs,offsets):\n",
    "     return (coefs*lp.outer_self(offsets)).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert allclose(D2,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $I = d(d+1)/2$ coefficients and offsets (a.k.a $I=3$ if $d=2$, and $I=6$ if $d=3$). Note that this is more than the similar-looking eigen-decomposition of a matrix, which uses only $d$ coefficients and unit vectors. However, Selling's offsets have integer entries, hence are suitable for the construction of finite difference schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selling decomposition of matrix : \n",
      " [[0.67622539 0.91777115]\n",
      " [0.91777115 2.34873696]]\n",
      "Coefficients :  [0.43467964 0.94787431 0.24154575]\n",
      "Offsets : \n",
      " [[-1  0  1]\n",
      " [-1 -1  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Selling decomposition of matrix : \\n\", D2)\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Decomposition offsets for the matrix D2\")\n",
    "plt.quiver(*np.zeros(offsets.shape),*offsets,angles='xy',scale_units='xy',scale=1);\n",
    "plt.scatter(*offsets); plt.scatter(*(-offsets));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Case of a $3 \\times 3$ matrix.\n",
    "\n",
    "As previously, we generate a 3x3 random psd tensor, decompose it and validate the absence of reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3 = MakeRandomTensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert allclose(D3,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selling decomposition of matrix : \n",
      " [[ 0.86853982 -0.08963958 -0.06552819]\n",
      " [-0.08963958  0.50213052 -0.73715916]\n",
      " [-0.06552819 -0.73715916  2.85683026]]\n",
      "Coefficients :  [0.15516777 0.08963958 0.62373247 0.23502864 1.49444606 0.1774623 ]\n",
      "Offsets : \n",
      " [[-1  1 -1  0  0  0]\n",
      " [ 0 -1  0  1  0 -1]\n",
      " [ 1  1  0 -2  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Selling decomposition of matrix : \\n\", D3)\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Case of (extremely) strong anisotropy\n",
    "\n",
    "Selling's tensor decomposition algorithm requires the matrix to be positive definite. It involves a loop, whose number of iterations grows to infinity as the matrix degenerates.\n",
    "\n",
    "A maximum number of iterations is set by default, to a reasonably large value, so that non-convergence is typically due to an error on the user's side - namely a non-positive matrix. \n",
    "\n",
    "In the following cell, we define the following matrix, which is positive definite but strongly anisotropic:\n",
    "$$\n",
    "    \\begin{pmatrix}\n",
    "    1 & \\varepsilon\\\\\n",
    "    \\varepsilon & 2 \\varepsilon^2\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct some matrix with extremely large condition number\n",
    "eps = 1/200.\n",
    "D2_bad = np.array([[1,eps],[eps,2*eps**2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the anisotropy direction of this matrix is *almost but not exactly* aligned with the coordinate axes, which is a worst case scenario for Selling's algorithm. As a result, Selling's algorithm fails to converge within the prescribed iteration limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Selling's algorithm did not terminate in iterMax2=100 iterations\",)\n"
     ]
    }
   ],
   "source": [
    "#Selling's decomposition does not terminate within the iteration limit\n",
    "try:\n",
    "    coefs,offsets = Selling.Decomposition(D2_bad)\n",
    "except ValueError as e:\n",
    "    print(e.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iteration limit of Selling's algorithm may be increased, so as to ensure correct termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selling.iterMax2 *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D2_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the resulting offsets are unlikely to be of use for any PDE discretization, since they are way too large. \n",
    "\n",
    "Note also that basis reduction techniques more efficient than Selling's algorithm are available for tensors with extremely large condition numbers. (E.g. Lagrange's algorithm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offsets : \n",
      " [[-99 100  -1]\n",
      " [ -1   1   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"offsets : \\n\", offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Decomposition a field of symmetric tensors\n",
    "\n",
    "Our implementation of Selling's algorithm automatically threads over dimensions deeper than two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 10x10 field of random 2x2 spd tensors\n",
    "D2_field = MakeRandomTensor(2,(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs, offsets = Selling.Decomposition(D2_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the matrix field is $(d,d, n_1,\\cdots,n_k)$, whereas the coefficients are $(I,n_1,\\cdots,n_k)$ and the offsets $(d,I,n_1,\\cdots,n_k)$ where $I = d (d+1)/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 10, 10), (3, 10, 10), (2, 3, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{D2_field.shape}, {coefs.shape}, {offsets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert allclose(D2_field,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Under the hood : obtuse superbases\n",
    "\n",
    "This section illustrates the main mathematical concept underlying Selling's decomposition, known as *obtuse superbases* of the lattice $Z^d$.\n",
    "\n",
    "A superbase of $Z^d$ is a special kind of coordinate system $(b_0,\\cdots,b_d)$, spanning the lattice of integer points and with some redundancy. More precisely, one requires\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    b_0+\\cdots+b_d &= 0,\\\\\n",
    "    \\det(b_1,\\cdots,b_d) &= \\pm 1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Such a superbase is said $D$-obtuse, where $D$ is a given $d\\times d$ symmetric positive definite matrix, if \n",
    "$$\n",
    "    <b_i,D b_j> \\leq 0\n",
    "$$\n",
    "for all distinct $i,j\\in \\{0,\\cdots,d\\}$.\n",
    "\n",
    "Sellings decomposition of a matrix $D \\in S_d^{++}$ is based Selling's formula applied to a $D$-obtuse superbase, which itself is produced by Selling's algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Two dimensions\n",
    "\n",
    "The following method applies Selling's algorithm to a given positive definite tensor $D \\in S_2^{++}$, producing a suitable superbase of $Z^2$.\n",
    "\n",
    "<!---ExoFR\n",
    "Implémenter l'algorithme de Selling, pour construire une superbase $D$-obtuse pour toute matrice symétrique définie positive $D$ donnée de taille $2 \\times 2$.\n",
    "\n",
    "On rappelle que si $(v_0,v_1,v_2)$ est une superbase qui n'est pas obtuse, donc satisfaisant $<v_i,D v_j> > 0$ où $\\{i,j,k\\}$ est une permutation de $\\{0,1,2\\}$, alors la règle de mise à jour Selling est \n",
    "$$\n",
    "    (v_0,v_1,v_2) \\gets (-v_i,v_j,v_i-v_j).\n",
    "$$\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def ObtuseSuperbase2(D,niter=100):\n",
    "    \"\"\"\n",
    "    Input.\n",
    "     - D :  array of shape (2,2)\n",
    "    Output : \n",
    "     - sb : array of shape (2,3)\n",
    "    \"\"\"\n",
    "    sb = np.array([[-1,-1],[1,0],[0,1]]) # here of shape (3,2), transposed in the end\n",
    "    for _ in range(niter):\n",
    "        for i,j,k in [(0,1,2),(0,2,1),(1,2,0)]:\n",
    "            # TODO : check if <sb_i, D sb_j> > 0\n",
    "            # in that case, apply the Selling update rule and break\n",
    "        else: \n",
    "            # All superbase angles are obtuse\n",
    "            return sb.T\n",
    "    raise ValueError(f\"Selling algorithm failed to converge in {niter} iterations\")\n",
    "\n",
    "# Try your code\n",
    "sb = ObtuseSuperbase2(D2)\n",
    "--->\n",
    "\n",
    "<!---\n",
    "def ObtuseSuperbase2(D,niter=100):\n",
    "    sb = np.array([[-1,-1],[1,0],[0,1]])\n",
    "    for _ in range(niter):\n",
    "        for i,j,k in [(0,1,2),(0,2,1),(1,2,0)]:\n",
    "            if lp.dot_VAV(sb[i],D,sb[j]) > 0:\n",
    "                sb[k] = sb[i]-sb[j]\n",
    "                sb[i] = -sb[i]\n",
    "                break\n",
    "        else: \n",
    "            return sb.T\n",
    "    raise ValueError(f\"Selling algorithm failed to converge in {niter} iterations\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = Selling.ObtuseSuperbase(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.,  2.],\n",
       "       [ 1., -0., -1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated superbase $(b_0,\\cdots,b_d)$ is designed to be $D$-obtuse. In other words to obey \n",
    "$$\n",
    "    <b_i,D b_j> \\leq 0\n",
    "$$\n",
    "for all distinct $i,j\\in \\{0,\\cdots,d\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2415457537440081, -0.4346796384446704, -0.9478743070679034]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lp.dot_VAV(sb[:,i],D2,sb[:,np.mod(i+1,3)]) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selling's formula yields the desired decomposition of the given symmetric positive definite matrix $D$\n",
    "$$\n",
    "    D = -\\sum_{0\\leq i<j \\leq d} <b_i,D b_j> v_{ij} v_{ij}^T,\n",
    "$$\n",
    "where one defines $v_{ij} = \\pm b_k^\\perp$ whenever $\\{i,j,k\\} = \\{0,1,2\\}$. \n",
    "\n",
    "Note that, \n",
    "* the weight of the decomposition are the negated scalar products, hence are non-negative.\n",
    "* the offsets of the decomposition are the superbase elements rotated by $\\pi/2$, hence have integer coordinates.\n",
    "\n",
    "<!---ExoFR\n",
    "Implémentez la formule de reconstruction de Selling, en dimension 2.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def Decomposition2(D):\n",
    "    coefs = []\n",
    "    offsets = []\n",
    "    for i,j,k in [(0,1,2),(0,2,1),(1,2,0)]:\n",
    "        coefs.append(   # TODO. Append coefficient\n",
    "        offsets.append( # TODO. Append offset\n",
    "    return np.array(coefs),np.array(offsets).T\n",
    "--->\n",
    "\n",
    "<!---\n",
    "def Decomposition2(D):\n",
    "    sb = ObtuseSuperbase2(D)\n",
    "    coefs = []\n",
    "    offsets = []\n",
    "    for i,j,k in [(0,1,2),(0,2,1),(1,2,0)]:\n",
    "        coefs.append(-lp.dot_VAV(sb[:,i],D,sb[:,j]))\n",
    "        offsets.append([sb[1,k],-sb[0,k]])\n",
    "    return np.array(coefs),np.array(offsets).T\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D2,sb=sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [0.43467964 0.94787431 0.24154575]\n",
      "Offsets : \n",
      " [[-1  0  1]\n",
      " [-1 -1  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to produce a tensor decomposition from an arbitrary superbase, but the coefficients are positive only if the superbase is obtuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [-0.91777115  3.26650811  1.59399654]\n",
      "Offsets : \n",
      " [[ 1  0 -1]\n",
      " [-1  1  0]]\n"
     ]
    }
   ],
   "source": [
    "sb = Selling.CanonicalSuperbase(D2) # Only takes the dimension an array type from the argument\n",
    "coefs,offsets = Selling.Decomposition(D2,sb=sb)\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(D2,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Three dimensions\n",
    "\n",
    "We follow similar steps in dimension $d=3$. Selling's algorithm, applied to the given matrix $D$, yields a specific superbase of $Z^3$.\n",
    "\n",
    "<!---ExoFR\n",
    "Implémenter l'algorithme de Selling, pour construire une superbase $D$-obtuse pour toute matrice symétrique définie positive $D$ donnée de taille $3 \\times 3$.\n",
    "\n",
    "On rappelle que si $(v_0,v_1,v_2,v_3)$ est une superbase qui n'est pas obtuse, donc satisfaisant $<v_i,D v_j> > 0$ où $\\{i,j,k,l\\}$ est une permutation de $\\{0,1,2,3\\}$, alors la règle de mise à jour Selling est \n",
    "$$\n",
    "    (v_0,v_1,v_2,v_3) \\gets (-v_i,v_j,v_k+v_i,v_l+v_i).\n",
    "$$\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def ObtuseSuperbase3(D,niter=100):\n",
    "    \"\"\"\n",
    "    Input.\n",
    "     - D :  array of shape (3,3)\n",
    "    Output : \n",
    "     - sb : array of shape (3,6)\n",
    "    \"\"\"\n",
    "    # TODO : reprendre et adapter ObtuseSuperbase2\n",
    "    raise ValueError(f\"Selling algorithm failed to converge in {niter} iterations\")\n",
    "\n",
    "# Try your code\n",
    "sb = ObtuseSuperbase3(D3)\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = Selling.ObtuseSuperbase(D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -0.,  0., -1.],\n",
       "       [ 0.,  1.,  1., -2.],\n",
       "       [ 0.,  1.,  0., -1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The superbase produced by Selling's algorithm is $D$-obtuse, similarly to the two dimensional case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1551677694190755,\n",
       " -0.08963958172347006,\n",
       " -0.2350286383841237,\n",
       " -0.6237324732734056,\n",
       " -1.4944460568297004,\n",
       " -0.1774622969114411]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lp.dot_VAV(sb[:,i],D3,sb[:,j]) for i in range(4) for j in range(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selling's formula yields the desired decomposition of the given positive definite matrix $D \\in S_3^{++}$:\n",
    "$$\n",
    "    D = -\\sum_{0\\leq i<j \\leq d} <b_i,D b_j> v_{ij} v_{ij}^T,\n",
    "$$\n",
    "where one defines $v_{ij} = \\pm b_k \\wedge b_l$ whenever $\\{i,j,k,l\\} = \\{0,1,2,3\\}$. \n",
    "\n",
    "Note that:\n",
    "* the weight of the decomposition are the negated scalar products, hence are non-negative.\n",
    "* the offsets of the decomposition are the cross-products of superbase elements (or their opposites), hence have integer entries.\n",
    "\n",
    "<!---ExoFR\n",
    "Implémenter la formule de décomposition de Selling en dimension $d=3$.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def Decomposition3(D):\n",
    "    \"\"\"\n",
    "    Input.\n",
    "     - D :       array of shape (3,3)\n",
    "    Output.\n",
    "     - coefs :   array of shape (6,)\n",
    "     - offsets : array of shape (3,6)\n",
    "    \"\"\"\n",
    "    coefs = []\n",
    "    offsets = []\n",
    "    # TODO : Reprendre et adapter Decomposition2\n",
    "    return np.array(coefs),np.array(offsets).T\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [0.15516777 0.08963958 0.62373247 0.23502864 1.49444606 0.1774623 ]\n",
      "Offsets : \n",
      " [[-1  1 -1  0  0  0]\n",
      " [ 0 -1  0  1  0 -1]\n",
      " [ 1  1  0 -2  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  0, -1,  1],\n",
       "       [ 1,  0,  0, -1,  1,  0],\n",
       "       [-1, -1,  0,  2, -1, -1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing with the cross products of the superbase elements.\n",
    "ad.array(\n",
    "    [lp.cross(sb[:,i],sb[:,j]) for i in range(4) for j in range(i)]\n",
    ").astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Properties of the decomposition\n",
    "\n",
    "Selling's decomposition of tensors, presented in this notebook, has a qualities that make it particularly suitable for PDE discretizations. More precisely, it is:\n",
    "* *Local*: The offsets appearing in the decomposition are typically small, and in any case bounded in terms of the anisotropy ratio of the matrix, see below.\n",
    "* *Stable*: The decomposition is unique, up to trivial transformations (reordering the offsets, and replacing some with their opposites). It is also stable, more precisely the coefficients are locally Lipschitz w.r.t. the decomposed matrix.  \n",
    "* *Spanning*: The offsets of the decomposition span $Z^d$ by linear relations with integer coordinates. In practice, this means that anisotropic PDE discretizations using this method should not produce chessboard artifacts. \n",
    "\n",
    "We denote the *anisotropy ratio* of a symmetric positive definite matrix $D$ by \n",
    "$$\n",
    "    \\mu(D) := \\sqrt{\\|D\\| \\|D^{-1}\\|}.\n",
    "$$\n",
    "In other words, this is the square root of the condition number of $D$.\n",
    "\n",
    "We illustrate these properties in dimension $d=2$, by considering the following family of matrices $D(\\theta,\\mu) \\in S_2^{++}$:\n",
    "$$\n",
    "    D(\\theta,\\mu) := \\mu^2 e(\\theta) e(\\theta)^T + e(\\theta)^\\perp (e(\\theta)^\\perp)^T,\n",
    "$$\n",
    "whose condition number is equal to $\\mu\\geq 1$, and whose anisotropy direction is aligned with the vector $e(\\theta):=(\\cos \\theta,\\sin \\theta)$, $\\theta \\in R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = xp.linspace(0,np.pi/2,100)\n",
    "μ = 10\n",
    "D2_rotating = (\n",
    "    μ**2 * lp.outer_self(xp.array([np.cos(θ),np.sin(θ)])) \n",
    "    + lp.outer_self(xp.array([-np.sin(θ),np.cos(θ)])) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D2_rotating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Offsets smallness \n",
    "\n",
    "The offsets $(e_i)_{1 \\leq i \\leq I}$ involved in Selling's decomposition of a tensor $D$ obey\n",
    "$$\n",
    "    \\|e_i\\| \\leq C \\mu(D),\n",
    "$$\n",
    "where $C$ is an absolute constant. \n",
    "\n",
    "<!---\n",
    "np.sqrt(np.sum(offsets**2,axis=0))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets_norms = xp.linalg.norm(offsets,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sqrt of condition number :  10\n",
      "Largest offset norm :  5.0990195135927845\n"
     ]
    }
   ],
   "source": [
    "print(\"Sqrt of condition number : \", μ)\n",
    "print(\"Largest offset norm : \", np.max(offsets_norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(θ,np.max(offsets_norms,axis=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stability\n",
    "\n",
    "We can rewrite Selling's decomposition in a manner independent of the a specific ordering of the offsets, as follows\n",
    "$$\n",
    "    D = \\sum_{e \\in Z^d} \\lambda^e(D) e e^T.\n",
    "$$\n",
    "One can then prove that the coefficient $\\lambda^e(D)$ of Selling's tensor decomposition, for a given offset $e \\in Z^d$, depends continuously on the parameter $D$, as illustrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = Selling.GatherByOffset(θ,coefs,offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "for offset,(angle,coef) in decomp.items():\n",
    "    plt.plot(angle,coef)\n",
    "plt.legend(decomp.keys(),ncol=3);\n",
    "savefig(fig,\"Coefs_Sel2_rot.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Spanning property (no chessboard artifacts)\n",
    "\n",
    "The lattice $Z^d$ is spanned, by integer combinations, by the offsets $(e_i)_{1 \\leq i \\leq I}$ appearing in the decomposition of an arbitrary p.s.d. tensor $D$. In other words, for all $x \\in Z^d$, there exists coefficients $k_1,\\cdots, k_I \\in Z$ such that \n",
    "$$\n",
    "    x = k_1 e_1 + \\cdots+ k_d e_d.\n",
    "$$\n",
    "In addition, one may select this decomposition so that the weight $\\lambda_i$ of $e_i$ is positive whenever $k_i \\neq 0$.\n",
    "\n",
    "This property guarantees that the graph underlying e.g. the discretization of an anisotropic laplacian is locally connected, hence that spurious modes such as chessboard artifacts will not appear. \n",
    "\n",
    "From a mathematical standpoint, the spanning property can be deduced from the construction of the decomposition in terms of obtuse superbases. Numerically, we can check it by finding a subset of the offsets whose determinant equals $\\pm 1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.det(offsets[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = Selling.Decomposition(D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp.det(offsets[:,0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Piecewise linearity\n",
    "\n",
    "Selling's coefficients depend in a piecewise linear manner on the decomposed tensor, since by Selling's formula they read $ - <b_i,D b_j>$ where $b_i,b_j$ are elements of a $D$-obtuse superbase $(b_0,\\cdots,b_d)$. This property is exploited, in some (somewhat sophisticated) numerical schemes, e.g. for the [Pucci](../Notebooks_NonDiv/NonlinearMonotoneSecond2D.ipynb) and [Monge Ampere](../Notebooks_NonDiv/MongeAmpere.ipynb) PDEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interpolate(a,b,T=np.linspace(0,1,100)):\n",
    "    return T, np.moveaxis(ad.array([(1-t)*a + t*b for t in T]),0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "t,D2t = Interpolate(MakeRandomTensor(2),MakeRandomTensor(2))\n",
    "decomp = Selling.GatherByOffset(t,*Selling.Decomposition(D2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "for offset,(time,coef) in decomp.items(): plt.plot(time,coef)\n",
    "plt.legend(decomp.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "t,D3t = Interpolate(MakeRandomTensor(3),MakeRandomTensor(3))\n",
    "decomp = Selling.GatherByOffset(t,*Selling.Decomposition(D3t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4)); plt.title(\"Coefficients of Selling's decomposition (d=3)\")\n",
    "for offset,(time,coef) in decomp.items(): plt.plot(time,coef)\n",
    "plt.legend(decomp.keys(),ncol=3)\n",
    "savefig(fig,\"Coefs_Sel3.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Smooth decomposition\n",
    "\n",
    "The coefficients of Selling's decomposition are piecewise linear, hence have Lipschitz regularity, but not better. In some applications it is preferable, at least from the theoretical standpoint, to define a decomposition whose coefficients have a *Lipschitz gradient*, or whose *square root is Lipschitz*. We describe such a construction in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Construction\n",
    "\n",
    "Two auxiliary functions are needed for our smooth variant of Selling's decomposition. The first one is a regularized substitude for the absolute value, smoothed within the interval $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sabs(x):\n",
    "    \"\"\"Regularized absolute value. Guarantee : 0 <= result-|x| <= 1/2\"\"\"\n",
    "    x = np.abs(x) # Actually useless for this specific application\n",
    "    return np.where(x<=1, 0.5*(1+x**2), x) \n",
    "#    return np.where(x<=1, (3+6*x**2-x**4)/8,x) # Alternative with higher regularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(-2,2,100)\n",
    "plt.plot(x,sabs(x),label=\"sabs\")\n",
    "plt.plot(x,np.abs(x),label=\"abs\")\n",
    "plt.title(\"Smoothed absolute value\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second auxiliary function is a regularized substitute for the median of three positive reals $\\rho_0,\\rho_1,\\rho_2$. In addition, the result is also defined in terms of two quantities denoted $s$ and $q$, that are chosen for their invariance under Selling's superbase operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smed(ρ0,ρ1,ρ2):\n",
    "    \"\"\"Regularized median (a.k.a. ρ1) assuming ρ0<=ρ1<=ρ2.\n",
    "    Guarantee : ρ1/(2*sqrt(2)) <= result < ρ1\"\"\"\n",
    "    s,q = ρ0*ρ1+ρ1*ρ2+ρ2*ρ0, (ρ2-ρ1)**2 # Invariant quantities under Selling superbase flip \n",
    "    return 0.5*s/np.sqrt(q+2*s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,2*np.pi,200)\n",
    "ρ0,ρ1,ρ2 = np.sort([1.5+np.cos(t),0.5*np.sin(t)**2,np.cos(3*t)+2],axis=0)\n",
    "plt.plot(t,ρ0, t,ρ1, t,ρ2, t,smed(ρ0,ρ1,ρ2))\n",
    "plt.title(\"Smoothed median\")\n",
    "plt.legend(['ρ0','ρ1','ρ2', 'smed']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a positive definite matrix $D$, and a $D$-obtuse superbase $(v_0,v_1,v_2)$.\n",
    "Define the Selling weights $\\rho_i = -<e_{i-1},D e_{i+1}>$, with periodic indices, and offsets $e_i = v_i^\\perp$. Assume that $\\rho_0\\leq \\rho_1\\leq \\rho_2$, up to permuting the basis elements.\n",
    "\n",
    "Our regularized Selling decomposition takes the following form, with $m = \\mathrm{smed}(\\rho_0,\\rho_1,\\rho_2)$.\n",
    "$$\n",
    "    D = \\sum_{0 \\leq i \\leq 2} \\rho_i e_i e_i^\\top + \\frac 1 2 (m\\, \\mathrm{sabs}(\\rho_0/m)-\\rho_0)(e_0 e_0^\\top - 2 e_1 e_1^\\top - 2 e_2 e_2^\\top + (e_1-e_2)(e_1-e_2)^\\top).\n",
    "$$\n",
    "Note that the first term $\\sum_{0 \\leq i \\leq 2} \\rho_i e_i e_i^\\top$ is Selling's standard decomposition of $D$. The second term amounts to zero, since $e_0 e_0^\\top - 2 e_1 e_1^\\top - 2 e_2 e_2^\\top + (e_1-e_2)(e_1-e_2)^\\top = 0$, but it introduces the additional offset $e_1-e_2$ and modifies the weights in a smooth manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdecomp(D):\n",
    "    \"\"\"Smooth variant of Selling's two dimensional decomposition\"\"\"\n",
    "    v = np.moveaxis(Selling.ObtuseSuperbase(D),1,0)\n",
    "    ρ = np.array([-lp.dot_VAV(v[1],D,v[2]),-lp.dot_VAV(v[0],D,v[2]),-lp.dot_VAV(v[0],D,v[1])])\n",
    "    order = np.argsort(ρ,axis=0)\n",
    "    v = np.take_along_axis(v,order[:,None],axis=0); ρ=np.take_along_axis(ρ,order,axis=0)\n",
    "\n",
    "    m = smed(*ρ)\n",
    "    w = np.maximum(0,m*sabs(ρ[0]/m)-ρ[0]) # Positive (w.o. max) up to roundoff error\n",
    "    \n",
    "    return (ad.array([ρ[0]+w/2, ρ[1]-w, ρ[2]-w, w/2]),\n",
    "         lp.perp(np.moveaxis(ad.array([v[0],v[1],v[2],v[1]-v[2]]),0,1)).astype(int) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Display of coefficients\n",
    "\n",
    "Recall that Selling's decomposition has piecewise linear coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "t,D2t = Interpolate(MakeRandomTensor(2),MakeRandomTensor(2))\n",
    "if xp is not np: D2t = D2t.get() # Bug with cupy 9.0 and np.zeros_like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4)); plt.title(\"Coefficients of Selling's decomposition\")\n",
    "decomp = Selling.GatherByOffset(t,*Selling.Decomposition(D2t))\n",
    "for offset,(time,coef) in decomp.items(): plt.plot(time,coef)\n",
    "plt.legend(decomp.keys()); savefig(fig,\"Coefs_Sel2.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we constructed a matrix decomposition whose coefficients have a bounded second order derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4)); plt.title(\"Coefficients of the smooth decomposition\")\n",
    "decomp = Selling.GatherByOffset(t,*sdecomp(D2t))\n",
    "for offset,(time,coef) in decomp.items(): plt.plot(time,coef)\n",
    "plt.legend(decomp.keys()); savefig(fig,\"Coefs_Smooth.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, their square root is Lipschitz, a property used in some convergence analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4)); plt.title(\"Sqrt of coefficients, smooth decomposition\")\n",
    "for offset,(time,coef) in decomp.items(): plt.plot(time,np.sqrt(coef))\n",
    "plt.legend(decomp.keys(),loc=\"upper right\"); savefig(fig,\"SqCoefs_Smooth.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Linear decomposition\n",
    "\n",
    "Selling's decomposition is piecewise linear, and is non-differentiable close to the identity matrix.\n",
    "In contrast, it can be useful in some applications to have a positive matrix decomposition that is smooth (as the previous one) or even better linear in a neighborhood of the identity matrix. We provide the following routine, which provides such a linear and non-negative decomposition for all positive definite matrices $D$ such that \n",
    "$$\n",
    "    \\kappa \\lambda_{\\max}(D) \\leq \\lambda_{min}(D), \\quad \\kappa:= \\frac {d-1}{d+1},\n",
    "$$\n",
    "using a fixed stencil of $d^2$ points.\n",
    "It appears that no decomposition with a fixed stencil and linear weights applies to a larger neighborhood of the identity matrix, defined by a smaller constant $\\kappa$ (unless there is an error in my calculations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_decomp_offsets(d):\n",
    "    \"\"\"The stencil for this linear decomposition is fixed and has $d^2$ elements\"\"\"\n",
    "    e = xp.eye(d)\n",
    "    return np.concatenate(\n",
    "        (e,xp.array([e[i]+s*e[j] for i in range(d) for j in range(i) for s in (-1,1)])),axis=0).T\n",
    "\n",
    "def linear_decomp_coefs(D):\n",
    "    \"\"\"These weights depend linearly on the matrix $D$\"\"\"\n",
    "    d=len(D)\n",
    "    α=(d+1)/(2*d); β=-1/(2*d); γ=1/(4*d); δ=1/4; # ε=(d-1)/(d+1)\n",
    "    t = sum(D[i,i] for i in range(d))\n",
    "    return np.concatenate((ad.array([(α-β)*D[i,i]+β*t for i in range(d)]),\n",
    "        ad.array([γ*(D[i,i]+D[j,j])+s*δ*(D[i,j]+D[j,i]) for i in range(d) \n",
    "        for j in range(i) for s in (-1,1)]) ),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two dimensional stencil:\n",
      " [[ 1.  0. -1.  1.]\n",
      " [ 0.  1.  1.  1.]]\n",
      "Three dimensional stencil:\n",
      " [[ 1.  0.  0. -1.  1. -1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  1.  0.  0. -1.  1.]\n",
      " [ 0.  0.  1.  0.  0.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Two dimensional stencil:\\n\",linear_decomp_offsets(2))\n",
    "print(\"Three dimensional stencil:\\n\",linear_decomp_offsets(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We numerically check the announced properties of this linear decomposition, in dimensions $2$ and $3$, on a hundred matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=2; D = MakeRandomTensor(d,(100,),relax=0.5) \n",
    "coefs,offsets = linear_decomp_coefs(D),linear_decomp_offsets(d)\n",
    "\n",
    "# Check reconstruction\n",
    "assert allclose(Reconstruct(coefs,offsets[...,None]),D)\n",
    "\n",
    "# Check positivity for sufficiently well conditioned matrices\n",
    "poscoef = np.min(coefs,axis=0)>=0\n",
    "λmin,λmax = np.linalg.eigvalsh(np.moveaxis(D,-1,0)).T\n",
    "illcond = λmin < (d-1)/(d+1)*λmax\n",
    "assert np.all(poscoef | illcond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=3; D = MakeRandomTensor(d,(100,),relax=0.5)\n",
    "coefs,offsets = linear_decomp_coefs(D),linear_decomp_offsets(d)\n",
    "\n",
    "# Check reconstruction\n",
    "assert np.allclose(Reconstruct(coefs,offsets[...,None]),D)\n",
    "\n",
    "# Check positivity for sufficiently well conditioned matrices\n",
    "poscoef = np.min(coefs,axis=0)>=0\n",
    "λmin,_,λmax = np.linalg.eigvalsh(np.moveaxis(D,-1,0)).T\n",
    "illcond = λmin < (d-1)/(d+1)*λmax\n",
    "assert np.all(poscoef | illcond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Automatic differentiation\n",
    "\n",
    "**Selling's decomposition** This decomposition is piecewise linear. The code is compatible with automatic differentiation, but the AD part is unstable at points of non-differentiability, which include the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "D0 = ad.Dense.identity(constant=xp.eye(2)) # identity matrix + symbolic first order perturbation\n",
    "D0 = (D0+D0.T)/2 # Symmetrize the first order part\n",
    "D1 = D0 + 1e-4*xp.asarray(np.random.rand(2,2)-0.5) # A perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices $D_0$ and $D_1$ are close, and so are their Selling decompositions.\n",
    "(Note that the stencil for $D_0$, the identity matrix, is not uniquely determined, but the Selling weight associated to the modified stencil elements is zero anyway.)\n",
    "However, the first order AD parts are different.\n",
    "\n",
    "<!---\n",
    "λ0,e0 = Selling.Decomposition(D0)\n",
    "λ1,e1 = Selling.Decomposition(D1)\n",
    "print(λ0-λ1)\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ0,e0 = Selling.Decomposition(D0)\n",
    "λ1,e1 = Selling.Decomposition(D1)\n",
    "# In other cases, λ1 may need to be permuted, to account for arbitrary ordering of e0,e1\n",
    "λdiff = λ0-λ1\n",
    "assert np.max(np.abs(λdiff.value)) < 1e-4 # The coefficients values are close\n",
    "np.max(np.abs(λdiff.coef)) # The coefficient derivatives are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoothed variant of Selling's decomposition.** The previous instability phenomenon is avoided with the smooth variant of the decomposition.\n",
    "\n",
    "Note that the *ordering* of the stencil elements, is not uniquely determined. But this can be dealt with easily by putting them into some canonical ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ0,e0 = sdecomp(D0)\n",
    "λ1,e1 = sdecomp(D1)\n",
    "# λ1 is reversed here to account for reversed ordering of the offsets e0 and e1 \n",
    "# (An arbitrary permutation is possible in general)\n",
    "λdiff = λ0-λ1[::-1] \n",
    "assert np.max(np.abs(λdiff.value))<1e-4 # The coefficients are close\n",
    "assert np.max(np.abs(λdiff.coef))<1e-4 # The coefficient derivatives are close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear variant.**\n",
    "The linear decomposition presented above only applies to positive definite matrices whose condition number is sufficiently small. Since it linear, however, not only the coefficients are close, but their derivatives are identical. The offsets are also, of course, identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ0 = linear_decomp_coefs(D0)\n",
    "λ1 = linear_decomp_coefs(D1)\n",
    "λdiff = λ0-λ1 # Always the same ordering here\n",
    "assert np.max(np.abs(λdiff.value))<1e-4 # The coefficients are close\n",
    "assert np.max(np.abs(λdiff.coef))==0 # Their derivatives are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}