{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive PDE discretizations on Cartesian grids\n",
    "## Volume : Algorithmic tools\n",
    "## Part : Tensor decomposition techniques\n",
    "## Chapter : Voronoi's reduction, in dimension 4 and 5\n",
    "\n",
    "\n",
    "This notebook presents some tensor decomposition techniques that are at the foundation of our anisotropic PDE discretizations on cartesian grids. The general objective is to express a given symmetric positive definite (SPD) matrix $D$ under the form\n",
    "$$\n",
    "    D = \\sum_{0 \\leq i < I} \\lambda_i e_i e_i^T,\n",
    "$$\n",
    "where $\\lambda_i \\geq 0$ is a non-negative weight, and $e_i \\in Z^d$ is an integral offset.\n",
    "This decomposition is a starting point for the design of various numerical schemes, for both first order and second order, linear and non-linear PDEs, which will be discussed in the subsequent notebooks.\n",
    "\n",
    "The techniques used for constructing the above decomposition are non-trivial, related to classical yet subtle tools of discrete geometry. In this notebook, we however insist more on their properties \n",
    "\n",
    "This notebook is devoted to the decomposition of SPD tensors of size $d \\times d$, where the dimension $d\\in \\{4,5\\}$. A simpler set of techniques applies in dimension $d \\in \\{2,3\\}$, see the notebook [I Tensor decomposition, dimensions 2 and 3](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/AdaptiveGridDiscretizations/master/Notebooks/TensorSelling.ipynb)\n",
    "\n",
    "**Acknowledgement.** \n",
    "\n",
    "The experiments presented in this notebook are part of ongoing research, with PhD student Guillaume Bonnet, in co-direction with [Frederic Bonnans](http://www.cmap.polytechnique.fr/~bonnans/).\n",
    "\n",
    "\n",
    "**References.**\n",
    "\n",
    "The tensor decomposition presented in this notebook is a central ingredient of the following paper:\n",
    "\n",
    "Mirebeau, J.-M. (2017, April 12). Riemannian fast-marching on cartesian grids using Voronoi's first reduction of quadratic forms. HAL (Preprint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Algorithmic tools, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. Computing the decomposition of a tensor](#1.-Computing-the-decomposition-of-a-tensor)\n",
    "    * [1.1 Case of a  $4 \\times 4$ tensor](#1.1-Case-of-a--$4-\\times-4$-tensor)\n",
    "    * [1.2 Case of a $5\\times 5$ tensor](#1.2-Case-of-a-$5\\times-5$-tensor)\n",
    "    * [1.3 A field of tensors](#1.3-A-field-of-tensors)\n",
    "  * [2. Under the hood: Voronoi's first reduction of tensors.](#2.-Under-the-hood:-Voronoi's-first-reduction-of-tensors.)\n",
    "    * [2.1 Comparing the objective function](#2.1-Comparing-the-objective-function)\n",
    "    * [2.2 Non-uniqueness of the maximizer](#2.2-Non-uniqueness-of-the-maximizer)\n",
    "  * [3. Properties of Voronoi's reduction](#3.-Properties-of-Voronoi's-reduction)\n",
    "    * [3.1 Smallness of the offsets](#3.1-Smallness-of-the-offsets)\n",
    "    * [3.2 Stability](#3.2-Stability)\n",
    "    * [3.3 Spanning, of the lattice $Z^d$ by the tensor decomposition offsets.](#3.3-Spanning,-of-the-lattice-$Z^d$-by-the-tensor-decomposition-offsets.)\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgement.** Some of the experiments presented in these notebooks are part of \n",
    "ongoing research with Ludovic MÃ©tivier and Da Chen.\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, Centre Borelli, ENS Paris-Saclay, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\") # Allow import of agd from parent directory (useless if conda package installed)\n",
    "#from Miscellaneous import TocTools; TocTools.displayTOC('TensorVoronoi','Algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agd import LinearParallel as lp\n",
    "from agd.Selling import GatherByOffset\n",
    "from agd.Plotting import savefig; #savefig.dirName = 'Figures/TensorVoronoi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The routines for tensor decomposition are for efficiency purposes provided in a small c++ library, named FileVDQ where VDQ stands for \"Voronoi Decomposition of Quadratic forms\". This is in contrast with the two and three dimensional cases, where the decomposition algorithm is coded in Python (the c++ library can also be used in smaller dimensions). A function named `VoronoiDecomposition` provides the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agd.Eikonal import VoronoiDecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Optional configuration\n",
    "\n",
    "Uncomment the following line to use the GPU implementation of Voronoi's decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "EikonalGPU_config"
    ]
   },
   "outputs": [],
   "source": [
    "#VoronoiDecomposition.default_mode = 'gpu_transfer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Computing the decomposition of a tensor\n",
    "\n",
    "We illustrate our tensor decomposition method on random positive definite matrices, of the form \n",
    "$$\n",
    "    D = A^T A,\n",
    "$$\n",
    "where $A$ is a square matrix with random coefficients w.r.t. the Gaussian normal law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeRandomTensor(dim,shape = tuple()):\n",
    "    A = np.random.standard_normal( (dim,dim) + shape )\n",
    "    return lp.dot_AA(lp.transpose(A),A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, we fix the random seed\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inserse operation to tensor decomposition is, of course, reconstruction, defined by \n",
    "$$\n",
    "    (\\lambda_i, e_i)_{i=1}^I \\mapsto D = \\sum_{1 \\leq i \\leq I} \\lambda_i e_i e_i^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reconstruct(coefs,offsets):\n",
    "     return lp.mult(coefs,lp.outer_self(offsets)).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LInfNorm(a):\n",
    "    return np.max(np.abs(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Case of a  $4 \\times 4$ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D4 = MakeRandomTensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58050469 -0.73151355 -0.24786425  0.65940888]\n",
      " [-0.73151355  4.02894983  2.589515    0.43286178]\n",
      " [-0.24786425  2.589515    6.10351105  3.38411893]\n",
      " [ 0.65940888  0.43286178  3.38411893  3.44164748]]\n"
     ]
    }
   ],
   "source": [
    "print(D4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decomposition, of a $4 \\times 4$ SPD tensor, involves either $10$ or $12$ coefficients and offsets. \n",
    "If the tensor is randomly generated, then each possibility arises with positive probability, in approximately half the cases.\n",
    "\n",
    "For uniformity of the data structures, we always return $12$ coefficients and offsets, but the last two are often zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [1.73966329 0.06642844 0.15724673 0.18106995 0.16328382 0.00623787\n",
      " 1.38738859 0.93488664 0.00623787 0.27498616 0.302155   0.00623787]\n",
      "Offsets : \n",
      " [[ 0  1  1  1  1  1  0  0  0  0  0  1]\n",
      " [ 1 -1 -2 -1 -1  0  0  1  1  0  1 -1]\n",
      " [ 0  1 -1  0 -1  1  1  2  1  1  1  0]\n",
      " [ 0  2  1  1  1  2  1  1  0  0  1  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By design, the coefficients are non-negative, and the reconstruction is exact up to numerical precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal coefficient :  0.006237894296646118\n",
      "Reconstruction error :  5.549733129717183e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimal coefficient : \", np.min(coefs))\n",
    "print(\"Reconstruction error : \", LInfNorm(D4-Reconstruct(coefs,offsets)))\n",
    "assert np.allclose(D4,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing another tensor at random, we observe only $10$ non-zero coefficients and offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeRandomTensor(4), MakeRandomTensor(4); # Please do not comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [0.49956441 0.3344202  0.00239825 0.67380857 0.17172146 2.27991986\n",
      " 1.96547747 0.01978564 0.18202043 0.07072139 0.         0.        ]\n",
      "Offsets : \n",
      " [[ 1  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 -1  1 -1  0  1 -1  2  0  0]\n",
      " [ 0 -1  0  0  0  0  1 -1 -1  0  0  0]\n",
      " [ 0 -1  0 -1  1  0  1  0 -1  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "D4b= MakeRandomTensor(4)\n",
    "coefs,offsets = VoronoiDecomposition(D4b)\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(D4b,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Case of a $5\\times 5$ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D5 = MakeRandomTensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.87614651 -1.20025611 -0.3039039   3.45377063 -2.92404121]\n",
      " [-1.20025611  4.08494961  2.00986908 -0.98704778 -1.18866626]\n",
      " [-0.3039039   2.00986908  6.09801254  1.10173352 -0.81699419]\n",
      " [ 3.45377063 -0.98704778  1.10173352  3.09137402 -2.81363475]\n",
      " [-2.92404121 -1.18866626 -0.81699419 -2.81363475  4.55827309]]\n"
     ]
    }
   ],
   "source": [
    "print(D5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decomposition of $5 \\times 5$ SPD tensors always involves $15$ coefficients and offsets. (Some coefficients may vanish but, contrary to the four dimensional case, this occurs with probability zero.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [0.00724207 0.2256628  0.07998447 0.17522477 0.10235864 0.1294006\n",
      " 0.12570727 0.4178696  0.1386955  0.00786875 0.24933013 0.068444\n",
      " 0.12471117 0.03802328 0.24450543]\n",
      "Offsets : \n",
      " [[ 1  2  2  2  1  1  0  0  1  2  0  1  3  2  3]\n",
      " [ 2  0  0 -1  3  0  0  1 -3  2  1 -3  0  2 -1]\n",
      " [ 4 -2  0  0  2  1  2  0 -2  3 -2 -4 -1  5  1]\n",
      " [ 2  1  1  2  1  0  0 -1  0  2 -1  0  1  2  2]\n",
      " [-3 -2 -1 -2 -3  1  1  1  2 -3  0  1 -1 -2 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal coefficient :  0.007242065449640733\n",
      "Reconstruction error :  8.881784197001252e-16\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimal coefficient : \", np.min(coefs))\n",
    "print(\"Reconstruction error : \", LInfNorm(D5-Reconstruct(coefs,offsets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(D5,Reconstruct(coefs,offsets),atol=1e-5) # atol is for float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 A field of tensors\n",
    "\n",
    "When provided with a numerical array shaped as $(d,d,n)$, or $(d,d,n_1,\\cdots,n_d)$, our tensor decomposition routine automatically threads over the inner dimensions $n$ or $n_1,\\cdots, n_d$.\n",
    "\n",
    "<!---\n",
    "**TODO** Perform a reshape in VDEUtils python library, avoiding such restrictions, and simplifying the c++ code ?\n",
    "In fact the present code makes sense, in case one wants to implement anisotropic diffusion directly in c++.\n",
    "\n",
    "This facility is intended for use in adaptive finite difference PDE schemes.\n",
    "Note, however, that the field of $d \\times d$ tensors, may only have depth $1$ or $d$.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "D4_field = MakeRandomTensor(4,(10,))\n",
    "# Alternatively\n",
    "#D4_field = MakeRandomTensor(4,(2,2,2,2))\n",
    "#D5_field = MakeRandomTensor(4,(2,2,2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(D4_field,Reconstruct(coefs,offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Under the hood: Voronoi's first reduction of tensors.\n",
    "\n",
    "The tensor decompositions computed in this notebook are the result of a linear program, which is well known in the field of lattice geometry (a subfield of discrete computational geometry).\n",
    "The dual to this linear program is often referred to as Voronoi's first reduction. \n",
    "\n",
    "In detail, the decomposition of a tensor $D$ proceeeds by maximizing the sum of the weights\n",
    "$$\n",
    "    \\text{maximize} \\quad \n",
    "    \\sum_{1 \\leq i \\leq I} \\lambda_i,\n",
    "$$\n",
    "while the constraints enforce that the decomposition is valid\n",
    "$$\n",
    "    \\text{subject to} \\quad \n",
    "    \\lambda_i \\geq 0, \\quad \n",
    "    e_i \\in Z^d, \\quad\n",
    "    \\text{and}  \\quad\n",
    "    \\sum_{1 \\leq i \\leq I} \\lambda_i e_i e_i^T = D.\n",
    "$$\n",
    "Note that the vectors $e_i \\in Z^d$ are not fixed a-priori, and that $I$ is not bounded a-priori, hence that optimization problem is strictly speaking infinite dimensional.\n",
    "\n",
    "Two motivations can be invoqued to justify the choice of objective function, which is the sum of the decomposition coefficients. Indeed, this approach:\n",
    "* Promotes small offsets. This is clear in view of the trace identity\n",
    "$$\n",
    "    \\mathrm{Tr}(D) = \\sum_{1 \\leq i \\leq I} \\lambda_i \\|e_i\\|^2,\n",
    "$$\n",
    "which relate the coefficients magnitudes with the offsets norms.\n",
    "* Is highly symmetrical, allowing for efficient implementations. The numerical cost of our optimized implementation is expected to be low enough to compute one such decomposition for each point of the discretization grid of a PDE.\n",
    "\n",
    "It can be shown that Voronoi's first reduction, the above linear program, has at least one solution for each positive definite symmetric matrix $D$. \n",
    "Interestingly however, the solution may not be unique, so that a selection principle becomes necessary. More precisely:\n",
    "* In dimension $2$ and $3$, the linear program actually always has a unique solution, which can also be computed using Selling's algorithm, see the relevant notebook [I Tensor decomposition, dimensions 2 and 3](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/HFM_Python_Notebooks/master/TensorSelling.ipynb).\n",
    "* In dimension $4$, the linear program either has a unique solution, or a set of solutions that forms a triangle (equilateral) in the coefficients space. In the latter case, the triangle barycenter is returned.\n",
    "* In dimension $5$, the linear program often has a $5$ dimensional set of solutions, forming a convex polyhedron. A vertex of this polyhedron is selected, in a consistent manner so as to ensure the continuity of the coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Comparing the objective function\n",
    "\n",
    "We empirically check, on a random example, that our tensor decomposition yields a large sum of coefficients.\n",
    "\n",
    "For that purpose, we generate a matrix $D = \\sum_{i=1}^I \\lambda_i e_i e_i^T$ by drawing randomly the weights \n",
    "$(\\lambda_i)$ and offsets $e_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = np.random.standard_normal(15)**2\n",
    "offsets = np.random.uniform(-5,5,(5,15)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "D5b = Reconstruct(coefs,offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients :  26.029629166601506\n",
      "Coefficients :  [1.64010186e-01 1.58982835e+00 8.42470554e-01 4.50354692e+00\n",
      " 1.06598451e+00 2.30848509e+00 2.34482637e-01 1.60506386e+00\n",
      " 5.00796073e-01 1.96975685e-01 6.00057917e-01 8.59200099e-01\n",
      " 3.54326801e-03 1.05058140e+01 1.04937004e+00]\n",
      "Offsets ; \n",
      " [[-3  0 -1  1  1 -4 -1  1  0  3  1 -3 -4  1 -4]\n",
      " [ 0  4  0 -1  1  0  0  4 -1  4  4 -3 -4 -3 -4]\n",
      " [-4  1 -4 -1  3 -4  3 -2 -3  1  1  3  2  3 -2]\n",
      " [-3  2  3  4  0 -1  2 -1  4  3  0  2  2 -3  4]\n",
      " [ 0  3 -1  3 -1 -4  4 -4 -1  4  4  0  1  0 -2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of coefficients : \", np.sum(coefs))\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets ; \\n\", offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tensor decomposition yields, as expected, a larger sum of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of new coefficients 411.51346412301064\n",
      "Coefficients :  [  0.35419223   0.80861419   2.60917234   2.63908768   3.12586236\n",
      "   7.15106153  11.04205513  17.83511162  24.26595879  26.42989922\n",
      "  30.65375519  49.95257568  61.22357941  73.16596222 100.25657654]\n",
      "Offsets ; \n",
      " [[ 0 -1 -1 -1 -1 -1  0 -1  0  0  0 -1  0  0  0]\n",
      " [ 1 -1  0  0  0  0  0  0  0  1  0  0  1  0  1]\n",
      " [-1  0 -1  0  0  0  0 -1  0 -1  1 -1 -1  0  0]\n",
      " [ 0  0  1  0  0  1  0  1 -1  0 -1  0  1 -1  0]\n",
      " [-1 -1 -1 -1  0  0  1  0  0  0  0 -1  0 -1  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of new coefficients\", np.sum(coefs))\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets ; \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second example, we expose the non-linearity of our tensor decomposition by comparing:\n",
    "* The average of the decompositions of two tensors.\n",
    "* The decomposition of the average tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients, average decomposition :  5.712830034317449\n",
      "Sum of coefficients, decomposition of the average :  7.57825231552124\n"
     ]
    }
   ],
   "source": [
    "coefs0,_  = VoronoiDecomposition(D4)\n",
    "coefs1,_  = VoronoiDecomposition(D4b)\n",
    "coefs01,_ = VoronoiDecomposition(D4+D4b)\n",
    "print(\"Sum of coefficients, average decomposition : \", 0.5*(np.sum(coefs0)+np.sum(coefs1)))\n",
    "print(\"Sum of coefficients, decomposition of the average : \", 0.5*np.sum(coefs01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Non-uniqueness of the maximizer\n",
    "\n",
    "We illustrate a case where a tensor $D$ admits several optimal decompositions, all maximizing the coefficients sum.\n",
    "The specific example chosen is also interesting from the point of view of the spanning property, discussed in the next section.\n",
    "\n",
    "Note that the choice of theses offsets is very specific, coming from a fine theoretical description of Voronoi's first reduction, the associated *perfect forms*, and their minimal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_NonUnique = np.array([1,1,1,1])\n",
    "offsets_NonUnique = np.transpose(np.array([[0,0,1,0],[0,1,0,-1],[1,-1,0,0],[1,0,-1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients :  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of coefficients : \", np.sum(coefs_NonUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "D4_NonUnique = Reconstruct(coefs_NonUnique,offsets_NonUnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4_NonUnique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor decomposition returned by our software is different, but the coefficients sum is no smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of new coefficients :  4.0\n",
      "Coefficients :  [0.33333334 0.33333334 0.33333331 0.33333334 0.33333334 0.33333331\n",
      " 0.33333331 0.33333334 0.33333334 0.33333331 0.33333334 0.33333334]\n",
      "Offsets : \n",
      " [[ 1  0  0  0  1  1  0  0  0  1  1  1]\n",
      " [ 0  1  0  0  0 -1  1  1  0  0 -1 -1]\n",
      " [ 0  0  1  0 -1  0  0 -1  1 -1  0 -1]\n",
      " [ 0  0  0  1  0  0 -1  0 -1  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of new coefficients : \", np.sum(coefs))\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(D4_NonUnique, Reconstruct(coefs,offsets) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Properties of Voronoi's reduction\n",
    "\n",
    "We discuss three properties of the implemented tensor decomposition\n",
    "$$\n",
    "    D \\mapsto (\\lambda_i, e_i)_{i=1}^I,\n",
    "$$\n",
    "which seems to be desirable from the implementation point of view. There properties are\n",
    "* **Smallness** of the offsets $e_i \\in Z^d$.\n",
    "* **Stability** of the coefficients $\\lambda_i \\in R$\n",
    "* **Spanning** of the full lattice $Z^d$, by the offsets $(e_i)_{i=1}^I$. (Not always satisfied if $d=5$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Smallness of the offsets\n",
    "\n",
    "By design, by the choice of the objective function in the underlying linear program, Voronoi's first reduction promotes small offsets in the tensor decompositions produced.\n",
    "It is also possible to bound the offsets norm in terms of the tensor condition number\n",
    "$$\n",
    "    \\|e_i\\| \\leq C \\mu(D)^{d-1}\n",
    "$$\n",
    "where $\\mu(D) := \\sqrt{\\|D\\| \\|D^{-1}\\|}$ and $C$ is an absolute constant. \n",
    "\n",
    "\n",
    "Note that this theoretical bound is not sharp in dimension $d=3$, in that case one can prove that $\\|e_i\\| \\leq C \\mu(D)$, and may not be sharp either in higher dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a SPD tensor with condition number $\\mu$, and compare $\\max_{1 \\leq i \\leq d} \\|e_i\\|$ with $\\mu$. Successively $d=4$ and then $d=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.standard_normal(4)\n",
    "v=v/np.linalg.norm(v)\n",
    "D4_cigar = (mu**2-1)*lp.outer_self(v) + np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4_cigar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu :  10\n",
      "max offset norm :  6.708203932499369\n",
      "Offsets : \n",
      " [[-1  3  1  2 -3 -2 -4  1  2 -1  0  0]\n",
      " [ 1 -3 -1 -1  2  2  4 -2 -2  0  0  0]\n",
      " [-1  2  1  1 -2 -2 -3  1  1  0  0  0]\n",
      " [ 0  2  1  1 -1 -1 -2  1  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"mu : \",mu)\n",
    "print(\"max offset norm : \",np.max(np.linalg.norm(offsets,axis=0)))\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.standard_normal(5)\n",
    "v=v/np.linalg.norm(v)\n",
    "D5_cigar = (mu**2-1)*lp.outer_self(v) + np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D5_cigar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu :  10\n",
      "max offset norm :  6.782329983125268\n",
      "Offsets : \n",
      " [[ 0 -1  1  1 -1  1  1  1  2  0  1  0  1  1  0]\n",
      " [-1 -1  0  1 -1  0  0  0  0 -1  0  0  0  0  0]\n",
      " [-1 -2  2  3 -3  1  3  4  5  0  3  1  3  2 -1]\n",
      " [ 1  2 -2 -3  2 -1 -2 -3 -4  0 -3  0 -2 -2  1]\n",
      " [ 0  0  1  1  0  0  1  1  1  0  1  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"mu : \",mu)\n",
    "print(\"max offset norm : \",np.max(np.linalg.norm(offsets,axis=0)))\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stability\n",
    "\n",
    "The implemented tensor decompositions are stable, in the sense that the weight associated with and offset depends continuously on the tensor decomposed.\n",
    "Mathematically, for any $e \\in Z^d / \\{\\pm 1\\}$, the following mapping is locally Lipschitz \n",
    "$$\n",
    "    D \\mapsto \\lambda^e(D),\n",
    "$$\n",
    "where $\\lambda^e(D)$ is the coefficient of $e e^T$ in the decomposition of $D$.\n",
    "\n",
    "This continuity is achieved thanks to an appropriate selection principle, in the cases where the linear program defining Voronoi's first reduction does not have unique maximizer. Note that the coefficient of an offset $e_i$ and of its opposite $-e_i$ are regarded as identical.\n",
    "\n",
    "We check the coefficients continuity by interpolating between two randomly drawn tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interpolate(a,b,T=np.linspace(0,1,100)):\n",
    "    return T, np.moveaxis(np.array([(1-t)*a + t*b for t in T]),0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_interp, D4_interp = Interpolate(MakeRandomTensor(4),MakeRandomTensor(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error :  4.379817774236017e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Reconstruction error : \", LInfNorm(D4_interp - Reconstruct(coefs,offsets)))\n",
    "assert np.allclose(D4_interp, Reconstruct(coefs,offsets),atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = GatherByOffset(T_interp,coefs,offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "for offset,(time,coef) in decomp.items():\n",
    "    plt.plot(time,coef)\n",
    "plt.legend(decomp.keys(),ncol=3)\n",
    "savefig(fig,\"Coefs_Vor4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error :  4.823934109943195e-06\n"
     ]
    }
   ],
   "source": [
    "T_interp, D5_interp = Interpolate(MakeRandomTensor(5),MakeRandomTensor(5))\n",
    "coefs,offsets = VoronoiDecomposition(D5_interp)\n",
    "print(\"Reconstruction error : \", LInfNorm(D5_interp - Reconstruct(coefs,offsets)))\n",
    "assert np.allclose(D5_interp, Reconstruct(coefs,offsets),atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CPU vs GPU implementation.** The CPU decomposition is stable w.r.t the inputs, locally Lipschitz more precisely. In contrast, the GPU implementation is discontinuous. Indeed, the code devoted to the selection of the decomposition in cases of non-uniqueness requires double precision floating point arithmetic, and for this reason it was not ported to the GPU.\n",
    "\n",
    "<!---This is due to a bit of code (selection of the decomposition in cases of non-uniqueness) which was not ported to the GPU, and could easily be fixed in the future.--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = GatherByOffset(T_interp,coefs,offsets)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "for offset,(time,coef) in decomp.items():\n",
    "    plt.plot(time,coef)\n",
    "plt.legend(decomp.keys(),ncol=7);\n",
    "savefig(fig,\"Coefs_Vor5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix eigenvalues :  [16.09060444  5.79356695  5.18317148  0.28922182  0.53419682]\n",
      "Coefficients :  [0.03566651 0.11726284 0.1542273  0.19929171 0.20794383 0.24738836\n",
      " 0.25872949 0.34937188 0.45032027 0.63644886 0.88558388 1.1639781\n",
      " 1.34325409 1.49763775 1.60365629]\n",
      "Offsets : \n",
      " [[ 2  1  0  0  2  0  2 -1  1 -2  0 -1 -1  1  0]\n",
      " [ 1  0  1  1  2 -1  0  1  2 -1 -1  0 -1  1  0]\n",
      " [ 0  0 -1  0  0 -1  0  0  0 -1  0 -1 -1  0 -1]\n",
      " [ 0  1  0  0  0  1  1 -1 -1  0  1  0  0  0  0]\n",
      " [-1 -1 -1  0 -1 -1 -1  1  0  0  0  0  0  0 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix eigenvalues : \",np.linalg.eigvals(D5_interp[...,0]))\n",
    "print(\"Coefficients : \", coefs[...,0])\n",
    "print(\"Offsets : \\n\", offsets[...,0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposed matrix : \n",
      " [[ 9.47698215e+00  5.56816864e+00  3.78013118e+00  5.33774689e-01\n",
      "  -1.47131475e+00]\n",
      " [ 5.56816864e+00  7.98192782e+00  2.07286383e+00 -2.38298448e+00\n",
      "  -9.02088673e-03]\n",
      " [ 3.78013118e+00  2.07286383e+00  5.14894904e+00 -2.47388327e-01\n",
      "   2.00526914e+00]\n",
      " [ 5.33774689e-01 -2.38298448e+00 -2.47388327e-01  2.30865702e+00\n",
      "  -9.72752458e-01]\n",
      " [-1.47131475e+00 -9.02088673e-03  2.00526914e+00 -9.72752458e-01\n",
      "   2.97424548e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Decomposed matrix : \\n\",D5_interp[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Spanning, of the lattice $Z^d$ by the tensor decomposition offsets. \n",
    "\n",
    "The tensor decompositions presented in this notebook are intended as the foundation to finite difference schemes. \n",
    "The offsets $(e_i)_{i=1}^I$ involved in the decomposition of a tensor $D = D(x)$ appearing in the discretized PDE, thus determine the local connectivity of the discretization grid around $x$.\n",
    "\n",
    "In order to avoid chessboard artifacts, it is desirable that the offsets span the lattice $Z^d$ (using integer coefficients), which is referred to as the *spanning property*. Let us recall that a set of $d$ vectors $e_1,\\cdots,e_d \\in Z^d$ span the lattice $Z^d$ with integer coefficients iff\n",
    "$$\n",
    "    \\det(e_1,\\cdots,e_d)=1.\n",
    "$$\n",
    "\n",
    "*General findings* In dimension $d\\leq 4$, the spanning property is guaranteed for the implemented tensor decomposition. In dimension $d=5$, it is not, but we provide a fix for it. However, it is not clear that this fix is desirable in practical implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Four dimensional decompositions span**\n",
    "\n",
    "We can guarantee, by theoretical arguments, that our decompositions of $4\\times 4$ SPD tensors obey the spanning property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(offsets[:,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An intruiguing special case**\n",
    "\n",
    "Interestingly, there are exists tensors $D\\in S_4^{++}$ admitting an optimal decomposition, in the sense of Voronoi's first reduction see above, which is not spanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensors admitting a non-unique optimal decomposition :  [[ 2 -1 -1  1]\n",
      " [-1  2  0 -1]\n",
      " [-1  0  2 -1]\n",
      " [ 1 -1 -1  2]]\n",
      "Coefficients of an optimal decomposition :  [1 1 1 1]\n",
      "Offsets of an optimal decomposition :  [[ 0  0  1  1]\n",
      " [ 0  1 -1  0]\n",
      " [ 1  0  0 -1]\n",
      " [ 0 -1  0  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"A tensors admitting a non-unique optimal decomposition : \", D4_NonUnique)\n",
    "print(\"Coefficients of an optimal decomposition : \", coefs_NonUnique)\n",
    "print(\"Offsets of an optimal decomposition : \", offsets_NonUnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(offsets_NonUnique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our tensor decomposition method selects a different decomposition, which is spanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D4_NonUnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [0.33333334 0.33333334 0.33333331 0.33333334 0.33333334 0.33333331\n",
      " 0.33333331 0.33333334 0.33333334 0.33333331 0.33333334 0.33333334]\n",
      "Offsets : \n",
      " [[ 1  0  0  0  1  1  0  0  0  1  1  1]\n",
      " [ 0  1  0  0  0 -1  1  1  0  0 -1 -1]\n",
      " [ 0  0  1  0 -1  0  0 -1  1 -1  0 -1]\n",
      " [ 0  0  0  1  0  0 -1  0 -1  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(offsets[:,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Five dimensional decompositions may not span**\n",
    "\n",
    "We present below a tensor $D\\in S_5^{++}$ whose Voronoi's decomposition is unique and non-spanning. Note that the choice of these offsets is very specific, coming from a fine theoretical description of Voronoi's first reduction, the associated *perfect forms*, and their minimal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_NonSpanning = np.array([1,1,1,1,1])\n",
    "offsets_NonSpanning = np.transpose(np.array(\n",
    "    [[0,0,1,0,1],[0,0,1,1,0],[0,1,0,0,0],[1,0,0,0,0],[1,1,0,1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "D5_NonSpanning = Reconstruct(coefs_NonSpanning,offsets_NonSpanning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.det(offsets_NonSpanning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can illustrated below, the explicit decomposition in terms of coefficients and offsets maximizes the sum of the weights (a property which defines Voronoi's reduction). In addition, and contrary to the previous four dimensional example, this maximizer is non-degenerate and attained for a unique decomposition - the one represented above which is reproduced by our decomposition algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D5_NonSpanning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients :  8.0\n",
      "Coefficients :  [1. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 0.]\n",
      "Offsets : \n",
      " [[1 0 0 0 0 1 1 0 0 0 0 1 1 0 1]\n",
      " [0 1 0 0 0 0 0 1 1 0 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 1 0 1 0 1 0 1 1 1 1]\n",
      " [0 0 0 0 1 0 1 0 1 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of coefficients : \", np.sum(coefs))\n",
    "print(\"Coefficients : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 1]\n",
      " [0 1 0 0 1]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 0 1]\n",
      " [0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(offsets[:,coefs>0].astype(int)) # Same as offsets_NonUnique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A fix for the spanning property**\n",
    "\n",
    "Let $D$ be a PSD tensor. Then it is always possible to construct a decomposition of $D$ with the spanning property by adding the decompositions of \n",
    "$$\n",
    "    D = \\lambda I + (D-\\lambda I),\n",
    "$$\n",
    "where $\\lambda>0$ is sufficiently small, so that $D-\\lambda I$ is positive definite. A natural choice is to set $\\lambda := \\frac 1 2 \\lambda_{\\min}(D)$, half the smallest eigenvalue of $D$.\n",
    "\n",
    "Recalling that the decomposition of the identity matrix is\n",
    "$$\n",
    "    I = \\sum_{1 \\leq i \\leq d} e_i e_i^T,\n",
    "$$\n",
    "we obtain a tensor decomposition which is spanning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.min(np.linalg.eigvals(D5_NonSpanning))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs,offsets = VoronoiDecomposition(D5_NonSpanning - alpha*np.eye(5))\n",
    "coefs = np.concatenate([alpha*np.ones(5),coefs],axis=0)\n",
    "offsets = np.concatenate([np.eye(5),offsets],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new decomposition reproduces the norm, and is spanning, as checked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.960464477539063e-08\n"
     ]
    }
   ],
   "source": [
    "print(LInfNorm(D5_NonSpanning - Reconstruct(coefs,offsets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs :  [1.59334678e-01 1.59334678e-01 1.59334678e-01 1.59334678e-01\n",
      " 1.59334678e-01 1.49011612e-08 1.49011612e-08 1.59334660e-01\n",
      " 1.59334660e-01 1.59334660e-01 1.59334674e-01 1.59334689e-01\n",
      " 1.59334689e-01 1.59334689e-01 3.18669349e-01 3.62661362e-01\n",
      " 3.62661362e-01 5.21995962e-01 5.21995962e-01 5.21995962e-01]\n",
      "Offsets : \n",
      " [[ 1  0  0  0  0  0 -1  1 -1  1 -1 -1  0  1  0  0  1  0 -1  0]\n",
      " [ 0  1  0  0  0 -1  0  1 -1  1  0  0 -1  0 -1  1  0  0 -1  0]\n",
      " [ 0  0  1  0  0  0  1  0  0 -1 -1  0  1  0 -1  0  0 -1  0  1]\n",
      " [ 0  0  0  1  0 -1  0  1  0  0 -1  0  0  1 -1  0  0  0 -1  1]\n",
      " [ 0  0  0  0  1  0  0  0 -1  0 -1 -1  0  0 -1  0  0 -1 -1  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefs : \", coefs)\n",
    "print(\"Offsets : \\n\", offsets.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this decomposition is not optimal from the point of view of the sum of weights, and of the offsets norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of coefficients :  4.521996099475067\n",
      "Max offset norm :  2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of coefficients : \", np.sum(coefs))\n",
    "print(\"Max offset norm : \", np.max(np.linalg.norm(offsets,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal sum of coefficients :  5\n",
      "Canonical offset norm :  2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal sum of coefficients : \", np.sum(coefs_NonSpanning))\n",
    "print(\"Canonical offset norm : \", np.max(np.linalg.norm(offsets_NonSpanning,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}