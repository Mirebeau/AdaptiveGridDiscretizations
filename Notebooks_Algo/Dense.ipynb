{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive PDE discretizations on Cartesian grids\n",
    "## Volume : Algorithmic tools\n",
    "## Part : Automatic differentiation\n",
    "## Chapter : Dense automatic differentiation, and geodesic shooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates automatic differentiation, with an application to Hamilton's equations and geodesic shooting. More precisely, we use automatic differentiation with the following combination of properties:\n",
    "* *First* and *Second* order. The variables used encode gradient and (sometimes) hessian information.\n",
    "* *Dense*. The Taylor expansion information - gradient and hessian - is stored in dense (full) form. This is practical for functions with arbitrary complexity, but low dimensional input.\n",
    "* *Forward*. The Taylor expansion information is propagated forward along with the computations.\n",
    "\n",
    "**Known bugs and incompatibilities.** Our implementation of automatic differentiation is based on subclassing the numpy array class. While simple and powerful, this approach suffers from a few pitfalls, described in the notebook [ADBugs](ADBugs.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Algorithmic tools, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. A word on Hamilton's equations](#1.-A-word-on-Hamilton's-equations)\n",
    "    * [1.1 Optics and geodesics](#1.1-Optics-and-geodesics)\n",
    "    * [1.2 Celestial mechanics](#1.2-Celestial-mechanics)\n",
    "    * [1.3 The Lotka-Volterra Predator-Prey model](#1.3-The-Lotka-Volterra-Predator-Prey-model)\n",
    "    * [1.4 Using the Hamiltonian class](#1.4-Using-the-Hamiltonian-class)\n",
    "  * [2. Automatic differentiation basics](#2.-Automatic-differentiation-basics)\n",
    "    * [2.1 Differentiating a function](#2.1-Differentiating-a-function)\n",
    "    * [2.2 Differentiating w.r.t several variables](#2.2-Differentiating-w.r.t-several-variables)\n",
    "    * [2.3 Vectorization](#2.3-Vectorization)\n",
    "    * [2.4 Second order automatic differentiation](#2.4-Second-order-automatic-differentiation)\n",
    "    * [2.5 The gradient and hessian member functions](#2.5-The-gradient-and-hessian-member-functions)\n",
    "  * [3. Solving ordinary differential equations](#3.-Solving-ordinary-differential-equations)\n",
    "    * [3.1 Explicit Euler scheme](#3.1-Explicit-Euler-scheme)\n",
    "    * [3.2 High order explicit schemes](#3.2-High-order-explicit-schemes)\n",
    "    * [3.3 Symplectic Euler scheme - Separable case](#3.3-Symplectic-Euler-scheme---Separable-case)\n",
    "    * [3.4 Symplectic Verlet scheme - Separable case](#3.4-Symplectic-Verlet-scheme---Separable-case)\n",
    "    * [3.5 Symplectic Euler scheme - Non separable case](#3.5-Symplectic-Euler-scheme---Non-separable-case)\n",
    "    * [3.6 The symplectic form](#3.6-The-symplectic-form)\n",
    "  * [4. Shooting geodesics](#4.-Shooting-geodesics)\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgement.** Some of the experiments presented in these notebooks are part of \n",
    "ongoing research with Ludovic Métivier and Da Chen.\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, Centre Borelli, ENS Paris-Saclay, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\") # Allow importing agd from parent directory\n",
    "#from Miscellaneous import TocTools; print(TocTools.displayTOC('Dense','Algo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agd import AutomaticDifferentiation as ad\n",
    "from agd.ODE.hamiltonian import GenericHamiltonian,SeparableHamiltonian,fixedpoint\n",
    "from agd import LinearParallel as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_infinity = ad.Optimization.norm_infinity\n",
    "\n",
    "def norm_infinity_ad(x):\n",
    "    \"\"\"Check that the zeroth, first and (possibly) second order content of x\"\"\"\n",
    "    if isinstance(x,ad.Dense.denseAD):  \n",
    "        return max(norm_infinity(x.value),norm_infinity(x.coef))\n",
    "    if isinstance(x,ad.Dense.denseAD2): \n",
    "        return max(norm_infinity(x.value),norm_infinity(x.coef1),norm_infinity(x.coef2))\n",
    "    raise ValueError(\"Not a Dense AD variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_packages():\n",
    "    from Miscellaneous.rreload import rreload\n",
    "    global ad,lp,GenericHamiltonian,SeparableHamiltonian\n",
    "    [ad,lp,GenericHamiltonian,SeparableHamiltonian] = rreload([ad,lp,GenericHamiltonian,SeparableHamiltonian],rootdir=\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A word on Hamilton's equations\n",
    "\n",
    "We choose to illustrate the automatic differentiation concept using Hamilton's equations of geodesics, which read\n",
    "$$\n",
    "    \\dot q = \\partial_p H(q,p), \\qquad \\dot p = -\\partial_q H(q,p),\n",
    "$$\n",
    "where $H$ is the *Hamiltonian* of the medium. \n",
    "These equations are (extremely) common in optics and mechanics. They naturally involve first-order differentiation. In addition, higher order differentiation will also be necessary in the context of geodesic shooting (adjusting the initial conditions to meet a prescribed endpoint), or implicit schemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Optics and geodesics\n",
    "\n",
    "Hamilton's equations characterize extremal paths, known as geodesics, arising in optics.\n",
    "Following the classical convention we denote by \n",
    "* $q$ the position variable,\n",
    "* $p$ the impultion, which is dual to the velocity.\n",
    "\n",
    "**Riemannian Hamiltonian.** For a domain $\\Omega \\subset R^d$ equipped with a Riemannian metric $M : \\Omega \\to S_d^{++}$, the Hamiltonian is defined as \n",
    "$$\n",
    "    H(q,p) := \\frac 1 2 \\|p\\|_{D(q)}^2, \\quad \\text{where} D(q) := M(q)^{-1}.\n",
    "$$\n",
    "\n",
    "**Poincaré's half plane model.** \n",
    "We illustrate this ODE in the case of Poincaré's half plane model of the hyperbolic space, defined by the Riemannian metric\n",
    "$$\n",
    "    M(q) := \\frac{\\mathrm{Id}}{q_1^2},\n",
    "$$\n",
    "where $q = (q_0,q_1) \\in \\Omega = R \\times R^{++}$. Thus $H(q,p) = (q_1^2/2) \\|p\\|^2$. \n",
    "\n",
    "**Exponential map.**\n",
    "We also consider the Riemannian metric on $R^2 \\setminus \\{0\\}$ defined by\n",
    "$$\n",
    "    M(q) := \\frac{\\mathrm{Id}}{\\|q\\|^2}.\n",
    "$$\n",
    "It can be regarded as the metric induced by the logarithmic (multivalued) map $\\ln : C \\setminus \\{0\\} \\to C$, where the targer space $C$ is equipped with the usual norm, and it possesses periodic trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SquaredNorm(p):\n",
    "    return (p**2).sum(axis=0)\n",
    "def H_HalfPlane(q,p):\n",
    "    return 0.5*q[1]**2*SquaredNorm(p)\n",
    "def H_Log(q,p):\n",
    "    return 0.5*SquaredNorm(q)*SquaredNorm(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Celestial mechanics\n",
    "\n",
    "The Hamiltonian is in this case the sum of the kinetic energy, and of the potential energy, say w.r.t. a mass at the origin.\n",
    "\n",
    "<!---\n",
    "**Symplectic integrators**\n",
    "In this notebook, we solve the equations of geodesics using a standard Runge-Kutta scheme. This may sound as a heresy since these equations benefit from a Hamiltonian structure, and can thus be solved more stably using a symplectic integrator, in principle. However, our Hamiltonians are *non-separable*, in other words they do *not* take the form \n",
    "$$\n",
    "    H(q,p) = F(p) + V(q).\n",
    "$$\n",
    "For this reason, the implementation details of a symplectic scheme are non-trivial, and we thus stick to a standard ODE scheme.\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_Celestial(q,p):\n",
    "    return 0.5*SquaredNorm(p) - SquaredNorm(q)**-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The Lotka-Volterra Predator-Prey model\n",
    "\n",
    "Some models in appeareance unrelated with mechanics or optics also exhibit a Hamiltonian structure. This is the case of the Lotka-Voltera Predator-Prey model, depending on parameters $\\alpha,\\beta,\\gamma,\\delta \\in R$\n",
    "$$\n",
    "    \\dot x = x (\\alpha-\\beta y), \\qquad \\dot y = y(\\delta x-\\gamma).\n",
    "$$\n",
    "Using a logarithmic change of variables, $q=\\ln x$ and $p=\\ln y$, this model can be put in Hamiltonian form, with\n",
    "$$\n",
    "    H(q,p) = \\alpha p - \\beta e^p + \\gamma q - \\delta e^q.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LotkaVolterra_params = (1.,1.,1.,1.)\n",
    "def H_LotkaVolterra(q,p,params=LotkaVolterra_params):\n",
    "    alpha,beta,gamma,delta=params\n",
    "    return alpha*p - beta*np.exp(p) + gamma*q-delta*np.exp(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Using the Hamiltonian class\n",
    "\n",
    "Since Hamiltonian structures are quite common in mathematics, a Hamiltonian class is provided, which implements most of the operations presented in this notebook. It does rely on automatic differentiation as well, but hides these  details internal internally. We check here that it reproduces the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-separable Hamiltonians\n",
    "HalfPlane = GenericHamiltonian(H_HalfPlane)\n",
    "Log = GenericHamiltonian(H_Log)\n",
    "\n",
    "# Separable Hamiltonian\n",
    "alpha,beta,gamma,delta=LotkaVolterra_params\n",
    "LotkaVolterra = SeparableHamiltonian( lambda q:gamma*q - delta*np.exp(q), lambda p:alpha*p - beta*np.exp(p) )\n",
    "LotkaVolterra.vdim=None # Uses scalar variables\n",
    "\n",
    "# Separable Hamiltonian with a quadratic structure in the second variable\n",
    "Celestial = SeparableHamiltonian( lambda q:-SquaredNorm(q)**-0.5, lambda p:0.5*SquaredNorm(p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the Hamiltonians defined as functions or classes, for comparison purposes\n",
    "HClass = [HalfPlane,Log,Celestial] \n",
    "HFun = [H_HalfPlane,H_Log,H_Celestial] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Automatic differentiation basics\n",
    "\n",
    "We illustrate the automatic differentiation mechanism by differentiating a Hamiltonian w.r.t. the position $q$ and momentum $p$, which is a prerequisite for implementing Hamilton's ODE of motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Differentiating a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamiltonian = H_HalfPlane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([0.,1.])\n",
    "p = np.array([1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order access the Hamiltonian's derivatives, say with respect to position, we evaluate it on a variable featuring first order information. Said otherwise, we create a variable representing the first order Taylor expansion\n",
    "$$\n",
    "    q_\\mathrm{ad} = (q_0+\\delta_0,q_1+\\delta_1) + O(\\|\\delta\\|^2),\n",
    "$$\n",
    "where $\\delta = (\\delta_0,\\delta_1)$ is a symbolic, infinitesimal perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ad = ad.Dense.identity(constant=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array([0., 1.]),\n",
       "array([[1., 0.],\n",
       "       [0., 1.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ad # Contains an additional array representing first order information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-th order :  [0. 1.]\n",
      "First order : \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero-th order : \",q_ad.value)\n",
    "print(\"First order : \\n\",q_ad.coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first order information is propagated through the computations, and eventually we obtain the result\n",
    "$$\n",
    "    H(q_\\mathrm{ad},p) = H(q,p) + <\\nabla_q H(q,p),\\delta> + O(\\|\\delta\\|^2).\n",
    "$$\n",
    "Note that, for Poincaré's half plane model, one has $\\nabla_q H(q,p) = (0,q_1 \\|p\\|^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array(1.),array([0., 2.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q_ad,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the Hamiltonian w.r.t. the variable q :  [0. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient of the Hamiltonian w.r.t. the variable q : \",Hamiltonian(q_ad,p).gradient())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly differentiate w.r.t. the momentum $p$. Poincaré's half plane model obeys\n",
    "$\\nabla_p H(q,p) = q_1^2 p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array(1.),array([1., 1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ad = ad.Dense.identity(constant=p)\n",
    "Hamiltonian(q,p_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing with the Hamiltonian class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Cls,Fun in zip(HClass,HFun):\n",
    "    assert norm_infinity( Cls.H(q,p) - Fun(q,p) ) < 1e-14\n",
    "    assert norm_infinity( Cls.DqH(q,p) - Fun(q_ad,p).gradient() ) < 1e-14\n",
    "    assert norm_infinity( Cls.DpH(q,p) - Fun(q,p_ad).gradient() ) < 1e-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Differentiating w.r.t several variables\n",
    "\n",
    "Evaluating $H(q_\\mathrm{ad},p_\\mathrm{ad})$ yields an result may sound unexpected: we obtain the sum $\\nabla_q H(q,p)+\\nabla_p H(q,p)$ of the gradients, instead of their independent values. Indeed, this follows from the first order Taylor expansion\n",
    "$$\n",
    "H(q+\\delta,p+\\delta) = \n",
    "H(q,p) + <\\nabla_q H(q,p),\\delta> + <\\nabla_p H(q,p),\\delta> + O(\\|\\delta\\|^2),\n",
    "$$\n",
    "where $\\delta = (\\delta_0,\\delta_1)$ is an infinitesimal symbolic perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array(1.),array([1., 3.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q_ad,p_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the gradient of $H$ w.r.t the independent variables $q$ and $p$, we need to specify that the corresdponding infinitesimal perturbations are independent. Namely set\n",
    "$$\n",
    "    q_\\mathrm{ad} = q+(\\delta_0,\\delta_1), \\quad p_\\mathrm{ad} = p+(\\delta_2,\\delta_3),\n",
    "$$\n",
    "where $(\\delta_0,\\cdots,\\delta_4)$ is four dimensional infinitesimal perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ad = ad.Dense.identity(constant=q,shift=(0,p.size))\n",
    "p_ad = ad.Dense.identity(constant=p,shift=(q.size,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, we obtain the full gradient of $H$, which is the concatenation of $\\nabla_q H$ and $\\nabla_p H$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array(1.),array([0., 2., 1., 1.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q_ad,p_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array([0., 1.]),\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array([1., 1.]),\n",
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply independent perturbations to a sequence of variables.**\n",
    "The `register` function takes care of shifting the perturbations adequately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ad_,p_ad_ = ad.Dense.register((q,p))\n",
    "for a,b in zip( (q_ad_,p_ad_), (q_ad,p_ad)):\n",
    "    assert norm_infinity_ad(a-b)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vectorization\n",
    "\n",
    "A common programming style in Python application to numerics is vectorized computations using numpy tensors.\n",
    "This allows avoiding loops, when some operation has to be repeated a large number of times, with improvements in clarity, flexibility, and speed. \n",
    "\n",
    "As an example, we compute $H(q_0,p_0)$, $H(q_1,p_1)$, $H(q_2,p_2)$, where $q_0,q_1,q_2$ and $p_0,p_1,p_2$ are different positions and impulsions. We also differentiate these values w.r.t. the impulsion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = np.array([0.,1.]); q1 = np.array([1.,1.]); q2 = np.array([-2.,1.]); \n",
    "p0 = np.array([1.,1.]); p1 = np.array([1.,0.]); p2 = np.array([-1.,-1.]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5, 1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q0,p0), Hamiltonian(q1,p1), Hamiltonian(q2,p2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[denseAD(array(1.),array([1., 1.])),\n",
       " denseAD(array(0.5),array([1., 0.])),\n",
       " denseAD(array(1.),array([-1., -1.]))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham_seq = [Hamiltonian(q,ad.Dense.identity(constant=p)) for (q,p) in ((q0,p0), (q1,p1), (q2,p2))]\n",
    "Ham_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorized form of these computations is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec = np.stack( (q0,q1,q2),axis=1)\n",
    "p_vec = np.stack( (p0,p1,p2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.5, 1. ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q_vec,p_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec_ad = ad.Dense.identity(constant=p_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the automatic differentiation result may not be what is desired. Indeed, the entries of `q_vec` are all considered independent, and we recover a six dimensional gradient vector for each component. This is both impractical and numerically expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array([1. , 0.5, 1. ]),\n",
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  0.,  0., -1.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham_vec = Hamiltonian(q_vec,p_vec_ad)\n",
    "Ham_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential result :  denseAD(1.0,[1. 1.])\n",
      "Vectorized result :  denseAD(1.0,[1. 0. 0. 1. 0. 0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sequential result : \",Ham_seq[0])\n",
    "print(\"Vectorized result : \",Ham_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, and in contrast with the previous section, we would like the perturbations to be regarded as dependent. This is achieved with the following parameters:\n",
    "* `shape_free` : apply free independent symbolic perturbations w.r.t. these dimensions.\n",
    "* `shape_bound` : apply bound correlated symbolic perturbations w.r.t. these dimensions.\n",
    "\n",
    "It is assumed that the *free* dimensions come first, and the *bound* dimensions come last. Only one of the two parameters `shape_free` and `shape_bound` needs to be specified, since they are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension is *free*, and the last one is *bound* since it is only introduced for vectorization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_free,shape_bound = p_vec.shape[:1], p_vec.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec_ad = ad.Dense.identity(constant=p_vec, shape_bound=shape_bound)\n",
    "#p_vec_ad = ad.Dense.identity(constant=p_vec, shape_free=shape_free) # Equivalently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized result (with shape_bound): \n",
      " denseAD([1.  0.5 1. ],\n",
      "[[ 1.  1.]\n",
      " [ 1.  0.]\n",
      " [-1. -1.]])\n"
     ]
    }
   ],
   "source": [
    "Ham_vec = Hamiltonian(q_vec,p_vec_ad)\n",
    "print(\"Vectorized result (with shape_bound): \\n\", Ham_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is compatible with differentiation w.r.t. multiple independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec_ad = ad.Dense.identity(constant=q_vec, shape_free=shape_free, shift=(0,len(p_vec)) )\n",
    "p_vec_ad = ad.Dense.identity(constant=p_vec, shape_free=shape_free, shift=(len(q_vec),0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array([1. , 0.5, 1. ]),\n",
       "array([[ 0.,  2.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.,  0.],\n",
       "       [ 0.,  2., -1., -1.]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham_vec = Hamiltonian(q_vec_ad,p_vec_ad)\n",
    "Ham_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full gradient w.r.t q0,p0 :  denseAD(1.0,[0. 2. 1. 1.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Full gradient w.r.t q0,p0 : \", Ham_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `register` function takes car of the shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec_ad_,p_vec_ad_ = ad.Dense.register((q_vec,p_vec), shape_bound=shape_bound)\n",
    "for a,b in zip( (q_vec_ad_,p_vec_ad_), (q_vec_ad,p_vec_ad) ):\n",
    "    assert  norm_infinity_ad(a-b) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative implementation using arrays of arrays.** Another way to achieve vectorization is to use 'arrays of arrays'. This approach is not recommended here, since it is more cumbersome and less efficient, but it is still shown for completeness and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_diss = ad.disassociate(q_vec, shape_free=(2,), # Creates an array of arrays\n",
    "                         expand_free_dims=None, expand_bound_dims=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An array of arrays : [array([ 0.,  1., -2.]) array([1., 1., 1.])]\n",
      "First element : [ 0.  1. -2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"An array of arrays :\", q_diss)\n",
    "print(\"First element :\", q_diss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is safer to avoid scalar arrays in the context of 'arrays of arrays'. Indeed, confusion aries otherwise between 'arrays scalars with array components', and 'standard arrays'. The default for `ad.disassociate` is to introduce singleton dimensions to ensure this behavior is avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_diss = ad.disassociate(q_vec, shape_free=(2,)) \n",
    "p_diss = ad.disassociate(p_vec, shape_free=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disassociated array  [[array([[ 0.],\n",
      "         [ 1.],\n",
      "         [-2.]])]\n",
      " [array([[1.],\n",
      "         [1.],\n",
      "         [1.]])]]\n",
      "with type  <class 'numpy.ndarray'> with data type  object and shape  (2, 1) including a trailing singleton.\n",
      "Reconstructed array [[ 0.  1. -2.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Disassociated array \", q_diss)\n",
    "print(\"with type \", type(q_diss), \"with data type \", q_diss.dtype, \n",
    "      \"and shape \", q_diss.shape, \"including a trailing singleton.\")\n",
    "print(\"Reconstructed array\", ad.associate(q_diss)) # Inverse operation to disassociate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now manipulate `q_diss` and `p_diss` as standard low-dimensional arrays, abstracting the underlying vectorization, and in particular use the AD tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[1. ],\n",
       "              [0.5],\n",
       "              [1. ]])], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q_diss,p_diss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_diss_ad = ad.Dense.identity(constant=q_diss,shift=(0,2))\n",
    "p_diss_ad = ad.Dense.identity(constant=p_diss,shift=(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ham_diss_ad = Hamiltonian(q_diss_ad,p_diss_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD(array([1. , 0.5, 1. ]),\n",
       "array([[ 0.,  2.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.,  0.],\n",
       "       [ 0.,  2., -1., -1.]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.associate(Ham_diss_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison with the Hamiltonian class**\n",
    "\n",
    "The Hamiltonian class needs to know about the number of independent components, in order to deal with multi-dimensional arrays appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "HalfPlane.shape_free = (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert norm_infinity_ad(Ham_vec - ad.associate(Ham_diss_ad)) < 1e-14\n",
    "assert norm_infinity(HalfPlane.H(q_vec,p_vec) - Ham_vec.value) < 1e-14\n",
    "assert norm_infinity(HalfPlane.DqH(q_vec,p_vec) - Ham_vec.gradient()[:2]) < 1e-14\n",
    "assert norm_infinity(HalfPlane.DpH(q_vec,p_vec) - Ham_vec.gradient()[2:]) < 1e-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Second order automatic differentiation\n",
    "\n",
    "There are situations where second order automatic differentiation is needed. It could be achieved, in principle, by recursive calls to first order differentiation. However, for reasons of performance and convenience, a dedicated class is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ad = ad.Dense2.identity(constant=q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hessian of Poincaré's half plane model hamiltonian, w.r.t. position is \n",
    "$$\n",
    "    \\nabla^2_q H(q,p) = \\begin{pmatrix} 0 & 0 \\\\ 0 & \\|p\\|^2 \\end{pmatrix}\n",
    "$$\n",
    "and w.r.t. impulsion\n",
    "$$\n",
    "    \\nabla^2_p H(q,p) = q_0^2 \\mathrm{Id}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([0., 2.]),\n",
       "array([[0., 0.],\n",
       "       [0., 2.]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham = Hamiltonian(q_ad,p)\n",
    "Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function value :  1.0\n",
      "Gradient :  [0. 2.]\n",
      "Hessian : \n",
      " [[0. 0.]\n",
      " [0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Function value : \", Ham.value)\n",
    "print(\"Gradient : \", Ham.coef1)\n",
    "print(\"Hessian : \\n\", Ham.coef2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ad = ad.Dense2.identity(constant=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([1., 1.]),\n",
       "array([[1., 0.],\n",
       "       [0., 1.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q,p_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A joint hessian, of size $4\\times 4$, can be computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ad = ad.Dense2.identity(constant=q, shift=(0,p.size))\n",
    "p_ad = ad.Dense2.identity(constant=p, shift=(q.size,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ad.coef2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([0., 2., 1., 1.]),\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 2., 2., 2.],\n",
       "       [0., 2., 1., 0.],\n",
       "       [0., 2., 0., 1.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamiltonian(q_ad,p_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization works as in the first order case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec_ad = ad.Dense2.identity(constant=q_vec, shape_free=shape_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([0., 2.]),\n",
       "array([[0., 0.],\n",
       "       [0., 2.]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham = Hamiltonian(q_vec_ad,p_vec)\n",
    "Ham[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec_ad = ad.Dense2.identity(constant=q_vec,shape_bound=shape_bound, shift=(0,len(p_vec)) )\n",
    "p_vec_ad = ad.Dense2.identity(constant=p_vec,shape_bound=shape_bound, shift=(len(q_vec),0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([0., 2., 1., 1.]),\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 2., 2., 2.],\n",
       "       [0., 2., 1., 0.],\n",
       "       [0., 2., 0., 1.]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham = Hamiltonian(q_vec_ad,p_vec_ad)\n",
    "Ham[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative approach using recursive automatic differentiation.** \n",
    "We present an alternative approach to second order automatic differentiation, based on recursive first order differentiation. It is not recommended, since it is more cumbersome and less efficient, but it is still shown for completeness and testing.\n",
    "\n",
    "<!---We can reconstruct the second order AD information by associating two levels of first order differentiation.\n",
    "Note the parameter `singleton_axis=-2`, replacing the default `singleton_axis=-1`, because the last axis is for the AD dimension.--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADRecIdentity(constant,shape_free=None,shift=(0,0)):\n",
    "    # First order differentiation\n",
    "    q_ad = ad.Dense.identity(constant=constant, shape_free=shape_free, shift=shift) \n",
    "    # Hide automatic differentiation info in the component type\n",
    "    q_diss = ad.disassociate(q_ad, shape_free=shape_free) \n",
    "    # Recursive first order differentiation\n",
    "    q_ad2 = ad.Dense.identity(constant=q_diss, shape_free=shape_free, shift=shift) \n",
    "    return q_ad2\n",
    "\n",
    "def ADRecToAD2(q): \n",
    "    q01 = ad.associate(q.value) # Zero-th and first order\n",
    "    q12 = ad.associate(q.coef,squeeze_free_dims=-2) # first and second order\n",
    "    q12 = np.moveaxis(q12,q.ndim-1,-1) # Put ad information last\n",
    "    return ad.Dense2.denseAD2(q01.value,q01.coef,q12.coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_rec = ADRecIdentity(q,shape_free=(2,), shift=(0,2))\n",
    "p_rec = ADRecIdentity(p,shape_free=(2,), shift=(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([0., 2., 1., 1.]),\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 2., 2., 2.],\n",
       "       [0., 2., 1., 0.],\n",
       "       [0., 2., 0., 1.]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham_rec = Hamiltonian(q_rec,p_rec)\n",
    "ADRecToAD2(Ham_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec_rec = ADRecIdentity(q_vec, shape_free=(2,), shift=(0,2))\n",
    "p_vec_rec = ADRecIdentity(p_vec, shape_free=(2,), shift=(2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "denseAD2(array(1.),array([0., 2., 1., 1.]),\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 2., 2., 2.],\n",
       "       [0., 2., 1., 0.],\n",
       "       [0., 2., 0., 1.]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ham_vec_rec = Hamiltonian(q_vec_rec,p_vec_rec)\n",
    "ADRecToAD2(Ham_vec_rec)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 The gradient and hessian member functions\n",
    "\n",
    "Automatic differentiation allows to compute the gradient and hessian of a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An array of shape (3,), and AD information w.r.t 4 independent variables\n"
     ]
    }
   ],
   "source": [
    "print(f\"An array of shape {Ham.shape}, and AD information w.r.t {Ham.size_ad} independent variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, the coefficients corresponding to differentiation of are stored last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal storage has derivatives last.\n",
      "first order: (3, 4), second order: (3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Internal storage has derivatives last.\")\n",
    "print(f\"first order: {Ham.coef1.shape}, second order: {Ham.coef2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, for practical purposes it is often desirable to move them first. This is the role of the `gradient` and `hessian` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface moves derivatives first.\n",
      "gradient: (4, 3), hessian: (4, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Interface moves derivatives first.\")\n",
    "print(f\"gradient: {Ham.gradient().shape}, hessian: {Ham.hessian().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solving ordinary differential equations\n",
    "\n",
    "We implement Hamilton's equations of motion\n",
    "$$\n",
    "    \\dot q = \\partial_p H(q,p), \\qquad \\dot p = -\\partial_q H(q,p),\n",
    "$$\n",
    "using several numerical schemes. In terms of automatic differentiation, the most interesting case is the semi-implicit Symplectic Euler scheme.\n",
    "\n",
    "**Conserved quantity.**\n",
    "By construction, the Hamiltonian value is conserved along the Hamiltonian flow:\n",
    "$$\n",
    "    H(q(t),p(t)) = \\mathrm{cst},\n",
    "$$\n",
    "if $t \\mapsto (q(t),p(t))$ is a solution to Hamilton's equations of motion.\n",
    "\n",
    "**Explicit solution for the half plane model.**\n",
    "The geodesics for the Poincare half plane model are known explicitly. They are half circles whose center lies on the horizontal axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Explicit Euler scheme\n",
    "\n",
    "The simplest of all ODE solvers reads\n",
    "$$\n",
    "    \\frac{q_{n+1}-q_n} {\\Delta t} = \\partial_p H(q_n,p_n), \\qquad \\frac{p_{n+1}-p_n} {\\Delta t} = -\\partial_q H(q_n,p_n),\n",
    "$$\n",
    "where $(q_0,p_0)$ is a given initial condition, and $n>0$ is the iteration number, and $\\Delta t$ is the time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EulerStep(q,p,H,dt):\n",
    "    d=len(q)\n",
    "    q_ad = ad.Dense.identity(constant=q,shape_free=(d,),shift=(0,d))\n",
    "    p_ad = ad.Dense.identity(constant=p,shape_free=(d,),shift=(d,0))\n",
    "    grad = H(q_ad,p_ad).gradient()\n",
    "    return q+dt*grad[d:],p-dt*grad[:d]\n",
    "\n",
    "def Geodesic(q0,p0,H,t,n=100,step=EulerStep):\n",
    "    dt=t/n\n",
    "    q,p=q0.copy(),p0.copy()\n",
    "    Q,P=[q],[p]\n",
    "    for i in range(n):\n",
    "        q,p=step(q,p,H,dt)\n",
    "        Q.append(q)\n",
    "        P.append(p)\n",
    "    # For convenience, we put time as a second coordinate.\n",
    "    return np.stack(Q,axis=1),np.stack(P,axis=1),np.linspace(0,t,n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euler's explicit scheme is only first order accurate. While the geodesic circular shape is more or less observed, the Hamiltonian conservation is far from perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,P,T = Geodesic(q_vec,p_vec,Hamiltonian,4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Poincare geodesic (Explicit euler)\")\n",
    "plt.plot(Q[0],Q[1]); plt.axhline(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Poincare Hamiltonian (Explicit euler)\")\n",
    "plt.plot(T,Hamiltonian(Q,P));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 High order explicit schemes\n",
    "\n",
    "A natural approach to improve the ODE solver is to increase its consistency order. This can be achieved using Runge-Kutta methods, here of second and fourth order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SymplecticGradient(q,p,H):\n",
    "    d=len(q)\n",
    "    q_ad = ad.Dense.identity(constant=q,shape_free=(d,),shift=(0,d))\n",
    "    p_ad = ad.Dense.identity(constant=p,shape_free=(d,),shift=(d,0))\n",
    "    grad = H(q_ad,p_ad).gradient()\n",
    "    return grad[d:],-grad[:d]\n",
    "\n",
    "def RK2Step(q,p,H,dt):\n",
    "    k1 = SymplecticGradient(q,p,H)\n",
    "    k2 = SymplecticGradient(q+0.5*dt*k1[0],p+0.5*dt*k1[1],H)\n",
    "    return q+dt*k2[0],p+dt*k2[1]\n",
    "\n",
    "def RK4Step(q,p,H,dt):\n",
    "    k1 = SymplecticGradient(q,p,H)\n",
    "    k2 = SymplecticGradient(q+0.5*dt*k1[0],p+0.5*dt*k1[1],H)\n",
    "    k3 = SymplecticGradient(q+0.5*dt*k2[0],p+0.5*dt*k2[1],H)\n",
    "    k4 = SymplecticGradient(q+dt*k3[0],p+dt*k3[1],H)\n",
    "    return q+dt*(k1[0]+2*k2[0]+2*k3[0]+k4[0])/6.,p+dt*(k1[1]+2*k2[1]+2*k3[1]+k4[1])/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2,P2,T = Geodesic(q_vec,p_vec,Hamiltonian,4.,step=RK2Step)\n",
    "Q4,P4,T = Geodesic(q_vec,p_vec,Hamiltonian,4.,step=RK4Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Poincare geodesic (Explicit solvers)\")\n",
    "plt.plot(Q[0],Q[1], Q2[0],Q2[1], Q4[0],Q4[1]); plt.axhline(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the Hamiltonian is almost exactly constant for the second and fourth order models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Poincare Hamiltonian (Runge-Kutta)\")\n",
    "plt.plot(T,Hamiltonian(Q2,P2), T,Hamiltonian(Q4,P4)); #T,Hamiltonian(Q,P),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cone model.**\n",
    "However, if the trajectory is long enough, and the time step is large enough, then even the high order models fail to conserve the Hamiltonian. This is evidenced with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamiltonian = H_Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,p = np.array([1,0]),np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,P,T = Geodesic(q,p,Hamiltonian,6.,step=EulerStep)\n",
    "Q2,P2,T2 = Geodesic(q,p,Hamiltonian,25.,step=RK2Step)\n",
    "Q4,P4,T4 = Geodesic(q,p,Hamiltonian,75.,step=RK4Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Cone model (Explicit solvers)\")\n",
    "plt.plot(Q[0],Q[1], Q2[0],Q2[1], Q4[0],Q4[1]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Cone Hamiltonian (Explicit solvers)\")\n",
    "plt.plot(T,Hamiltonian(Q,P), T2,Hamiltonian(Q2,P2), T4,Hamiltonian(Q4,P4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, in the celestial mechanics case, the Hamiltonian drifts with time using the Euler explicit and Runge-Kutta schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamiltonian = H_Celestial\n",
    "q,p = np.array([1.,0.]),np.array([0.3,0.7])\n",
    "t = 10.\n",
    "Q,P,T = Geodesic(q,p,Hamiltonian,t,step=EulerStep,n=int(100*t))\n",
    "Q2,P2,T2 = Geodesic(q,p,Hamiltonian,t,step=RK2Step,n=int(20*t))\n",
    "Q4,P4,T4 = Geodesic(q,p,Hamiltonian,t,step=RK4Step,n=int(8*t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Poincare geodesic (Explicit solvers)\")\n",
    "plt.plot(Q[0],Q[1], Q2[0],Q2[1], Q4[0],Q4[1]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T,Hamiltonian(Q,P), T2,Hamiltonian(Q2,P2), T4,Hamiltonian(Q4,P4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison with the Hamiltonian class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_,P_,T_    = Celestial.integrate(q,p,scheme=\"Euler\",niter=int(100*t),T=t,path=True)\n",
    "Q2_,P2_,T2_ = Celestial.integrate(q,p,scheme=\"Runge-Kutta-2\", niter=int(20*t),  T=t,path=True)\n",
    "Q4_,P4_,T4_ = Celestial.integrate(q,p,scheme=\"Runge-Kutta-4\", niter=int(8*t),   T=t,path=True)\n",
    "for a,b in zip( (Q_,P_,T_,Q2_,P2_,T2_,Q4_,P4_,T4_), (Q,P,T,Q2,P2,T2,Q4,P4,T4) ): \n",
    "    assert norm_infinity(a-b)<1e-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Symplectic Euler scheme - Separable case\n",
    "\n",
    "Symplectic schemes guarantee that a quantity, closely related with the Hamiltonian, is conserved along the trajectory. \n",
    "\n",
    "The Euler symplectic scheme is defined as follows:\n",
    "$$\n",
    "    \\frac{p_{n+1}-p_n}{\\Delta t} = -\\partial_q H(q_n,p_{n+1}), \\quad\n",
    "    \\frac{q_{n+1}-q_n}{\\Delta t} = \\partial_p H(q_n,p_{n+1}), \n",
    "$$\n",
    "Note that the scheme is semi-implicit, in view of the definition of $p_{n+1}$.\n",
    "Two cases must be distinguished for the implementation.\n",
    "* **Separable Hamiltonians.** If the Hamiltonian takes the form $H(q,p) = F(p) + V(q)$, then the Euler symplectic scheme becomes explicit. The Celestial Mechanics and Lotka-Volterra schemes fall in that category.\n",
    "* **Non separable Hamiltonians.** If the Hamiltonian has a general form, then one can try to solve the implicit part of Euler's symplectic scheme using a Newton method. Another approach, not detailed here, is to introduce an higher dimensional separable Hamiltonian with the same dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SymplecticEulerStep_Separable(q,p,H,dt):\n",
    "    d=len(q)\n",
    "        \n",
    "    # Differentiate w.r.t. q and advance p\n",
    "    q_ad = ad.Dense.identity(constant=q,shape_free=(d,))\n",
    "    q_grad = H(q_ad,p).gradient() # We can use p thanks to separability\n",
    "    p1 = p-dt*q_grad\n",
    "    \n",
    "    # Differentiate w.r.t. p and advance q\n",
    "    p1_ad = ad.Dense.identity(constant=p1,shape_free=(d,))\n",
    "    p1_grad = H(q,p1_ad).gradient()\n",
    "    q1 = q+dt*p1_grad\n",
    "\n",
    "    return q1,p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamiltonian = H_Celestial\n",
    "q,p = np.array([1,0]),np.array([0.3,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 20.\n",
    "QS,PS,TS = Geodesic(q,p,Hamiltonian,t,step=SymplecticEulerStep_Separable,n=int(30*t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symplectic Euler scheme is only first order accurate, but it has the property that the Hamiltonian remains bounded above and below during the evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Celestial mechanics (Euler symplectic)\")\n",
    "plt.plot(QS[0],QS[1]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Hamiltonian conservation (Euler symplectic)\")\n",
    "plt.plot(TS,Hamiltonian(QS,PS));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Symplectic Verlet scheme - Separable case\n",
    "\n",
    "The Verlet method is a second order symplectif integration scheme. It is explicit if the Hamiltonian is separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SymplecticVerletStep_Separable(q,p,H,dt):\n",
    "    d=len(q)\n",
    "    \n",
    "    # Differentiate w.r.t. q and advance p\n",
    "    q_ad = ad.Dense.identity(constant=q,shape_free=(d,))\n",
    "    q_grad = H(q_ad,p).gradient()\n",
    "    p1 = p-0.5*dt*q_grad\n",
    "    \n",
    "    # Differentiate w.r.t. p and advance q\n",
    "    p1_ad = ad.Dense.identity(constant=p1,shape_free=(d,))\n",
    "    p1_grad = H(q,p1_ad).gradient()\n",
    "    q1 = q+dt*p1_grad\n",
    "    \n",
    "    # Differentiate w.r.t. q and advance p\n",
    "    q1_ad = ad.Dense.identity(constant=q1,shape_free=(d,))\n",
    "    q1_grad = H(q1_ad,p1).gradient()\n",
    "    p2 = p1-0.5*dt*q1_grad\n",
    "    \n",
    "    return q1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamiltonian = H_Celestial\n",
    "q,p = np.array([1.,0.]),np.array([0.3,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 20.\n",
    "QV,PV,TV = Geodesic(q,p,Hamiltonian,t,step=SymplecticVerletStep_Separable,n=int(30*t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that the Verlet scheme, in the separable case, amounts to the symplecting Euler scheme shifted by half a time step. Visually, their output is therefore quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Celestial mechanics (Verlet symplectic)\")\n",
    "plt.plot(QV[0],QV[1]); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improved accuracy is more obvious on the Hamiltonian conservation than on the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Hamiltonian conservation (Verlet symplectic vs Euler symplectic)\")\n",
    "plt.plot(TV,Hamiltonian(QV,PV), TS,Hamiltonian(QS,PS) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison with the Hamiltonian class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "QS_,PS_,TS_ = Celestial.integrate(q,p,scheme=\"Euler-p\", niter=int(30*t),T=t,path=True)\n",
    "QV_,PV_,TV_ = Celestial.integrate(q,p,scheme=\"Verlet-p\",niter=int(30*t),T=t,path=True)\n",
    "for a,b in zip( (QS_,PS_,TS_,QV_,PV_,TV_), (QS,PS,TS,QV,PV,TV) ): assert norm_infinity(a-b)<1e-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Symplectic Euler scheme - Non separable case\n",
    "\n",
    "We implement the general semi-implicit Symplectic Euler scheme using a Newton method for the implicit part.\n",
    "Our first step is to implement the Newton method.\n",
    "\n",
    "**Note on Newton versus Fixed point.**\n",
    "In the context of implicit schemes for geometric integration, fixed point iterations are often more computationally efficient than Newton iterations. We consider Newton iterations here for illustration of the AD library. The `Hamiltonian` class uses by default a fixed point solver for the implicit schemes.\n",
    "\n",
    "**Generic Newton solver.**\n",
    "A Newton solver is implemented in the `ad.Optimization` package, based on a similar approach using automatic , but with some additional flexibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewtonSolve(F,p0,niter=5,*args):\n",
    "    p_ad = ad.Dense.identity(constant=p0.copy(),shape_free=(len(p0),))\n",
    "    for i in range(niter):\n",
    "        p_ad = p_ad+F(p_ad,*args).solve()\n",
    "    return p_ad.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test it by solving $x+x^2=0$, with initial guess $x=0.5$. The solution $x=0$ is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.39659527e-16])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FTest(x):\n",
    "    return x+x**2\n",
    "NewtonSolve(FTest,np.array([0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, compatibility issues may arise if the function called $F$ itself uses automatic differentiation in its definition. This is the case of our numerical schemes, which involve the partial derivatives of the Hamiltonian. We circumvent this potential problem by hiding the AD information in the element type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewtonSolve_AD(F,p0,niter=5,*args):\n",
    "    d=len(p0)\n",
    "    def disac(x): return ad.disassociate(x,shape_free=(d,))\n",
    "    def assoc(x): return ad.associate(x)\n",
    "    p_ad = ad.Dense.identity(constant=p0.copy(),shape_free=(d,))\n",
    "    for i in range(niter):\n",
    "        p_ad = p_ad+assoc(F(disac(p_ad),*args)).solve()\n",
    "    return p_ad.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SymplecticEulerStep(q0,p0,H,dt):\n",
    "    d=len(q0)\n",
    "    \n",
    "    def F(p1):\n",
    "        # A potential issue is that p1 may have an additional singleton dimension,\n",
    "        # which is introduced in recursive AD techniques. So we must reshape q0 and p0 accordingly.\n",
    "        q0_,p0_= (a.reshape(p1.shape) for a in (q0,p0))    \n",
    "        \n",
    "        q0_ad = ad.Dense.identity(constant=q0_,shape_free=(d,))\n",
    "        q0_grad = H(q0_ad,p1).gradient()\n",
    "        return p1-p0_+dt*q0_grad\n",
    "    \n",
    "    p1 = NewtonSolve_AD(F,p0) # Implicit update of momentum\n",
    "    \n",
    "    p1_ad = ad.Dense.identity(constant=p1,shape_free=(d,))\n",
    "    p1_grad = H(q0,p1_ad).gradient()\n",
    "    q1=q0+dt*p1_grad # Explicit update of position\n",
    "    \n",
    "    return q1,p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the Hamiltonian is separable, then the semi-implicit scheme coincides with the explicit scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamiltonian = H_Celestial\n",
    "q,p = np.array([1.,0.]),np.array([0.3,0.7])\n",
    "qI,pI = SymplecticEulerStep(q,p,Hamiltonian,0.1) # Semi-implicit\n",
    "qE,pE = SymplecticEulerStep_Separable(q,p,Hamiltonian,0.1)\n",
    "for a,b in zip( (qI,pI), (qE,pE) ):\n",
    "    assert norm_infinity(a-b)<1e-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, only the semi-implicit implementation is truly symplectic for general hamiltonians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-implicit : (array([0.98989795, 0.1       ]), array([-0.10102051,  1.        ]))\n",
      "Explicit      : (array([0.99, 0.1 ]), array([-0.1,  1. ]))\n"
     ]
    }
   ],
   "source": [
    "Hamiltonian = H_Log\n",
    "q,p = np.array([1.,0.]),np.array([0.,1.])\n",
    "print(\"Semi-implicit :\", SymplecticEulerStep(q,p,Hamiltonian,0.1))\n",
    "print(\"Explicit      :\", SymplecticEulerStep_Separable(q,p,Hamiltonian,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 20.\n",
    "QI,PI,TI = Geodesic(q,p,Hamiltonian,t,step=SymplecticEulerStep,n=int(10*t))\n",
    "QS,PS,TS = Geodesic(q,p,Hamiltonian,t,step=SymplecticEulerStep_Separable,n=int(10*t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the two schemes is very accurate, since they are only first order. (In this specific example, one expects a closed geodesic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Cone model (Euler symplectic, separable or non-separable)\")\n",
    "plt.plot(QI[0],QI[1], QS[0],QS[1] ); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semi-implicit scheme almost perfectly conserves the Hamiltonian. This is in contrast with the explicit scheme which here makes the invalid assumption of separability. The goal is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Cone Hamiltonian, Euler alternating scheme\")\n",
    "plt.plot(TI,Hamiltonian(QI,PI), label=\"semi-implicit (symplectic)\")\n",
    "plt.plot(TS,Hamiltonian(QS,PS), label=\"explicit (non-symplectic)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison with the Hamiltonian class**\n",
    "\n",
    "The default implementation of implicit schemes in the Hamiltonian class uses a fixed point solver. A small discrepancy is observed with the Newton method, due to the convergence tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "QI_,PI_,TI_ = Log.integrate(q,p,scheme=\"Euler-p\", niter=int(10*t),T=t,path=True)\n",
    "for a,b in zip( (QI_,PI_,TI_), (QI,PI,TI) ): assert norm_infinity(a-b) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the stopping criterion of fixed point solver does improve concordance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log.impl_solver = lambda f,x : fixedpoint(f,x,tol=1e-14)\n",
    "QI_,PI_,TI_ = Log.integrate(q,p,scheme=\"Euler-p\", niter=int(10*t),T=t,path=True)\n",
    "for a,b in zip( (QI_,PI_,TI_), (QI,PI,TI) ): assert norm_infinity(a-b) < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme = Log.symplectic_schemes()[\"Euler-p\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 The symplectic form\n",
    "\n",
    "The symplectic form is a bilinear form on the space of positions of impulsions, defined as \n",
    "$$\n",
    "    B( (\\delta q,\\delta p), (\\delta q',\\delta p') ) = <\\delta q,\\delta p'> - <\\delta p, \\delta q'>.\n",
    "$$\n",
    "It is often denoted as $B = \\delta q \\wedge \\delta p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SymplecticForm(q_ad,p_ad):\n",
    "    \"\"\"\n",
    "    Returns the matrix of the symplectic 2-form, \n",
    "    in the considered first order perturbations.\n",
    "    \"\"\"\n",
    "    dp = p_ad.gradient()\n",
    "    dq = q_ad.gradient()\n",
    "    size_ad = p_ad.size_ad\n",
    "    return ad.array([[lp.dot_VV(dq[i],dp[j]) - lp.dot_VV(dp[i],dq[j])\n",
    "                     for i in range(size_ad)] for j in range(size_ad)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider canonical independent perturbations in the position and impulsion variables. \n",
    "The matrix of the symplectic form is a $2d\\times 2d$ antisymmetric matrix, with block form\n",
    "$$\n",
    "    \\begin{pmatrix}\n",
    "    0 & -I\\\\ I & 0\n",
    "    \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,p = np.array([1.,0.]),np.array([0.,1.])\n",
    "q_ad,p_ad = ad.Dense.register( (q,p) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of the symplectic form:\n",
      "[[ 0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "mSymp = SymplecticForm(q_ad,p_ad)\n",
    "print(f\"Matrix of the symplectic form:\\n{mSymp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the form is preserved by our numerical schemes, by applying them to the `q_ad` and `p_ad` variables. Since their definition already involves automatic differentiation, we need to hide it using the associate and disassociate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=len(q)\n",
    "def disac(x): return ad.disassociate(x,shape_free=(d,))\n",
    "def assoc(x): return ad.associate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "qE_ad,pE_ad = (assoc(x) for x in SymplecticEulerStep_Separable(disac(q_ad),disac(p_ad),H_Celestial,0.1))\n",
    "assert norm_infinity(SymplecticForm(qE_ad,pE_ad)-mSymp) < 1e-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[denseAD(array([0.98989795]),array([[ 0.96948553,  0.00206207,  0.10206207, -0.02041241]]))],\n",
       "        [denseAD(array([0.1]),array([[0.2       , 0.98989795, 0.        , 0.1       ]]))]],\n",
       "       dtype=object),\n",
       " array([[denseAD(array([-0.10102051]),array([[-0.10310363,  0.02062073,  1.02062073, -0.20412415]]))],\n",
       "        [denseAD(array([1.]),array([[ 0.        , -0.10102051,  0.        ,  1.        ]]))]],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheme(disac(q_ad),disac(p_ad),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semi-implicit scheme for the H_Log hamiltonian\n",
    "qI_ad,pI_ad = (assoc(x) for x in scheme(disac(q_ad),disac(p_ad),0.1))\n",
    "assert norm_infinity(SymplecticForm(qI_ad,pI_ad) - mSymp) < 1e-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shooting geodesics\n",
    "\n",
    "Geodesic shooting is the process of adjusting the initial velocity or momentum of a geodesic, so that the endpoint at time $t=1$ meets a prescribed position. \n",
    "A natural strategy is to optimize the initial velocity using a Newton method, taking advantage of automatic differentiation to compute the jacobian matrix of the exponential map. Note that AD is also used, independently, to solve Hamilton's ODE, which involves the derivatives of the Hamiltonian.\n",
    "\n",
    "We use the Poincare Half-Plane model for illustration. It is particularly simple since, due to its hyperbolic nature, there exists a unique geodesic between any two given points.\n",
    "\n",
    "**Riemannian exponential map.** In Riemannian geometry, the exponential map associates to a position $q$ and velocity $v$ the endpoint $\\exp_x(v) := \\gamma_x^v(1)$ of the corresponding geodesic $\\gamma_x^v$. The inverse map is known as the logarithmic map. This terminology does not perfectly apply here since Hamilton's equations are written in terms of the Hamiltonian momentum, which is *dual* to the velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shoot(q,p,*args,**kwargs):\n",
    "    Q,P,T = Geodesic(q,p,*args,**kwargs)\n",
    "    return np.take(Q,-1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7200162 , 1.27931064])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q0,p0=np.array([0,1]),np.array([1,1])\n",
    "Shoot(q0,p0,H_HalfPlane,1.,step=EulerStep,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aim(q1,q0,pGuess,*args,**kwargs):\n",
    "    if pGuess is None: pGuess=np.zeros(q0.shape)\n",
    "    def F(p): \n",
    "        nonlocal args,kwargs,q0,q1\n",
    "        # Reshape needed due to introduced trailing singleton \n",
    "        q0_,q1_ = (np.reshape(a,p.shape) for a in (q0,q1))\n",
    "        return Shoot(q0_,p,*args,**kwargs)-q1_\n",
    "    return NewtonSolve_AD(F,pGuess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.array([1.,1.])\n",
    "p01 = Aim(q1,q0,p0,H_HalfPlane,1.,step=EulerStep,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert norm_infinity(Shoot(q0,p01,H_HalfPlane,1.,step=EulerStep,n=10) -q1) < 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}