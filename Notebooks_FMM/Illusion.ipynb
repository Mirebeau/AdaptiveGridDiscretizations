{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The HFM library - A fast marching solver with adaptive stencils\n",
    "\n",
    "## Part : Image models and segmentation\n",
    "## Chapter : A mathematical model for Poggendorff's visual illusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python notebook is *freely inspired* from the publication:  \n",
    "<a id='FMCS_2017'>[1]</a>\tB. Franceschiello, A. Mashtakov, G. Citti, and A. Sarti, “Modelling of the Poggendorff Illusion via Sub-Riemannian Geodesics in the Roto-Translation Group,” presented at the International Conference on Image Analysis and Processing, 2017, pp. 37–47.\n",
    "\n",
    "The main assumption in our experiments is that: if a curve in an image is occluded, then the visual cortex attemps to continue it with a geodesic w.r.t. the Reeds-Shepp model. This assumption is backed by the mathematical works of Petitot and Citti-Sarti, and the neuro-biological observations of Bosking, Angelis, et al, on the first layer V1 of the visual cortex.\n",
    "\n",
    "The model considered in this notebook is *simplified* in comparison with the one considered in the above paper. Indeed, the original model involves a data adaptive cost function, related to the activation of the cells of V1 implied by the input image, whereas we consider a constant cost function $c=1$ here.\n",
    "\n",
    "This notebook is intended as a companion notebook for the manuscript [(link)](https://hal.archives-ouvertes.fr/hal-01778322):  \n",
    "<a name=\"cite_MP18\"> [MP18] </a> Jean-Marie Mirebeau, Jorg Portegies, \"Hamiltonian Fast Marching: A numerical solver for anisotropic and non-holonomic eikonal PDEs\", 2018, submitted,\n",
    "and as documentation for the [HamiltonFastMarching (HFM) library](https://github.com/mirebeau/HamiltonFastMarching), which also has interfaces to the Matlab&reg; and Mathematica&reg; languages. It is part of a series, see the [summary](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/HFM_Python_Notebooks/master/Summary.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Fast Marching Methods, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. Sub-Riemannian extrapolation](#1.-Sub-Riemannian-extrapolation)\n",
    "  * [2. First Poggendorff illusion](#2.-First-Poggendorff-illusion)\n",
    "  * [3. Poggendorff's round illusion](#3.-Poggendorff's-round-illusion)\n",
    "\n",
    "\n",
    "\n",
    "This Python&reg; notebook is intended as documentation and testing for the [HamiltonFastMarching (HFM) library](https://github.com/mirebeau/HamiltonFastMarching), which also has interfaces to the Matlab&reg; and Mathematica&reg; languages. \n",
    "More information on the HFM library in the manuscript:\n",
    "* Jean-Marie Mirebeau, Jorg Portegies, \"Hamiltonian Fast Marching: A numerical solver for anisotropic and non-holonomic eikonal PDEs\", 2019 [(link)](https://hal.archives-ouvertes.fr/hal-01778322)\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, University Paris-Sud, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\") # Allow import of agd from parent directory (useless if conda package installed)\n",
    "#from Miscellaneous import TocTools; print(TocTools.displayTOC('Illusion','FMM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agd import Eikonal\n",
    "from agd.Plotting import savefig; #savefig.dirName = 'Figures/Illusion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Optional configuration\n",
    "Uncomment the following line to use the GPU eikonal solver. (Comment it for the CPU eikonal solver.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "EikonalGPU_config"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning a copy of module matplotlib.pyplot whose functions accept cupy arrays as input.\n",
      "Setting dictIn.default_mode = 'gpu' in module agd.Eikonal .\n"
     ]
    }
   ],
   "source": [
    "#from agd import AutomaticDifferentiation as ad; plt,Eikonal = map(ad.cupy_friendly,(plt,Eikonal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sub-Riemannian extrapolation\n",
    "\n",
    "The two visual illusions considered, due to Poggendorf, challenge our brain's ability to continue a straight or curved line in a region occluded by a vertical band. For both illusions, it is found that we tend to under-estimate the height $y_1$ at the arrival point. \n",
    "\n",
    "Following the cited [paper](#FMCS_2017), we model our brain's extrapolation procedure for lines occluded by a vertical band by the following optimization problem. The unknown $\\delta y$ determines the height $y_1+\\delta y$ on the right side of the vertical band. In the considered examples, the seemingly \"logical\" continuation (as a straight line, or a circle) would yield $\\delta y= 0$, but our brain and the sub-Riemannian model both select a negative value $\\delta y <0$.  The optimization problem reads:\n",
    "\\begin{equation*}\n",
    "    \\min_{\\delta y \\in [-\\delta_1,\\delta_2]} d_\\xi( (x_0,y_0,\\theta_0),\\ (x_1,y_1+\\delta y,\\theta_1) )\n",
    "\\end{equation*}\n",
    "We denoted by $d_\\xi$ the sub-Riemannian distance associated with the Reeds-Shepp model on $\\mathbb R^2 \\times \\mathbb P^1$, where $\\mathbb P^1 = [0,\\pi]$ with periodic boundary conditions. The parameter $\\xi$ balances the cost of phisical motion and of angular motion. The inverse $\\xi^{-1}$ is homogeneous to a radius of curvature. A large value of $\\xi$ yields a large penalization of the curvature of the physical projection of the path to be extracted. \n",
    "\n",
    "One weakness of the considered model is that it does not predict the value of parameter $\\xi$, which is thus adjusted by hand in the following examples. In addition, this parameter is expected to depend on the scale at which the picture is displayed.\n",
    "\n",
    "The metric of the $\\varepsilon$-relaxation of the Reeds-Shepp model, where $\\varepsilon>0$ is a relaxation parameter, reads as follows: for any point $(x,\\theta) \\in \\mathbb R^2 \\times \\mathbb P^1$ of the configuration space, and any tangent vector $(\\dot x, \\dot \\theta) \\in \\mathbb R^2 \\times \\mathbb R$, one has\n",
    "\\begin{equation*}\n",
    "F_{(x,\\theta)}(\\dot x,\\dot \\theta)^2 = <n(\\theta),\\dot x>^2 + \\varepsilon^{-2} <n(\\theta)^\\perp,\\dot x>^2 + \\xi^2 |\\dot \\theta|^2.\n",
    "\\end{equation*}\n",
    "We denoted $n(\\theta) := (\\cos \\theta,\\sin \\theta)$. The relaxation parameter $\\varepsilon$ formally equals $0$ for the genuine sub-Riemannian mathematical model. However, we need to set $\\varepsilon = 0.1$ numerically. In our brain's biological implementation, we expect that $\\varepsilon$ is likewise a small positive value.\n",
    "\n",
    "The function implemented in the next cell numerically solves the optimization problem that we introduced, using the HFM library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReedsSheppContinuation(p0,p1,dy,n=100,n1=5,n2=1,nTheta=120,xi=1):\n",
    "    hfmIn = Eikonal.dictIn({\n",
    "        'model':'ReedsShepp2',\n",
    "        'geodesicSolver':'ODE',\n",
    "        'order':2,\n",
    "        'cost':1,\n",
    "        'xi':xi,\n",
    "        'projective':1,\n",
    "    })\n",
    "    \n",
    "    x0,y0,_ = p0\n",
    "    x1,y1,theta1 = p1\n",
    "    nDown,nUp = (n1,n2) if y1>y0 else (n2,n1)\n",
    "    hfmIn.SetRect([[min(x0,x1),max(x0,x1)],[min(y0,y1-nDown*dy),max(y0,y1+nUp*dy)]], \n",
    "                  dimx=n,sampleBoundary=True)\n",
    "    hfmIn.nTheta = nTheta\n",
    "\n",
    "    # First run : compute the best overall tip\n",
    "    h=hfmIn['gridScale']\n",
    "    hfmIn['seeds'] = [[x1,y1+n*h,theta1] for n in range(int(-nDown*dy/h),int(nUp*dy/h)+1)]\n",
    "    hfmIn['tips'] = [p0]\n",
    "    hfmOut1 = hfmIn.Run()\n",
    "\n",
    "    # Second run : compute the best suggested tip\n",
    "    hfmIn['seeds'] = [p0]\n",
    "    hfmIn['tips'] = [[x1,y1+n*dy,theta1] for n in range(-nDown,nUp+1)]\n",
    "    hfmIn['exportValues']=1\n",
    "    hfmOut2 = hfmIn.Run()\n",
    "\n",
    "    tipsI,_ = hfmIn.IndexFromPoint(hfmIn['tips'])\n",
    "    tipValues = hfmOut2['values'][tuple(tipsI.T)]\n",
    "        \n",
    "    return hfmOut1['geodesics'][0], hfmOut2['geodesics'], tipValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the kernel traits.\n",
      "Prepating the domain data (shape,metric,...)\n",
      "Preparing the problem rhs (cost, seeds,...)\n",
      "Preparing the GPU kernel\n",
      "Running the eikonal GPU kernel\n",
      "GPU kernel eikonal ran for 0.13352179527282715 seconds, and 60 iterations.\n",
      "Post-Processing\n",
      "!! Warning !! Unused keys from user : ['geodesicSolver']\n",
      "Setting the kernel traits.\n",
      "Prepating the domain data (shape,metric,...)\n",
      "Preparing the problem rhs (cost, seeds,...)\n",
      "Preparing the GPU kernel\n",
      "Running the eikonal GPU kernel\n",
      "GPU kernel eikonal ran for 0.1089940071105957 seconds, and 68 iterations.\n",
      "Post-Processing\n",
      "!! Warning !! Unused keys from user : ['geodesicSolver']\n"
     ]
    }
   ],
   "source": [
    "geoOpt, geoAll, tipValues = ReedsSheppContinuation([0,0,np.pi/4],[1,1,np.pi/4],0.1,xi=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows the minimal geodesic for the considered optimization problem, which will appear as our brain's approximation of a straight line in the first Poggendorff illusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[3,3]); plt.title('Best Reeds-Shepp path'); plt.axis('equal'); plt.axis('off');\n",
    "plt.plot(geoOpt[0],geoOpt[1],color='red');\n",
    "savefig(fig,'ReedsSheppPath.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next display a family of geodesics, from the left to the right of the domain, with the prescribed tangents, colored according to their length. (Shortest is darker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGray(vals):\n",
    "    grays = np.sqrt(vals-min(vals))\n",
    "    grays = grays/max(grays)\n",
    "    return 0.8*grays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[3,3]); plt.axis('equal'); plt.axis('off');\n",
    "plt.title('Reeds-Shepp paths.\\n Darker is shorter.',fontdict={'verticalalignment':'top'}); \n",
    "for geo,lvl in zip(geoAll,toGray(tipValues)):\n",
    "    plt.plot(geo[0],geo[1],color=str(lvl));\n",
    "savefig(fig,'ReedsSheppPaths.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. First Poggendorff illusion\n",
    "\n",
    "The first Poggendorff illusion challenges our brain's ability to continue a straight line occluded by a vertical band. The function implemented in the next cell displays the illusion, and returns the endpoints of the occluded segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BarIllusion(theta,r,w):\n",
    "    c,s=np.cos(theta),np.sin(theta)\n",
    "    fig = plt.figure()\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    plt.plot([-c,-r*c],[-s,-r*s],color='black')\n",
    "    plt.plot([c,r*c],[s,r*s],color='black')\n",
    "    plt.plot([-r*c,-r*c],[-s,s],color='gray')\n",
    "    plt.plot([r*c,r*c],[-s,s],color='gray')\n",
    "    return fig,np.array([[-r*c,-r*s,theta],[r*c,r*s,theta]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When viewing the Poggendorff illusion, in the next cell, most people tend to think that the dark straight lines are not aligned, but that the right one is a little *too high*. This is actually not the case, as evidenced by the above python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,endPts = BarIllusion(np.pi/6,0.2,10);\n",
    "plt.title('First Poggendorf illusion');\n",
    "savefig(fig,'FirstPoggendorffIllusion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next try to explain Poggendorff's illusion using the sub-Riemannian Reeds-Shepp model. The red curve supposedly accounts for our brain's completion of the left black line, in the space in between the two gray lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the kernel traits.\n",
      "Prepating the domain data (shape,metric,...)\n",
      "Preparing the problem rhs (cost, seeds,...)\n",
      "Preparing the GPU kernel\n",
      "Running the eikonal GPU kernel\n",
      "GPU kernel eikonal ran for 0.0655219554901123 seconds, and 55 iterations.\n",
      "Post-Processing\n",
      "!! Warning !! Unused keys from user : ['geodesicSolver']\n",
      "Setting the kernel traits.\n",
      "Prepating the domain data (shape,metric,...)\n",
      "Preparing the problem rhs (cost, seeds,...)\n",
      "Preparing the GPU kernel\n",
      "Running the eikonal GPU kernel\n",
      "GPU kernel eikonal ran for 0.0690000057220459 seconds, and 58 iterations.\n",
      "Post-Processing\n",
      "!! Warning !! Unused keys from user : ['geodesicSolver']\n"
     ]
    }
   ],
   "source": [
    "geoOpt,geoAll,tipValues = ReedsSheppContinuation(endPts[0,:],endPts[1,:],0.02,xi=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,_ = BarIllusion(np.pi/6,0.2,10);\n",
    "plt.title('Subriemannian continuation prediction');\n",
    "plt.plot(geoOpt[0],geoOpt[1],color='red');\n",
    "savefig(fig,'FirstPoggendorffIllusion_Prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,_ = BarIllusion(np.pi/6,0.2,10);\n",
    "plt.title('First Poggendorf illusion : subriemannian continuations.\\n Darker is shorter.',fontdict={'verticalalignment':'top'});\n",
    "for geo,lvl in zip(geoAll,toGray(tipValues)):\n",
    "    plt.plot(geo[0],geo[1],color=str(lvl));\n",
    "savefig(fig,'FirstPoggendorffIllusion_Choices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Poggendorff's round illusion\n",
    "\n",
    "We next turn to a second illusion due to Poggendorff, involving the completion of a circular shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoundIllusion(theta1,theta2,w):\n",
    "    c1,s1 = np.cos(theta1),np.sin(theta1)\n",
    "    c2,s2 = np.cos(theta2),np.sin(theta2)\n",
    "    fig = plt.figure()\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    plt.plot([c1,c1],[-1,1],color='grey')\n",
    "    plt.plot([c2,c2],[-1,1],color='grey')\n",
    "    I1 = np.linspace(-theta1,theta1,100)\n",
    "    I2 = np.linspace(theta2,2*np.pi-theta2,100)\n",
    "    plt.plot([np.cos(t) for t in I1],[np.sin(t) for t in I1],color='black',solid_capstyle='round')\n",
    "    plt.plot([np.cos(t) for t in I2],[np.sin(t) for t in I2],color='black',solid_capstyle='round')\n",
    "    return fig, np.array([[c1,s1,theta1+np.pi/2],[c2,s2,theta2+np.pi/2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dark line is circular, yet most people feel that the occluded parts to not connect well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,endPts = RoundIllusion(np.pi/6,np.pi/3,6);\n",
    "plt.title('Round Poggendorf illusion');\n",
    "savefig(fig,'RoundPoggendorffIllusion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the kernel traits.\n",
      "Prepating the domain data (shape,metric,...)\n",
      "Preparing the problem rhs (cost, seeds,...)\n",
      "Preparing the GPU kernel\n",
      "Running the eikonal GPU kernel\n",
      "GPU kernel eikonal ran for 0.09900617599487305 seconds, and 63 iterations.\n",
      "Post-Processing\n",
      "!! Warning !! Unused keys from user : ['geodesicSolver']\n",
      "Setting the kernel traits.\n",
      "Prepating the domain data (shape,metric,...)\n",
      "Preparing the problem rhs (cost, seeds,...)\n",
      "Preparing the GPU kernel\n",
      "Running the eikonal GPU kernel\n",
      "GPU kernel eikonal ran for 0.1440129280090332 seconds, and 88 iterations.\n",
      "Post-Processing\n",
      "!! Warning !! Unused keys from user : ['geodesicSolver']\n"
     ]
    }
   ],
   "source": [
    "geoOpt,geoAll,tipValues = ReedsSheppContinuation(endPts[0,:],endPts[1,:],0.04,xi=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our brain's completion of the occluded part, according to the considered sub-Riemannian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,_ = RoundIllusion(np.pi/6,np.pi/3,6);\n",
    "plt.title('Subriemannian continuation prediction');\n",
    "plt.plot(geoOpt[0],geoOpt[1],color='red');\n",
    "savefig(fig,'RoundPoggendorffIllusion_Prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,_ = RoundIllusion(np.pi/6,np.pi/3,6);\n",
    "plt.title('Round Poggendorf illusion : subriemannian continuations.\\n Darker is shorter.');\n",
    "for geo,lvl in zip(geoAll,toGray(tipValues)):\n",
    "    plt.plot(geo[0],geo[1],color=str(lvl));\n",
    "savefig(fig,'RoundPoggendorffIllusion_Choices.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}