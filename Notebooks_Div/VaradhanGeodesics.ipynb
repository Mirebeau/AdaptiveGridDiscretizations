{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive PDE discretizations on Cartesian grids\n",
    "## Volume : Divergence form PDEs\n",
    "## Part : Applications\n",
    "## Chapter : Extracting geodesics from the heat kernel\n",
    "\n",
    "This notebook is a numerical illustration of *Varadhan's formula*, which relates Riemannian geodesics and eikonal equations, with the heat kernel.\n",
    "We also present a variant of this method, devoted to Rander metrics, which are asymmetric perturbations of Riemannian metrics featuring a drift term.\n",
    "\n",
    "**References**\n",
    "\n",
    "The numerical scheme used for anisotropic diffusion in this notebook is taken from:\n",
    "* Fehrenbach, J., & Mirebeau, J.-M. (2014). Sparse non-negative stencils for anisotropic diffusion. Journal of Mathematical Imaging and Vision, 49(1), 123–147. http://doi.org/http://dx.doi.org/10.1007/s10851-013-0446-3\n",
    "\n",
    "The Varadhan formula was first numerically illustrated in:\n",
    "* Crane, K., Weischedel, C., & Wardetzky, M. (2013). Geodesics in heat: A new approach to computing distance based on heat flow. ACM Transactions on Graphics (TOG), 32(5), 152."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anisotropic diffusion and Riemannian distances : Varadhan's formula\n",
    "\n",
    "**An elliptic equation.** \n",
    "Let $\\Omega \\subset R^d$ be a bounded domain, and let $D : \\Omega \\to S_d^{++}$ be a field of diffusion tensors. \n",
    "Consider the elliptic optimization problem \n",
    "$$\n",
    "    \\min \\int_\\Omega \\epsilon^2 | \\nabla u(x)|^2_{D(x)} + u(x)^2\\, dx\n",
    "$$\n",
    "subject to Dirichlet boundary conditions on a nonempty subset $\\Gamma_D \\subset \\partial \\Omega$ of the domain boundary \n",
    "$$\n",
    "    u=1 \\text{ on } \\Gamma_D,\n",
    "$$\n",
    "and Neuman boundary conditions on $\\partial\\Omega \\setminus \\Gamma_D$. \n",
    "In the interior of the domain, the above optimization problem can be rephrased in the form of an elliptic partial differential equation\n",
    "$$\n",
    "    u(x) - \\epsilon^2 \\mathrm{div} (D(x) \\nabla u(x)) = 0.\n",
    "$$\n",
    "\n",
    "**Relation with the eikonal equation.**\n",
    "Following the Hopf-Cole approach to the linearization of Burger's PDE, extended by Varhadan to multi-dimensional Poisson and diffusion equations, we rely on a logarithmic transformation of the unknown.\n",
    "\n",
    "Denote by $u_\\epsilon$ the solution to the previous PDE on $\\Omega$.\n",
    "Under adequate assumptions, one can show that \n",
    "$$\n",
    "    v_\\epsilon := -\\epsilon \\ln u_\\epsilon\n",
    "$$\n",
    "converges as $\\epsilon \\to 0^+$ to the distance function from $\\Gamma_D$ on $\\Omega$, measured with respect to the metric $M(x) := D(x)^{-1}$ which is the inverse to the diffusion tensors. \n",
    "A justification for this fact is that the PDE\n",
    "$$\n",
    "    |\\nabla v(x)|_{D(x)}^2 - \\epsilon \\mathrm{div}( D(x) \\nabla v(x)) = 1\n",
    "$$\n",
    "is satisfied on $\\Omega$, along with the Dirichlet boundary condition $v=0$ on $\\Gamma_D$.\n",
    "As $\\epsilon \\to 0$, the viscosity introduced by the second order operator vanishes, and one recovers the eikonal equation $|\\nabla v(x)|_{D(x)} = 1$.\n",
    "\n",
    "**Interpretation as a path length.**\n",
    "Consider the Riemannian metric \n",
    "$$\n",
    "    M(x) := D(x)^{-1},\n",
    "$$\n",
    "for all $x \\in \\Omega$.\n",
    "Let us recall that the unique viscosity solution to the above eikonal equation, with Dirichlet boundary conditions on $\\Gamma_D$ and outflow boundary conditions on $\\partial \\Omega \\setminus \\Gamma_D$, is the distance map from $\\Gamma_D$:\n",
    "$$\n",
    "    v(x) = \\inf_\\gamma \\int_0^1 \\| \\gamma'(t)\\|_{M(\\gamma(t))} dt\n",
    "$$\n",
    "where $\\gamma : [0,1] \\to \\Omega$ has locally Lipschitz regularity, and is subject to the constraints:\n",
    "$$\n",
    "    \\gamma(0) \\in \\Gamma_D, \\quad \\gamma(1) = x.\n",
    "$$\n",
    "Once the distance map $v$ is numerically computed, or approximated, one can backtrack the corresponding minimal geodesics $\\gamma$ using a gradient flow method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks on Varadhan's formula\n",
    "**Optional refinement.**\n",
    "Crane et al suggest a simple additional non-linear step to improve the accuracy of the reconstructed distance map $v$. While interesting, this method is not discussed in this notebook. \n",
    "Note also that this extra-step is:\n",
    "- incompatible with the Sinkhorn algorithm, discussed in the next notebook.\n",
    "- regarded as un-necessary if one is interested in the minimal geodesic paths rather than the geodesic distance itself.\n",
    "\n",
    "**Non-divergence form variant.**\n",
    "A non-divergence form equation can be considered, instead of the above divergence form elliptic equation:\n",
    "$$\n",
    "    u(x) - \\epsilon^2 \\mathrm{tr} (D(x) \\nabla^2 u(x)) = 0,\n",
    "$$\n",
    "for all $x \\in \\Omega$. This modification has little impact on the results, since the introduced first order term is negligible. See the end of this notebook for the introduction of a non-negligible first order term, in the context of Randers metrics.\n",
    "\n",
    "**Parabolic (time dependent) variant.**\n",
    "Another variant of Varadhan's formula involves the time-dependent heat equation, which is the following the parabolic PDE\n",
    "$$\n",
    "    \\partial_t u(t,x) - \\mathrm{div} (D(x) \\nabla u(t,x)).\n",
    "$$\n",
    "\n",
    "<!---\n",
    "It may be discussed in another notebook, in relation with Sinkhorn's algorithm for computational optimal transport.\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Summary**](Summary.ipynb) of volume Divergence form PDEs, this series of notebooks.\n",
    "\n",
    "[**Main summary**](../Summary.ipynb) of the Adaptive Grid Discretizations \n",
    "\tbook of notebooks, including the other volumes.\n",
    "\n",
    "# Table of contents\n",
    "  * [1. Isotropic metrics](#1.-Isotropic-metrics)\n",
    "    * [1.1 Reproducing the Euclidean distance](#1.1-Reproducing-the-Euclidean-distance)\n",
    "    * [1.2 Effect of the relaxation parameter $\\epsilon$](#1.2-Effect-of-the-relaxation-parameter-$\\epsilon$)\n",
    "    * [1.3 The Poincare half plane model](#1.3-The-Poincare-half-plane-model)\n",
    "  * [2. Anisotropic Riemannian metrics](#2.-Anisotropic-Riemannian-metrics)\n",
    "    * [2.1 Geodesic distance on a surface](#2.1-Geodesic-distance-on-a-surface)\n",
    "    * [2.2 Metric definition in term of eigenvectors and eigenvalues](#2.2-Metric-definition-in-term-of-eigenvectors-and-eigenvalues)\n",
    "  * [3. Randers metrics](#3.-Randers-metrics)\n",
    "    * [3.1 Generalized Varadhan formula](#3.1-Generalized-Varadhan-formula)\n",
    "    * [3.2 Constant Rander metric](#3.2-Constant-Rander-metric)\n",
    "    * [3.3 Zermelo's problem with a variable drift](#3.3-Zermelo's-problem-with-a-variable-drift)\n",
    "\n",
    "\n",
    "\n",
    "**Acknowledgement.** Some of the experiments presented in these notebooks are part of \n",
    "ongoing research with Ludovic Métivier and Da Chen.\n",
    "\n",
    "Copyright Jean-Marie Mirebeau, Centre Borelli, ENS Paris-Saclay, CNRS, University Paris-Saclay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,\"..\") # Allow import of agd from parent directory (useless if conda package installed)\n",
    "#from Miscellaneous import TocTools; TocTools.displayTOC('VaradhanGeodesics','Div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agd import LinearParallel as lp\n",
    "from agd import LinearPDE\n",
    "from agd import AutomaticDifferentiation as ad\n",
    "from agd import FiniteDifferences as fd\n",
    "from agd import Selling\n",
    "from agd.ExportedCode.Notebooks_NonDiv.LinearMonotoneSchemes2D import streamplot_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg; import scipy.sparse; import scipy.sparse.linalg \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Utility functions\n",
    "\n",
    "The following function is used throughout the notebook to estimate distances associated to isotropic, riemannian, or Randers metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VaradhanDistance(diff,rhs,dx,ϵ=None,ω=None,divergenceForm=None):\n",
    "    \"\"\"\n",
    "    Approximate a Riemannian distance using Varadhan's formula.\n",
    "    Input.  \n",
    "    - diff : diffusion tensors D(x), inverse of the riemannian metric. Alternatively : diffusion coefficients d(x).\n",
    "    - rhs : right-hand-side of linear system. (Typically zero everywhere except at seed points.)\n",
    "    - h : grid scale\n",
    "    - ϵ : relaxation parameter\n",
    "    - ω : first order term, used with asymmetric Rander metrics\n",
    "    - divergenceForm : None -> use the finite difference scheme implemented in this notebook\n",
    "            True/False -> use ad-hoc routine to build the matrix, with or without div form\n",
    "    \"\"\"\n",
    "    shape,ndim,size = rhs.shape,rhs.ndim,rhs.size\n",
    "    \n",
    "    if ϵ is None: # Produce a default value for the relaxation parameter ϵ\n",
    "        tdiff = diff if diff.shape==shape else lp.trace(diff)\n",
    "        δ = np.sqrt(np.max(tdiff)) # length scale associated with a field of diffusion tensors\n",
    "        ϵ = 2 * δ * dx \n",
    "    \n",
    "    if divergenceForm is None: # Operator matrix generated from this notebook's schemes\n",
    "        u_ad = ad.Sparse2.identity(shape)\n",
    "        if diff.shape==shape: # Isotropic\n",
    "            solution = IsotropicEnergy(  u_ad, ϵ**2*diff, rhs, dx).solve_stationnary()\n",
    "        elif ω is None: # Riemannian\n",
    "            solution = AnisotropicEnergy(u_ad, ϵ**2*diff, rhs, dx).solve_stationnary()\n",
    "        else: # Rander\n",
    "            v_ad = ad.Sparse2.identity(shape, shift=size) \n",
    "            solution = AsymmetricForm(u_ad, v_ad, ϵ**2*diff, ϵ*ω, rhs, dx).solve_weakform()\n",
    "            \n",
    "    else: # Operator matrix built directly using external library \n",
    "        if diff.shape==shape: diff = diff*fd.as_field(np.eye(ndim),shape)\n",
    "        coef,(row,col) = LinearPDE.OperatorMatrix(ϵ**2*diff, mult=np.ones_like(rhs), \n",
    "            omega=None if ω is None else ϵ*ω, gridScale=dx, \n",
    "            boundaryConditions='Neumann',divergenceForm=divergenceForm)\n",
    "        operator = scipy.sparse.coo_matrix((coef,(row,col))).tocsr()\n",
    "        solution = scipy.sparse.linalg.spsolve(operator,rhs.flatten())\n",
    "\n",
    "    # Extract Riemannian distance\n",
    "    distance  = -ϵ*np.log(solution.reshape(shape))\n",
    "    distance -= np.min(distance)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than imposing Dirichlet boundary conditions at the seed points, we introduce of a non-zero right hand side, featuring Dirac-like singularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RangeIndex(rg,x):\n",
    "    \"\"\"Find the index of a value x in an equispaced range rg\"\"\"\n",
    "    return int(round( (x-rg[0])/(rg[-1]-rg[0]) * (len(rg)-1)))\n",
    "\n",
    "def MakeRHS(seeds,axes):\n",
    "    rhs=np.full(tuple(len(ax) for ax in axes),0.)\n",
    "    for seed in seeds:\n",
    "        rhs[tuple(RangeIndex(ax,x) for ax,x in zip(axes,seed))] = 1\n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Isotropic metrics\n",
    "\n",
    "We illustrate Varadhan's formula for isotropic metrics, which are locally proportionnal to the Euclidean metric.\n",
    "$$\n",
    "    M(x) = c(x)^2 \\mathrm{Id},\n",
    "$$\n",
    "where $c : \\Omega \\to ]0,\\infty[$ is a continuous and positive cost function.\n",
    "The length of a path $\\gamma : [0,1] \\to \\Omega$, w.r.t. this metric, is therefore\n",
    "$$\n",
    "    \\int_0^1 c(\\gamma(t)) \\|\\gamma(t)\\| dt,\n",
    "$$\n",
    "and the eikonal equation reads\n",
    "$$\n",
    "    \\| \\nabla v(x)\\| = c(x),\n",
    "$$\n",
    "for all $x \\in \\Omega$.\n",
    "\n",
    "Varadhan's method involves, for this application, solving the elliptic equation\n",
    "$$\n",
    "    u(x) - \\varepsilon^2 \\mathrm{div}( c(x)^{-2} \\nabla u(x)) = 0.\n",
    "$$\n",
    "\n",
    "**Discretization.** Since the laplacian operator is *isotropic*, i.e. it is defined in terms of an isotropic diffusion tensor $c(x)^{-2} \\mathrm{Id}$, the standard five point finite difference scheme is used.\n",
    "\n",
    "\n",
    "**Geodesic extraction.** Minimal geodesics can be obtained by following the gradient of the distance map. In other words by solving the ordinary differential equation\n",
    "$$\n",
    "    \\gamma'(t) = V(\\gamma(t)),\n",
    "$$\n",
    "backwards in time, where for all $x \\in \\Omega$\n",
    "$$\n",
    "    V(x) = \\nabla u(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reproducing the Euclidean distance\n",
    "\n",
    "We compute the Euclidean distance from three points, referred to as *seeds*, in the square domain $[0,1]^2$.\n",
    "This test can be regarded as a sanity check. The Euclidean metric is obtained by choosing the constant cost $c\\equiv 1$ in the above definition of a Riemannian metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the domain [0,1]^2, sampled on a cartesian grid\n",
    "aX,dx = np.linspace(0,1,retstep=True)\n",
    "X = np.array(np.meshgrid(aX,aX,indexing='ij'))\n",
    "\n",
    "# Generate the diffusion coefficients \n",
    "diff = np.ones(X.shape[1:]) # Constant diffusion coefficient\n",
    "#diff = np.where(X[0]<=0.5,1,4) # Piecewise constant \n",
    "\n",
    "# Choose the seeds from which distance is computed\n",
    "#seeds = [[0.5,0.5]] #Alternatively : single seed in the center\n",
    "seeds = [[0.3,0.2],[0.8,0.3],[0.5,0.8]] # multiple seeds\n",
    "rhs = MakeRHS(seeds,(aX,aX))\n",
    "\n",
    "# Choose a relaxation parameter\n",
    "ϵ = 2 * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elliptic energy**\n",
    "\n",
    "In order to apply Varadhan's method, we implement the energy \n",
    "$$\n",
    "    \\frac 1 2 \\int_\\Omega \\big(u^2 + d \\|\\nabla u\\|^2\\big) -\\int_\\Omega f u,\n",
    "$$\n",
    "where $d : \\Omega \\to ]0,\\infty[$ is the diffusion coefficient, and $f$ is a right hand side. \n",
    "\n",
    "<!---ExoFR\n",
    "Implémenter une fonction calculant l'énergie ci-dessus.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def IsotropicEnergy(u,diff,rhs,h):\n",
    "    \"\"\"\n",
    "    Finite differences approximation of \n",
    "    (1/2) * ( u^2 + diff * (grad u)^2) - rhs * u \n",
    "    \"\"\"\n",
    "    # TODO. Hint : fd.DiffUpwind(u,(1,0),h) \n",
    "\n",
    "    energy_density = \n",
    "    ad.simplify_ad(energy_density) # Faster matrix build\n",
    "    \n",
    "    return energy_density.sum() * dx**ndim\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsotropicEnergy(u,diff,rhs,h):\n",
    "    \"\"\"\n",
    "    Finite differences approximation of the integral of\n",
    "    (1/2) * ( u^2 + diff * (grad u)^2) - rhs * u \n",
    "    \"\"\"\n",
    "    ndim = rhs.ndim\n",
    "    e = np.eye(ndim,dtype=int) # The canonical basis\n",
    "    \n",
    "    dup = fd.DiffUpwind(u, e,h)\n",
    "    dum = fd.DiffUpwind(u,-e,h)\n",
    "    \n",
    "    dup[np.isnan(dup)] = 0\n",
    "    dum[np.isnan(dum)] = 0\n",
    "    \n",
    "    energy_density = 0.5*u**2 + 0.25*diff*((dup**2 + dum**2)).sum(axis=0) - rhs*u\n",
    "    ad.simplify_ad(energy_density) # Faster matrix build\n",
    "    \n",
    "    return energy_density.sum() * h**ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of geodesic distance computation by Poisson kernel, one chooses $d(x) = \\epsilon^2 c(x)^{-2}$, and $f$ is supported on the seed points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 8.64 ms, total: 123 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distance = VaradhanDistance(diff,rhs,dx,ϵ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Distance map, computed using Varadhan's formula\")\n",
    "plt.contourf(*X,distance); plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.gradient(distance,dx)\n",
    "plt.axis('equal'); plt.title(\"Minimal geodesics, computed with Varadhan's method\")\n",
    "streamplot_ij(*X,*grad);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For concistency, we check the results using an external library for solving the same problem. (Note that the running time is substantially lower that with the AD implementation. This seems related to entry reordering in the sparse matrix build.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 ms, sys: 3.75 ms, total: 16.5 ms\n",
      "Wall time: 15.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distance_div = VaradhanDistance(diff,rhs,dx,ϵ,divergenceForm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(distance, distance_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Effect of the relaxation parameter $\\epsilon$\n",
    "\n",
    "\n",
    "The convergence analysis requires that the gridscale $h$ vanishes faster than the relaxation parameter $\\epsilon$, but not too fast, in the sense that :\n",
    "$$\n",
    "    (\\epsilon,h/\\epsilon,\\epsilon\\ln h) \\to 0.\n",
    "$$\n",
    "\n",
    "Nevertheless, the best practical results are often obtained when the relaxation parameter $\\epsilon$ is a few times larger than the gridscale $h$. In the above example, we set \n",
    "$$\n",
    "    \\epsilon = 2 h\n",
    "$$\n",
    "which is a reasonable practical choice. (Although, from the theoretical standpoint, it does not ensure convergence, since $h/\\epsilon \\not \\to 0$ under this constraint.) When setting these parameters, beware that:\n",
    "* An excessively *small* $\\epsilon/h$ leads to a *non-convergent* distance.\n",
    "* An excessively *large* $\\epsilon/h$ produces undesirable *numerical diffusion*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a too low value of epsilon\n",
    "distance = VaradhanDistance(diff,rhs,dx,ϵ/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\epsilon$ is too small, as with the above numerical distance computation, then empirical evidence shows that the the $L^1$ Manhattan distance is (approximately) reproduced, instead of the desired Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Distance map, too small epsilon. (Incorrect result)\")\n",
    "plt.contourf(*X,distance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a too large value of epsilon\n",
    "distance = VaradhanDistance(diff,rhs,dx,ϵ*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\epsilon$ is too large, on the other hand, then level sets are not equidistant, which illustrates the lack of accuracy of the obtained numerical approximation of the distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Distance map, too large epsilon. (Incorrect result)\")\n",
    "plt.contourf(*X,distance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The Poincare half plane model\n",
    "\n",
    "We illustrate Varadhan's formula on the Poincare model of the half plane, which is one of the geometric instantiations of the hyperbolic plane. (The Poincare disk model is another well known instantiation.)\n",
    "\n",
    "The Poincare half plane model is posed on the domain $\\Omega = \\mathbb R \\times \\mathbb R_+^*$, which is equipped with the following Riemannian metric\n",
    "$$\n",
    "    \\frac{dx^2 + dy^2} {y^2},\n",
    "$$\n",
    "for all $x,y \\in \\Omega$. Note that the metric is again isotropic.\n",
    "This numerical example is solved with an alternative method in \n",
    "[III - The Fisher information metric](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/HFM_Python_Notebooks/master/B4_FisherRao.ipynb)\n",
    "\n",
    "Let us set up the Poincare half plane example.\n",
    "\n",
    "<!---\n",
    "**Automatic parameter setting.**\n",
    "The `RiemannianDistance0` method coded above is not much practical since it requires to:\n",
    "- manually invert the Riemannian metric tensors $M$, in order to produce the diffusion tensors $D(x) := M(x)^{-1}$.\n",
    "- manually select an adequate relaxation parameter $\\epsilon$.\n",
    "\n",
    "In the following cell, we automate this process.\n",
    "\n",
    "def diffScale(D):\n",
    "    \"\"\"Associates a length scale (upper bound) with a field of diffusion tensors\"\"\"\n",
    "    return np.sqrt(np.max(lp.trace(D)))\n",
    "\n",
    "def RiemannianDistance(metric,rhs,dx):\n",
    "    diff = lp.inverse(metric)\n",
    "    ϵ = diffScale(diff) * 2 * dx\n",
    "    return RiemannianDistance0(diff,rhs,dx,ϵ)\n",
    "--->\n",
    "\n",
    "<!---ExoFR\n",
    "Définissez le coefficient de diffusion correspondant au modèle.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "# Create the domain [-1,1] x [0.3,1.3]\n",
    "dx = 0.01\n",
    "aX0 = np.arange(-1,1,dx)\n",
    "aX1 = np.arange(0.3,1.3,dx)\n",
    "X = np.array(np.meshgrid(aX0,aX1,indexing='ij'))\n",
    "\n",
    "seeds = [[0,0.5]]\n",
    "rhs = MakeRHS(seeds, (aX0,aX1))\n",
    "\n",
    "# Define the diffusion coefficient\n",
    "diff = # TODO\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the domain [-1,1] x [0.3,1.3]\n",
    "dx = 0.01\n",
    "aX0 = np.arange(-1,1,dx)\n",
    "aX1 = np.arange(0.3,1.3,dx)\n",
    "X = np.array(np.meshgrid(aX0,aX1,indexing='ij'))\n",
    "\n",
    "seeds = [[0,0.5]]\n",
    "rhs = MakeRHS(seeds, (aX0,aX1))\n",
    "\n",
    "# Define the cost function\n",
    "diff = X[1]**2 # Inverse of the Riemannian metric, here given as scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = VaradhanDistance(diff,rhs,dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level sets of the Poincare distance are (non concentric) Euclidean disks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Poincare half-plane model, computed with Varadhan's method.\")\n",
    "plt.contourf(*X,distance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geodesics of the Poincare metric are Euclidean cirles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Poincare half-plane geodesics, computed with Varadhan's method\")\n",
    "streamplot_ij(*X,*np.gradient(distance));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the consistency with the external library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(distance, VaradhanDistance(diff,rhs,dx,divergenceForm=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Anisotropic Riemannian metrics\n",
    "\n",
    "Varadhan's formula applies to both isotropic and anisotropic Riemannian metrics. Numerically, the main difficulty in the anisotropic context is to discretize an anisotropic Laplacian. However this point is handled transparently in the provided python function, using techniques described in \n",
    "[I Tensor decomposition, dimensions 2 and 3](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/AdaptiveGridDiscretizations/master/Notebooks/TensorSelling.ipynb)\n",
    "\n",
    "Once the geodesic distance $v$ from a given point is computed, the geodesic backtracking ODE reads\n",
    "$$\n",
    "    \\gamma'(t) = V(\\gamma(t)),\n",
    "$$\n",
    "similarly to the isotropic case. \n",
    "The flow direction is defined as the intrinsic Riemannian gradient of the distance map\n",
    "$$\n",
    "    V(x) = D(x) \\nabla v(x).\n",
    "$$\n",
    "The following numerical examples are solved with an alternative numerical method in \n",
    "[II - Riemannian metrics](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/HFM_Python_Notebooks/master/A3_Riemannian.ipynb)\n",
    "\n",
    "**Elliptic energy.**\n",
    "In order to use Varadhan's method to compute Riemannian distances, we need to implement the elliptic energy\n",
    "$$\n",
    "    \\frac 1 2 \\int_\\Omega (u^2 + \\| \\nabla u\\|^2_D) - \\int_\\Omega f u\n",
    "$$\n",
    "\n",
    "<!---ExoFR\n",
    "Implémentez cette énergie.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def AnisotropicEnergy(u,diff,rhs,h):\n",
    "    \"\"\"\n",
    "    Finite differences approximation of the integral of \n",
    "    (1/2) * ( u^2 + diff * (grad u)^2) - rhs * u\n",
    "    \"\"\"\n",
    "   \n",
    "    energy_density = # TODO. Hint : Selling.Decomposition(diff)\n",
    "    ad.simplify_ad(energy_density)\n",
    "    \n",
    "    return energy_density.sum() * dx**ndim\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnisotropicEnergy(u,diff,rhs,h):\n",
    "    \"\"\"\n",
    "    Finite differences approximation of the integral of \n",
    "    (1/2) * ( u^2 + diff * (grad u)^2) - rhs * u\n",
    "    \"\"\"\n",
    "    ndim = rhs.ndim\n",
    "    coefs,offsets = Selling.Decomposition(diff)\n",
    "    \n",
    "    dup = fd.DiffUpwind(u, offsets,h)\n",
    "    dum = fd.DiffUpwind(u,-offsets,h)\n",
    "    \n",
    "    dup[np.isnan(dup)] = 0\n",
    "    dum[np.isnan(dum)] = 0\n",
    "    \n",
    "    energy_density = 0.5*u**2 + 0.25*(coefs*(dup**2 + dum**2)).sum(axis=0) - rhs*u\n",
    "    ad.simplify_ad(energy_density)\n",
    "    \n",
    "    return energy_density.sum() * h**ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Geodesic distance on a surface\n",
    "\n",
    "We compute the geodesic distance on a parametrized two dimensional surface embedded into $R^3$ and defined by a height map:\n",
    "$$\n",
    "    z(x,y) = (3/4) sin(3 \\pi  x) \\sin(3 \\pi y), \n",
    "$$\n",
    "where $(x,y) \\in ]-0.5,0.5[^2$. The metric is \n",
    "$$\n",
    "    M(x,y) = \\mathrm{Id} + \\nabla z(x,y) \\nabla z(x,y)^T.\n",
    "$$\n",
    "\n",
    "<!---ExoFR\n",
    "Implementer cette métrique.\n",
    "--->\n",
    "\n",
    "\n",
    "<!---ExoCode\n",
    "# Create the domain\n",
    "gridScale = 0.01\n",
    "aX = np.arange(-0.5,0.5,gridScale); \n",
    "X = np.array(np.meshgrid(aX,aX,indexing='ij'))\n",
    "\n",
    "# Define the metric\n",
    "Z = (3/4.)*np.sin(3*np.pi*X[0])*np.sin(3*np.pi*X[1])\n",
    "metric = # TODO. Hint : np.gradient\n",
    "diff = lp.inverse(metric) \n",
    "\n",
    "# Generate the rhs\n",
    "rhs = MakeRHS([[0.,0.]], (aX,aX))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the domain\n",
    "dx = 0.01\n",
    "aX = np.arange(-0.5,0.5,dx); \n",
    "X = np.array(np.meshgrid(aX,aX,indexing='ij'))\n",
    "\n",
    "# Define the metric\n",
    "Z = (3/4.)*np.sin(3*np.pi*X[0])*np.sin(3*np.pi*X[1])\n",
    "grad = np.array(np.gradient(Z,dx))\n",
    "#metric = fd.as_field([[1,-0.5],[-0.5,1]],X.shape[1:])\n",
    "metric = fd.as_field(np.eye(2),X.shape[1:]) + lp.outer_self(grad)\n",
    "diff = lp.inverse(metric) \n",
    "\n",
    "# Generate the rhs\n",
    "rhs = MakeRHS([[0.,0.]], (aX,aX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = VaradhanDistance(diff,rhs,dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Surface test case, computed with Varadhan's method.\")\n",
    "plt.contourf(*X,distance); plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = lp.solve_AV(metric,np.array(np.gradient(distance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Surface test case geodesics, computed with Varadhan's method\")\n",
    "streamplot_ij(*X,*flow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(distance, VaradhanDistance(diff,rhs,dx,divergenceForm=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Metric definition in term of eigenvectors and eigenvalues\n",
    "\n",
    "In this example, the metric tensors are specified by their eigenvectors and eigenvalues\n",
    "$$\n",
    "    M(x) = \\lambda_1(x)^{-2} v_1(x) v_1(x)^T + \\lambda_2(x)^{-2} v_2(x) v_2(x)^T.\n",
    "$$\n",
    "The scalars $\\lambda_1$ and $\\lambda_2$ appearing in this expression should be regarded as the local velocity in the direction of $v_1$ and $v_2$ respectively.\n",
    "\n",
    "Our specific example involves constant eigenvalues, defined by $\\lambda_1 \\equiv 0.8$ and $\\lambda_2\\equiv 0.2$, and an analytic eigenvector $v_1(x_1,x_2) \\propto (1, \\cos( 2 \\pi x_1))$ (normalized) while $v_2$ is orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the domain\n",
    "dx = 0.02\n",
    "aX = np.arange(-1,1,dx); \n",
    "X = np.array(np.meshgrid(aX,aX,indexing='ij'))\n",
    "shape = X.shape[1:]\n",
    "\n",
    "# Generate the metric\n",
    "eig1 = np.stack((np.ones(shape),(np.pi/2)*np.cos(2*np.pi*X[0])))\n",
    "eig1 /= scipy.linalg.norm(eig1,axis=0) \n",
    "eig2 = np.stack( (eig1[1],-eig1[0]) )\n",
    "lambda1, lambda2 = 0.8, 0.2\n",
    "metric = lambda1**-2*lp.outer_self(eig1) + lambda2**-2*lp.outer_self(eig2)\n",
    "diff = lp.inverse(metric)\n",
    "\n",
    "# Generate the rhs\n",
    "rhs = MakeRHS([[0.,0.]], (aX,aX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = VaradhanDistance(diff,rhs,dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Seismic test case, computed with Varadhan's method.\")\n",
    "plt.contourf(*X,distance); plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = lp.solve_AV(metric,np.array(np.gradient(distance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal'); plt.title(\"Seismic test case geodesics, computed with Varadhan's method\")\n",
    "streamplot_ij(*X,*flow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(distance, VaradhanDistance(diff,rhs,dx,divergenceForm=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Randers metrics\n",
    "\n",
    "**Optimal control viewpoint.**\n",
    "Randers metrics are an extension of Riemannian metrics, featuring a drift term. We choose to illustrate them through an optimal control problem, referred to as Zermelo's navigation problem.\n",
    "Find the shortest time $T = T(x)$, where $x\\in \\Omega$ is a specified endpoint, for which there exists a path $\\gamma : [0,T] \\to \\Omega$ obeying \n",
    "$$\n",
    "    \\|\\gamma'(t) - \\omega(\\gamma(t)) \\|_{M(t)} \\leq 1\n",
    "$$\n",
    "for all $t \\in [0,T]$, and subject to the boundary conditions $\\gamma(0) \\in \\Gamma_D$ and $\\gamma(T) = x$.\n",
    "\n",
    "The problem parameters are the Riemannian metric $M$, the drift vector field $\\omega$, and the source set $\\Gamma_D$. We make the further assumption that \n",
    "$$\n",
    "    \\| \\omega(x) \\|_{M(x)} < 1\n",
    "$$\n",
    "for all $x \\in \\Omega$, otherwise the problem is not locally controllable.\n",
    "\n",
    "**The eikonal equation.** The arrival time $v(x) := T$ for the above optimal control problem obeys the generalized eikonal PDE\n",
    "$$\n",
    "    \\| \\nabla v(x)\\|_{D(x)} + <\\omega(x), \\nabla v(x)> = 1,\n",
    "$$\n",
    "where $D(x) := M(x)^{-1}$ is the inverse of the Riemannian metric.\n",
    "\n",
    "**Geodesic backtracking.** Minimal paths are extracted by an *intrinsic* gradient descent, taking into account the geometry defined by the Randers metric. More precisely, the backtracking ODE takes the form $\\gamma'(t) = V(\\gamma(t))$ where\n",
    "$$\n",
    "    V(x) := \\frac{D(x) \\nabla v(x)}{\\|\\nabla v(x)\\|_{D(x)}} + \\omega(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generalized Varadhan formula\n",
    "\n",
    "Consider the elliptic equation\n",
    "$$\n",
    "    u + 2\\epsilon <\\omega,\\nabla u> - \\epsilon^2 \\mathrm{div}(A \\nabla u)=0,\n",
    "$$\n",
    "where $A$ is a field of positive definite matrices, in a domain $\\Omega$. \n",
    "Assume e.g. $u=1$ on the boundary $\\partial \\Omega$.\n",
    "Then setting $u = e^{-v/\\epsilon}$, we find that $v$ obeys the PDE\n",
    "$$\n",
    "    \\|\\nabla v\\|_A^2 - \\epsilon \\mathrm{div}(A \\nabla v) = 1 + 2 <\\omega, \\nabla v>.\n",
    "$$\n",
    "Adding $<\\omega, \\nabla v>^2$ to both sides of this equation we obtain\n",
    "$$\n",
    "    \\| \\nabla v\\|_D^2 - \\epsilon \\mathrm{div}(A \\nabla v) = (1 + <\\omega, \\nabla v>)^2,\n",
    "$$\n",
    "where we have set $D := A+\\omega\\omega^T$ and factored the r.h.s.\n",
    "Neglecting the viscosity induced by the second order term, which vanishes as $\\epsilon \\to 0$, taking the square root and rearranging terms we obtain \n",
    "$$\n",
    "    \\| \\nabla v\\|_D - <\\omega,\\nabla v> =1,\n",
    "$$\n",
    "which is the generalized eikonal equation for Randers metrics.\n",
    "\n",
    "**Numerical scheme.**\n",
    "The second order term $\\mathrm{div}(A \\nabla u)$ is discretized as in the Riemannian case, relying on the techniques of \n",
    "[I Tensor decomposition, dimensions 2 and 3](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/AdaptiveGridDiscretizations/master/Notebooks/TensorSelling.ipynb)\n",
    "\n",
    "The first order term $2 <\\omega,\\nabla u>$ is discretized using centered finite differences, in the same direction as the second order differences discretizing the second order term. The resulting discretization is second order consistent, and monotone under adequate assumptions, see below.\n",
    "\n",
    "\n",
    "**Relaxation parameter.**\n",
    "The relaxation parameter $\\epsilon$ is subject to an additional constraint in the case of Rander metrics.\n",
    "Indeed, if $\\epsilon$ is too small, then the first order term dominates the second order term in Varadhan's formula, and the numerical scheme looses monotony. The resulting numerical solution may in that case present negative values, and the method fails. \n",
    "\n",
    "The method presented below involves a relaxation parameter only slightly larger than in the Riemannian case, which is already enough to accomodate fairly strong drifts, see below. Automatic setting of the relaxation parameter for even stronger drifts will be the object ot future research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandersDistance(metric,drift,rhs,dx,**kwargs):\n",
    "    diff = lp.inverse(metric)\n",
    "    distance = VaradhanDistance(diff-lp.outer_self(drift),rhs,dx,ω=2*drift,**kwargs)\n",
    "    grad = np.array(np.gradient(distance,dx))\n",
    "    flow = lp.dot_AV(diff,grad)\n",
    "    flow = flow/np.sqrt(lp.dot_VV(flow,grad)) + drift\n",
    "    return distance, flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bilinear form.** \n",
    "The numerical implementation of Varadhan's formula generalized to Randers metrics, requires the discretization of the following asymmetric bilinear form:\n",
    "$$\n",
    "    \\int_\\Omega (u v + <\\nabla u, D \\nabla v> + <\\omega,\\nabla u> v)- \\int_\\Omega fv\n",
    "$$\n",
    "\n",
    "<!---ExoFR\n",
    "Implémenter une approximation par différences finies de la forme bilinéaire ci-dessus.\n",
    "Partant d'une décomposition\n",
    "$$\n",
    "    D = \\sum_{1 \\leq i \\leq I} \\rho_i e_i e_i^T\n",
    "$$\n",
    "on pourra utiliser l'approximation\n",
    "$$\n",
    "    < \\omega,\\nabla u > = \\sum_{1 \\leq i \\leq I} \\omega_i \\frac{u(x+h e_i)-u(x-h e_i)} {2h}\n",
    "$$\n",
    "où $\\omega_i = \\rho_i <D^{-1} \\omega, e_i>$.\n",
    "--->\n",
    "\n",
    "<!---ExoCode\n",
    "def AsymmetricForm(u,v,diff,ω,rhs,dx):\n",
    "    \"\"\"\n",
    "    Finite differences discretization of the integral of \n",
    "    u*v + <grad u, D grad v> + <ω,u>v - rhs*v\n",
    "    \"\"\"\n",
    "    ρ,e = Selling.Decomposition(diff)\n",
    "    dup = fd.DiffUpwind(u, e,dx)\n",
    "    dum = fd.DiffUpwind(u,-e,dx)\n",
    "    du = fd.DiffCentered(u,e,dx)\n",
    "    dvp = fd.DiffUpwind(v, e,dx)\n",
    "    dvm = fd.DiffUpwind(v,-e,dx)\n",
    "\n",
    "    dup,dum,du,dvp,dvm = [np.where(np.isnan(e),0.,e) for e in (dup,dum,du,dvp,dvm)]\n",
    "    \n",
    "    form_density = \n",
    "    ad.simplify_ad(form_density)\n",
    "    \n",
    "    return form_density.sum()\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AsymmetricForm(u,v,diff,ω,rhs,dx):\n",
    "    \"\"\"\n",
    "    Finite differences discretization of the integral of \n",
    "    u*v + <grad u, D grad v> + <ω,u>v - rhs*v\n",
    "    \"\"\"\n",
    "    ρ,e = Selling.Decomposition(diff)\n",
    "    dup = fd.DiffUpwind(u, e,dx)\n",
    "    dum = fd.DiffUpwind(u,-e,dx)\n",
    "    du = fd.DiffCentered(u,e,dx)\n",
    "    dvp = fd.DiffUpwind(v, e,dx)\n",
    "    dvm = fd.DiffUpwind(v,-e,dx)\n",
    "\n",
    "    dup,dum,du,dvp,dvm = [np.where(np.isnan(e),0.,e) for e in (dup,dum,du,dvp,dvm)]\n",
    "    \n",
    "    η = lp.solve_AV(diff,ω)\n",
    "    λ = ρ*lp.dot_VV(np.expand_dims(η,axis=1),e)\n",
    "    \n",
    "    form_density = u*v + (0.5*ρ*(dup*dvp + dum*dvm)).sum(axis=0) + v*(λ*du).sum(axis=0) - rhs*v\n",
    "    ad.simplify_ad(form_density)\n",
    "    \n",
    "    return form_density.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Constant Rander metric\n",
    "\n",
    "This example is a sanity check, involving a constant Riemannian metric, namely the Euclidean metric, and a constant drift field in the direction of $(1,1)/\\sqrt 2$.\n",
    "As a result:\n",
    "- The level sets of the distance map are (non-concentric) circles.\n",
    "- The minimal geodesic paths a straight lines towards the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the domain\n",
    "aX,dx = np.linspace(-1,1,100,retstep=True); \n",
    "X = np.array(np.meshgrid(aX,aX,indexing='ij'))\n",
    "shape = X.shape[1:]\n",
    "\n",
    "# Define the Riemannian metric and the drift\n",
    "drift = 0.7 * np.ones(2)/np.sqrt(2)\n",
    "metric = np.eye(2)\n",
    "drift,metric = [fd.as_field(e,shape) for e in (drift,metric)]\n",
    "\n",
    "# Set the rhs\n",
    "rhs = MakeRHS([[0,0]],(aX,aX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance,flow = RandersDistance(metric,drift,rhs,dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal');\n",
    "plt.contourf(*X,distance); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamplot_ij(*X,*flow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(distance,RandersDistance(metric,drift,rhs,dx,divergenceForm=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Zermelo's problem with a variable drift\n",
    "\n",
    "We present an instance of Zermelo's navigation problem, where the vehicle's maximum speed is unit in all directions. The vehicle is however subject to a position dependent drift, with the following analytical expression:\n",
    "$$\n",
    "    \\omega(x,y) := \\rho \\sin(2 \\pi x) \\sin (2 \\pi y) \\frac{(x,y)}{\\|(x,y)\\|},\n",
    "$$\n",
    "for all $x,y \\in [-1,1]^2$. Note that the metric positiveness constraint requires $|\\rho| < 1$. We let $\\rho := 0.8$.\n",
    "\n",
    "A different numerical approach for the same problem is presented in the notebook\n",
    "[III - Rander metrics. Application to Zermelo's navigation problem, and image segmentation](http://nbviewer.jupyter.org/urls/rawgithub.com/Mirebeau/HFM_Python_Notebooks/master/A6_Rander.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = 0.8*np.sin(2*np.pi*X[0])*np.sin(2*np.pi*X[1]) * X/ np.linalg.norm(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance,flow = RandersDistance(metric,drift,rhs,dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal');\n",
    "plt.contourf(*X,distance);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal')\n",
    "streamplot_ij(*X,*flow);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(distance,RandersDistance(metric,drift,rhs,dx,divergenceForm=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}